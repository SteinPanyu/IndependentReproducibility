{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggforce)\n",
    "library(ggpubr)\n",
    "library(showtext)\n",
    "library(rmcorr)\n",
    "library(patchwork)\n",
    "\n",
    "font_add_google(\n",
    "    name='Source Serif Pro',\n",
    "    family='ssp',\n",
    "    db_cache=FALSE\n",
    ")\n",
    "\n",
    "showtext_auto()\n",
    "\n",
    "THEME_DEFAULT <- theme_bw(\n",
    "    base_size=10,\n",
    "    base_family='ssp',\n",
    ") + theme(\n",
    "        axis.title.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "        axis.title.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "        axis.text.x=element_text(colour='grey20', size=10),\n",
    "        axis.text.y=element_text(colour='grey20', size=10),\n",
    "        strip.text.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "        strip.text.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "        legend.background=element_blank(),\n",
    "        legend.title=element_text(colour='grey20', size=10, face='bold'),\n",
    "        legend.text=element_text(colour='grey20', size=10),\n",
    "        legend.position='top',\n",
    "        legend.box.spacing= unit(0, 'cm'),\n",
    "        plot.subtitle=element_text(colour='grey20', size=10, hjust=.5),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "PARTICIPANTS = pd.read_csv(PATH_PARTICIPANT).set_index('pcode')\n",
    "\n",
    "PARTICIPANTS.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'PARTICIPANT_INFO.csv'),index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTICIPANTS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belows are some demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in PARTICIPANTS.columns:\n",
    "    print(f'- {c}:', summary(PARTICIPANTS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels (via ESM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "LABELS = pd.read_csv(PATH_ESM).assign(\n",
    "    timestamp=lambda x: pd.to_datetime(x['responseTime'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    ").set_index(\n",
    "    ['pcode', 'timestamp']\n",
    ")\n",
    "LABELS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Belows are some demographics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = LABELS.groupby('pcode').count().iloc[:, -1]\n",
    "sam = np.concatenate([\n",
    "    (LABELS.loc[(p,), :].index.array - LABELS.loc[(p,), :].index.array.shift(1)).dropna().total_seconds()\n",
    "    for p in LABELS.index.get_level_values('pcode').unique()\n",
    "])\n",
    "print('- # Inst.:', summary(inst))\n",
    "print('- Samp. period:', summary(sam))\n",
    "for c in LABELS.columns:\n",
    "    print(f'- {c}:', summary(LABELS[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R -i LABELS -w 16 -h 6 -u cm\n",
    "\n",
    "data <- LABELS %>% pivot_longer(\n",
    "    cols = c('valence', 'arousal', 'attention', 'stress', 'duration', 'disturbance', 'change'),\n",
    "    names_to = 'metric'\n",
    ")\n",
    "\n",
    "p_rest <- ggplot(\n",
    "    data %>% filter(metric != 'duration'), aes(x=metric, y=value)\n",
    ") + geom_boxplot(\n",
    ") + geom_point(\n",
    "    data = data %>% filter(\n",
    "        metric != 'duration'\n",
    "    ) %>% group_by(\n",
    "        metric\n",
    "    ) %>% summarise(\n",
    "        mean = mean(value, na.rm=TRUE)\n",
    "    ),\n",
    "    mapping=aes(x=metric, y=mean),\n",
    "    shape=21,\n",
    "    stroke=1,\n",
    "    size=2,\n",
    "    fill='white'\n",
    ") + scale_x_discrete(\n",
    "    name=NULL,\n",
    "    limits=c('valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'),\n",
    "    labels=c('Valence', 'Arousal', 'Stress', 'Attent.', 'Disturb.', 'Change'),\n",
    ") + scale_y_continuous(\n",
    "    name='Response',\n",
    "    breaks=-3:3\n",
    ") + THEME_DEFAULT\n",
    "\n",
    "p_duration <- ggplot(\n",
    "    data %>% filter(metric == 'duration'), aes(x=metric, y=value)\n",
    ") + geom_boxplot(\n",
    ") + geom_point(\n",
    "    data = data %>% filter(\n",
    "        metric == 'duration'\n",
    "    ) %>% group_by(\n",
    "        metric\n",
    "    ) %>% summarise(\n",
    "        mean = mean(value, na.rm=TRUE)\n",
    "    ),\n",
    "    mapping=aes(x=metric, y=mean),\n",
    "    shape=21,\n",
    "    stroke=1,\n",
    "    size=2,\n",
    "    fill='white'\n",
    ")+ scale_x_discrete(\n",
    "    name=NULL,\n",
    "    limits=c('duration'),\n",
    "    labels=c('Duration'),\n",
    ") + scale_y_continuous(\n",
    "    name=NULL,\n",
    "    breaks=seq(from=5, to=60, by=10)\n",
    ") + THEME_DEFAULT\n",
    "\n",
    "p <- p_rest + p_duration + plot_layout(widths=c(4, 0.8))\n",
    "ggsave('./fig/dist-labels.pdf', plot=p, width=16, height=6, unit='cm', device=cairo_pdf)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "LABELS.stress.hist(bins=7, rwidth=0.7)\n",
    "plt.xlabel('Stress value on likert scale',fontsize=15)\n",
    "plt.ylabel('Number of responses',fontsize=15)\n",
    "plt.ylim([0, 1200])\n",
    "\n",
    "plt.grid(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta as td\n",
    "\n",
    "#Create a dataframe which contains the startday and endday for each user\n",
    "#Start day and end day depends on the ESM response\n",
    "EXP_DATE = LABELS.reset_index().groupby(\n",
    "    ['pcode']\n",
    ").agg(#https://deanla.com/pandas_named_agg.html#You-need-pd.NamedAgg\n",
    "    start_day=pd.NamedAgg(column='timestamp', aggfunc=lambda x: x.min().replace(hour=0, minute=0, second=0, microsecond=0)),\n",
    "    end_day=pd.NamedAgg(column='timestamp', aggfunc=lambda x: (x.max() + td(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)),\n",
    ")\n",
    "\n",
    "DIST_DATA = []\n",
    "\n",
    "for p in EXP_DATE.index: #p is the pcode\n",
    "    raw_data = LABELS.loc[p]\n",
    "\n",
    "    dist_temp = []\n",
    "\n",
    "    for data_type, data_values in raw_data.items(): #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html\n",
    "        data_sub = pd.concat([\n",
    "            data_values.to_frame().reset_index().assign(pcode=p) #to_frame() Convert Series to DataFrame.\n",
    "        ]).merge(\n",
    "            EXP_DATE, on='pcode', how='left'\n",
    "        ).loc[\n",
    "            #remove those sensor data which is outside the ESM collection period\n",
    "            #.dt.total_seconds() Return total duration of each element expressed in seconds.\n",
    "            lambda x: ((x['timestamp'] - x['start_day']).dt.total_seconds() >= 0) & ((x['end_day'] - x['timestamp']).dt.total_seconds() >= 0), :\n",
    "        ].assign(\n",
    "            #The floor of the scalar x is the largest integer i, such that i <= x. \n",
    "            day = lambda x: np.floor((x['timestamp'] - x['start_day']).dt.total_seconds() / 60 / 60 / 24)\n",
    "        ).groupby(\n",
    "            ['pcode', 'day']\n",
    "        ).count()['timestamp'].reset_index().assign(\n",
    "            type=data_type\n",
    "        )\n",
    "\n",
    "        dist_temp.append(data_sub)\n",
    "\n",
    "    DIST_DATA.append(pd.concat(dist_temp))\n",
    "    \n",
    "DIST_DATA = pd.concat(DIST_DATA)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a visualization package\n",
    "#https://altair-viz.github.io/getting_started/overview.html\n",
    "import altair as alt \n",
    "\n",
    "#If you are certain you would like to embed your dataset within the visualization specification, you can disable the MaxRows check with the following:\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "selection = alt.selection_single(\n",
    "    fields=['type'],\n",
    "    bind=alt.binding_select(\n",
    "        options=DIST_DATA['type'].unique(),\n",
    "        name='Data Type: '\n",
    "    )\n",
    ")\n",
    "\n",
    "chart=alt.Chart(DIST_DATA).mark_rect().encode(\n",
    "     x=alt.X('day:O', title='Time (days)'),\n",
    "     y=alt.Y('pcode:O', title='Pcode'),\n",
    "     color=alt.Color('timestamp:Q', title='Count')\n",
    ").transform_filter(\n",
    "    selection\n",
    ").add_selection(\n",
    "    selection\n",
    ").properties(\n",
    "    title='# Labels',\n",
    "    width=300,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.save('fig/#_labels.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each participant reported their labels multiple times (i.e., repeated measure), repeated measure correlation between affect labels were used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LABELS.reset_index()[[\n",
    "    'pcode', 'valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i data \n",
    "\n",
    "com <- combn(c('valence', 'arousal', 'stress', 'attention', 'disturbance', 'change'), 2)\n",
    "\n",
    "for(i in 1:ncol(com)) {\n",
    "    a <- com[, i][1]\n",
    "    b <- com[, i][2]\n",
    "    r <- rmcorr(participant = 'pcode', measure1=a, measure2=b, dataset=data)\n",
    "    cat(a, '-', b, ': R =', r$r, '(p =', r$p, ') \\n')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def _load_data(\n",
    "    name: str\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    paths = [\n",
    "        (d, os.path.join(PATH_SENSOR, d, f'{name}.csv'))\n",
    "        for d in os.listdir(PATH_SENSOR)\n",
    "        if d.startswith('P')\n",
    "    ]\n",
    "    return pd.concat(\n",
    "        filter(\n",
    "            lambda x: len(x.index),  #filter out any emmpty dataframe\n",
    "            [\n",
    "                pd.read_csv(p).assign(pcode=pcode)\n",
    "                for pcode, p in paths\n",
    "                if os.path.exists(p)\n",
    "            ]\n",
    "        ), ignore_index=True\n",
    "    ).assign(\n",
    "        timestamp=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "    ).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from datetime import timedelta as td\n",
    "\n",
    "\n",
    "for data_type in DATA_TYPES:\n",
    "    dat = _load_data(data_type)\n",
    "    inst = dat.groupby('pcode').count().iloc[:, -1]\n",
    "    sam = np.concatenate([\n",
    "        (dat.loc[(p,), :].index.array - dat.loc[(p,), :].index.array.shift(1)).dropna().total_seconds()\n",
    "        for p in dat.index.get_level_values('pcode').unique()\n",
    "    ])\n",
    "    print('#'*5, data_type, '#'*5)\n",
    "    print('- # Inst.:', summary(inst))\n",
    "    print('- Samp. period:', summary(sam))\n",
    "    for c in dat.columns:\n",
    "        print(f'- {c}:', summary(dat[c]))\n",
    "        \n",
    "    del dat\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label\n",
    "\n",
    "Here we consider binary classifications for valence, arousal, stress, and disturbance, in which a label value greater than 0 is \"HIGH\" (1) and the rest is \"LOW\" (0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LABELS_VALID = LABELS.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna(), :\n",
    "]\n",
    "print(f'# Non-voluntary response: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "excl_pcode = LABELS_VALID.loc[\n",
    "    lambda x: ~x['scheduledTime'].isna()\n",
    "].groupby('pcode').count().iloc[:, -1].loc[lambda y: y < 35]\n",
    "\n",
    "LABELS_VALID = LABELS_VALID.loc[\n",
    "    lambda x:  ~x.index.get_level_values('pcode').isin(excl_pcode.index), :\n",
    "]\n",
    "print(f'# Response from participants with enough responses: {len(LABELS_VALID)}')\n",
    "print(summary(LABELS_VALID.groupby('pcode').count().iloc[:, -1]))\n",
    "\n",
    "print('# Participants whose responses to ESM delivery were less then 35')\n",
    "print(excl_pcode, f'#participants = {len(excl_pcode)} / #response = {sum(excl_pcode)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(LABELS_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "LABELS_PROC = LABELS_VALID.assign(\n",
    "    valence_dyn = lambda x: np.where(x['valence'] > LABELS_VALID['valence'].mean(), 1, 0),\n",
    "    arousal_dyn = lambda x: np.where(x['arousal'] > LABELS_VALID['arousal'].mean(), 1, 0),\n",
    "    stress_dyn = lambda x: np.where(x['stress'] > LABELS_VALID['stress'].mean(), 1, 0),\n",
    "    disturbance_dyn = lambda x: np.where(x['disturbance'] > LABELS_VALID['disturbance'].mean(), 1, 0),\n",
    "    valence_fixed = lambda x: np.where(x['valence'] > 0, 1, 0),\n",
    "    arousal_fixed = lambda x: np.where(x['arousal'] > 0, 1, 0),\n",
    "    stress_fixed = lambda x: np.where(x['stress'] > 0, 1, 0),\n",
    "    disturbance_fixed = lambda x: np.where(x['disturbance'] > 0, 1, 0),    \n",
    "    \n",
    ")\n",
    "LABELS_PROC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "inst = LABELS_PROC.groupby('pcode').count().iloc[:, -1]\n",
    "sam = np.concatenate([\n",
    "    (LABELS_PROC.loc[(p,), :].index.array - LABELS_PROC.loc[(p,), :].index.array.shift(1)).dropna().total_seconds()\n",
    "    for p in LABELS_PROC.index.get_level_values('pcode').unique()\n",
    "])\n",
    "\n",
    "for c in [c for c in LABELS_PROC.columns if (c.endswith('_dyn') or c.endswith('_fixed'))]:\n",
    "    print(f'- {c}:', summary(LABELS_PROC[c].astype(object)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(LABELS_PROC['stress_fixed'].value_counts())\n",
    "LABELS_PROC.stress_fixed.value_counts().plot(kind='bar', rot=0)\n",
    "plt.xlabel('Stress label(compared with fixed thereshold=0)',fontsize=15)\n",
    "plt.ylabel('Number of responses',fontsize=15)\n",
    "plt.ylim([0, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(LABELS_PROC['stress_dyn'].value_counts())\n",
    "LABELS_PROC.stress_dyn.value_counts().plot(kind='bar', rot=0)\n",
    "plt.xlabel('Stress label(compared with dynamic thereshold=mean)',fontsize=15)\n",
    "plt.ylabel('Number of responses',fontsize=15)\n",
    "plt.ylim([0, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PROC.to_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'LABELS_PROC.csv'), index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize Label Distribution After Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta as td\n",
    "\n",
    "#Create a dataframe which contains the startday and endday for each user\n",
    "#Start day and end day depends on the ESM response\n",
    "EXP_DATE = LABELS_PROC.reset_index().groupby(\n",
    "    ['pcode']\n",
    ").agg(#https://deanla.com/pandas_named_agg.html#You-need-pd.NamedAgg\n",
    "    start_day=pd.NamedAgg(column='timestamp', aggfunc=lambda x: x.min().replace(hour=0, minute=0, second=0, microsecond=0)),\n",
    "    end_day=pd.NamedAgg(column='timestamp', aggfunc=lambda x: (x.max() + td(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)),\n",
    ")\n",
    "\n",
    "DIST_DATA = []\n",
    "\n",
    "for p in EXP_DATE.index: #p is the pcode\n",
    "    raw_data = LABELS.loc[p]\n",
    "\n",
    "    dist_temp = []\n",
    "\n",
    "    for data_type, data_values in raw_data.items(): #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.items.html\n",
    "        data_sub = pd.concat([\n",
    "            data_values.to_frame().reset_index().assign(pcode=p) #to_frame() Convert Series to DataFrame.\n",
    "        ]).merge(\n",
    "            EXP_DATE, on='pcode', how='left'\n",
    "        ).loc[\n",
    "            #remove those sensor data which is outside the ESM collection period\n",
    "            #.dt.total_seconds() Return total duration of each element expressed in seconds.\n",
    "            lambda x: ((x['timestamp'] - x['start_day']).dt.total_seconds() >= 0) & ((x['end_day'] - x['timestamp']).dt.total_seconds() >= 0), :\n",
    "        ].assign(\n",
    "            #The floor of the scalar x is the largest integer i, such that i <= x. \n",
    "            day = lambda x: np.floor((x['timestamp'] - x['start_day']).dt.total_seconds() / 60 / 60 / 24)\n",
    "        ).groupby(\n",
    "            ['pcode', 'day']\n",
    "        ).count()['timestamp'].reset_index().assign(\n",
    "            type=data_type\n",
    "        )\n",
    "\n",
    "        dist_temp.append(data_sub)\n",
    "\n",
    "    DIST_DATA.append(pd.concat(dist_temp))\n",
    "    \n",
    "DIST_DATA = pd.concat(DIST_DATA)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a visualization package\n",
    "#https://altair-viz.github.io/getting_started/overview.html\n",
    "import altair as alt \n",
    "\n",
    "#If you are certain you would like to embed your dataset within the visualization specification, you can disable the MaxRows check with the following:\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "selection = alt.selection_single(\n",
    "    fields=['type'],\n",
    "    bind=alt.binding_select(\n",
    "        options=DIST_DATA['type'].unique(),\n",
    "        name='Data Type: '\n",
    "    )\n",
    ")\n",
    "\n",
    "chart=alt.Chart(DIST_DATA).mark_rect().encode(\n",
    "     x=alt.X('day:O', title='Time (days)'),\n",
    "     y=alt.Y('pcode:O', title='Pcode'),\n",
    "     color=alt.Color('timestamp:Q', title='Count')\n",
    ").transform_filter(\n",
    "    selection\n",
    ").add_selection(\n",
    "    selection\n",
    ").properties(\n",
    "    title='# Labels',\n",
    "    width=300,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensor Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each type of sensor data, we applied different preprocessing, as follows:\n",
    "* AppUsageEvent.csv: We only consider \"packageName\" and \"category\" if a value of the field, \"type\", is either \"MOVE_TO_FOREGROUND\" or \"MOVE_TO_BACKGROUND\", because this value appears on any smartphone whose OS version is equal to or greather than 21, which was our criteria.\n",
    "* Connectivity.csv: the value of \"type\" field if \"isConnected\" is True; otherwise, \"UNDEFINED\"\n",
    "* Battery.csv: \"level\", \"status\", and \"temperature\" are used\n",
    "* CallEvent.csv: consider data whose \"duration\" is greater than 0. In addition, considering duration, we transformed call data that indicate currently calling or not. For example, given data whose the timestamp is $t$ and duration is 30,000, we generated two new data, in which \"CALLING\" at $t$ and \"IDEL\" at $t + 30,000$.\n",
    "* DataTraffic.csv: \"rxKiloBytes\" and \"txKiloBytes\" are used.\n",
    "* RingerModeEvent.csv: \"type\" field is used\n",
    "* ScreenEvent.csv: \"type\" field is used\n",
    "* OnOffEvent.csv: True if \"type\" equals to \"ON\"; otherwise, False.\n",
    "* PowerSaveEvent.csv: True if \"type\" equals to \"ACTIVATE\"; otherwise, False.\n",
    "* ChargeEvent.csv: True if \"type\" equals to \"CONNECTED\"; otherwise, False.\n",
    "* Location.csv: two consecutive GPS coordinates are used to calculate distance (in metre). In addition, GPS coordinates are transformed into 7-bit geohash, indicate 150 X 150-metre-sized cluster\n",
    "* ActivityTransition: \"transitionType\" field is used.\n",
    "* ActivityEvent: \"condienceXXX\" fields are used.\n",
    "* WiFi: similiarity measures, including Euclidean, Correlation, Manhattan, and Jaccard index, were calculated from two consecutive WiFi scanned APs.\n",
    "* InstalledApp: similarity measure, the Jaccard Index, was calculated from two consecutive installced app list.\n",
    "* MediaEvent: the number of video (\"mimetype\" starts with \"video/\"), image (\"mimetype\" starts with \"image/\" , and all media taken per second was calculated.\n",
    "* MessageEvent: the number of messages sent (\"messageBox\" equals to \"SENT\"), received (\"messageBox\" equals to \"INBOX\"), and both of them per second was calculated.\n",
    "* Acceleration: \"x\", \"y\", \"z\", and magnitude (i.e., $\\sqrt{x^2 + y^2 + z^2}$).\n",
    "* UltraViolet: \"intensity\"; net exposure between consecutive \"totalExposure\" values per second.\n",
    "* SkinTemperature: \"temperature\"\n",
    "* RRI: \"interval\"\n",
    "* AmbientLight: \"brightness\"\n",
    "* StepCount: \"steps\" per second\n",
    "* HR: \"bpm\"\n",
    "* EDA: \"resistance\"\n",
    "* Distance: net distance between consecutive \"totalDistance\" values per second; \"motionType\", \"pace\", and \"speed\"\n",
    "* Calorie: net calorie between consecutive \"totalCalories\" values per second.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "import pygeohash as geo\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict  \n",
    "from scipy.signal import medfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def trim_outlier(col, threshold=3.0):\n",
    "    \"\"\"\n",
    "    Remove the values in a dataframe column based on the median and the median absolute deviation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    col : pandas.Series\n",
    "        The column to be trimmed.\n",
    "    threshold : float, optional\n",
    "        The threshold for trimming, expressed in units of the Median Absolute Deviation (MAD).\n",
    "        Observations with a distance greater than `threshold` times the MAD value from the median are removed.\n",
    "        Default is 3.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        The column without outliers.\n",
    "    \"\"\"\n",
    "    median = col.median()\n",
    "    mad = (col - median).abs().median()\n",
    "    threshold_value = threshold * mad\n",
    "    mask = (col > median - threshold_value) & (col < median + threshold_value)\n",
    "    return col[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "def _haversine(_lat1, _lat2, _lng1, _lng2) -> float:\n",
    "    if np.isnan(_lat1) or np.isnan(_lat2) or np.isnan(_lng1) or np.isnan(_lng2):\n",
    "        return 0.0\n",
    "\n",
    "    _lat1_r, _lat2_r, _lng1_r, _lng2_r = np.radians(_lat1), np.radians(_lat2), np.radians(_lng1), np.radians(_lng2)\n",
    "    _lat = _lat2_r - _lat1_r\n",
    "    _lng = _lng2_r - _lng1_r\n",
    "    _R = 6371008.8\n",
    "    _d = np.sin(_lat * 0.5) ** 2 + np.cos(_lat1_r) * np.cos(_lat2_r) * np.sin(_lng * 0.5) ** 2\n",
    "    return 2 * _R * np.arcsin(np.sqrt(_d))\n",
    "\n",
    "new_data = []\n",
    "DISTANCE_MAX_IN_METRE = 100 #@param {type:\"slider\", min:25, max:500, step:25}\n",
    "REGION_SIZE_IN_METRE = 250 #@param {type:\"slider\", min:25, max:500, step:25}\n",
    "MAXIMUM_TIME_IN_MIN = 60 #@param {type:\"slider\", min:60, max:120, step:20}\n",
    "MINIMUM_TIME_IN_MIN = 5 #@param {type:\"slider\", min:1, max:15, step:1}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "#Weiszfeld algorithm to calculate midpoint in a cluster\n",
    "def midpoint(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Load the GPS locations of the cluster into a NumPy array\n",
    "    _data = np.array(data[['latitude','longitude']])\n",
    "    # Set the initial estimate to the mean of the GPS coordinates\n",
    "    midpoint = np.mean(_data, axis=0)\n",
    "    # Define the stopping criterion\n",
    "    epsilon = 1e-6\n",
    "    # Define the maximum number of iterations\n",
    "    max_iterations = 100\n",
    "    # Define the Weiszfeld algorithm\n",
    "    for i in range(max_iterations):\n",
    "        # Compute the distances between the midpoint and the points\n",
    "        distances = np.sqrt(np.sum((_data - midpoint)**2, axis=1))\n",
    "        \n",
    "        # Check if any distance is 0\n",
    "        if np.any(distances == 0):\n",
    "            idx = np.where(distances == 0)[0][0]\n",
    "            return pd.DataFrame({'mid_latitude': _data[idx, 0], 'mid_longitude': _data[idx, 1]}, index=data.index)\n",
    "       \n",
    "        \n",
    "        # Check if the stopping criterion has been reached\n",
    "        if np.max(distances) < epsilon:\n",
    "            break\n",
    "        # Compute the weighted mean of the GPS coordinates\n",
    "        weights = 1.0 / distances\n",
    "        midpoint = np.sum(_data * weights[:, np.newaxis], axis=0) / np.sum(weights)\n",
    "    return pd.DataFrame({'mid_latitude': midpoint[0], 'mid_longitude': midpoint[1]}, index=data.index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Define the API key and client\n",
    "API_KEY = 'AIzaSyAqZ6N_8TuUqDqGDhUF0y9ub8QZb2ZT4s0'\n",
    "client = googlemaps.Client(API_KEY)\n",
    "\n",
    "Eating = ['restaurant']\n",
    "Social = ['bar','cafe','movie_theater','night_club']\n",
    "Gym = ['gym']\n",
    "known = Eating + Social + Gym\n",
    "\n",
    "def label_cluster(data, radius):\n",
    "    location = (data['mid_latitude'].mean(),data['mid_longitude'].mean())\n",
    "    #return data['mid_latitude'].mean()\n",
    "    # Perform the search\n",
    "    results = client.places_nearby(location=location, radius=radius)\n",
    "    # Filter the results by type (e.g. restaurant)\n",
    "    known_places = [place for place in results['results'] if any(elem in place['types'] for elem in known)]\n",
    "    if known_places:\n",
    "        # Get the closest place to the location\n",
    "        closest_place = min(known_places, key=lambda p: p.get('distance', {}).get('value', float('inf')))\n",
    "\n",
    "        if any(elem in closest_place['types'] for elem in Social):\n",
    "            data['label']='social'\n",
    "        elif any(elem in closest_place['types'] for elem in Eating):\n",
    "            data['label']='eating'\n",
    "        else:\n",
    "            data['label']='gym'\n",
    "    else:\n",
    "        data['label']='others'\n",
    "    return data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# Define the center and radius of the circle around KAIST main campus\n",
    "center_lat_kaist, center_lon_kaist = (36.3722, 127.3600)\n",
    "_radius_kaist = 1000 # meters\n",
    "\n",
    "# Define the center and radius of the circle around KAIST Munji campus\n",
    "center_lat_munji, center_lon_munji = (36.391944, 127.398611)\n",
    "_radius_munji = 400 # meters\n",
    "\n",
    "# Calculate the distances between the cluster centers and the center of the circle\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000 # meters\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(delta_phi/2)**2 + \\\n",
    "        math.cos(phi1)*math.cos(phi2)*math.sin(delta_lambda/2)**2\n",
    "    c = 2*math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    d = R*c\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from typing import Dict, Union\n",
    "#import pygeohash as geo\n",
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import timedelta\n",
    "from collections import defaultdict\n",
    "from poi import PoiCluster\n",
    "from Funcs.Utility import transform\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# # AppUsageEvent.csv\n",
    "# def _proc_app_usage(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "#     data = data.loc[\n",
    "#         lambda x: x['type'].isin(['MOVE_TO_FOREGROUND', 'MOVE_TO_BACKGROUND']), :\n",
    "#     ].assign(\n",
    "# #        packageName=lambda x: np.where(x['type'] == 'MOVE_TO_FOREGROUND', x['packageName'], None),\n",
    "#         category=lambda x: np.where(x['type'] == 'MOVE_TO_FOREGROUND', x['category'], None),\n",
    "#     )\n",
    "    \n",
    "#     data = data.rename(columns={'category':'subcategory'})\n",
    "#     data['category'] = [transform[item] for item in data['subcategory'].values]\n",
    "\n",
    "\n",
    "#     return {\n",
    "# #        'PAC': data['packageName'].astype('object'),\n",
    "#         'CAT': data['category'].astype('object')\n",
    "#     }\n",
    "\n",
    "def _proc_app_usage(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    \n",
    "    data = data.loc[\n",
    "        lambda x: x['type'].isin(['MOVE_TO_FOREGROUND', 'MOVE_TO_BACKGROUND']), :\n",
    "    ].assign(\n",
    "#        packageName=lambda x: np.where(x['type'] == 'MOVE_TO_FOREGROUND', x['packageName'], None),\n",
    "        category=lambda x: np.where(x['type'] == 'MOVE_TO_FOREGROUND', x['category'], None),\n",
    "    )\n",
    "    \n",
    "    data = data.rename(columns={'category':'subcategory'})\n",
    "    data['category'] = [transform[item] for item in data['subcategory'].values]\n",
    "    \n",
    "    move = data\n",
    "    #data = data.reset_index()\n",
    "    \n",
    "    Duration = []\n",
    "    #Calculate duration for each user\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub_move = move.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode) # sort screen events by timestamp\n",
    "        sub_move = sub_move.reset_index()\n",
    "        sub_move['move_state'] = sub_move['type'].shift().fillna('MOVE_TO_BACKGROUND') # create a new column to keep the previous screen event\n",
    "        sub_move.loc[0, 'move_state'] = 'MOVE_TO_BACKGROUND'\n",
    "        sub_move = sub_move[sub_move['move_state'] != sub_move['type']]\n",
    "        sub_move.index = pd.to_datetime(sub_move.index) # convert index to DatetimeIndex\n",
    "        sub_move['duration'] = sub_move['timestamp'] - sub_move['timestamp'].shift()\n",
    "        sub_move.loc[0, 'duration'] = pd.Timedelta(0)\n",
    "        sub_move = sub_move[sub_move['duration'] > pd.Timedelta(0)]\n",
    "        sub_move['duration_sec'] = sub_move['duration'].dt.total_seconds()\n",
    "        sub_move['category'] = sub_move['category']\n",
    "        Duration.append(sub_move)\n",
    "\n",
    "    Duration = pd.concat(Duration, axis=0, ignore_index=True).set_index(\n",
    "            ['pcode', 'timestamp']\n",
    "        ) \n",
    "    cnt = Duration['category'].value_counts()\n",
    "    _val, _sup = cnt.index, cnt.values\n",
    "    \n",
    "    DUR = {'DUR_{}'.format(_k): Duration[Duration['category'] == '{}'.format(_k)]['duration_sec'].astype('float32') for _k in _val}\n",
    "    \n",
    "    CAT = {'CAT': data['category'].astype('object')}\n",
    "    \n",
    "    Feature = {**DUR, **CAT}\n",
    "        \n",
    "    return Feature\n",
    "# Connectivity.csv\n",
    "def _proc_connectivity(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data = data.assign(\n",
    "        type=lambda x: np.where(x['isConnected'] == True, x['type'], 'DISCONNECTED')\n",
    "    )\n",
    "\n",
    "    return data['type'].astype('object')\n",
    "\n",
    "\n",
    "# BatteryEvent.csv\n",
    "def _proc_battery(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return {\n",
    "        'LEV': data['level'].astype('float32'),\n",
    "        'STA': data['status'].astype('object'),\n",
    "        'TMP': data['temperature'].astype('float32')\n",
    "    }\n",
    "        \n",
    "\n",
    "# CallEvent.csv\n",
    "def _proc_call(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    #filter those calls with duration = 0\n",
    "    data = data.loc[\n",
    "        lambda x: x['duration'] > 0, :\n",
    "    ]\n",
    "    \n",
    "#     new_data = []\n",
    "\n",
    "#     for row in data.itertuples():\n",
    "#         pcode, timestamp = row.Index\n",
    "        \n",
    "#         new_data.append({\n",
    "#             'pcode': pcode,\n",
    "#             'timestamp': timestamp,                \n",
    "#             'state': 'CALL',\n",
    "#         })\n",
    "#         new_data.append({\n",
    "#             'pcode': pcode,\n",
    "#             'timestamp': timestamp + timedelta(milliseconds=row.duration),\n",
    "#             'state': 'IDLE'\n",
    "#         })\n",
    "\n",
    "#     new_data = pd.DataFrame(new_data).set_index(\n",
    "#         ['pcode', 'timestamp']\n",
    "#     )\n",
    "\n",
    "    return {\n",
    "        'DUR': data['duration'].astype('float32'),\n",
    "        'CNT': data['timesContacted'].astype('int')\n",
    "    }\n",
    "\n",
    "\n",
    "# DataTraffic.csv\n",
    "def _proc_data_traffic(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return {\n",
    "        'RCV': data['rxKiloBytes'].astype('float32'),\n",
    "        'SNT': data['txKiloBytes'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# RingerModeEvent.csv\n",
    "def _proc_ringer_mode(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['type'].astype('object')\n",
    "\n",
    "\n",
    "# ScreenEvent.csv\n",
    "def _proc_screen(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    screen_on = data[data['type'].isin(['ON'])]\n",
    "    screen_off =data[data['type'].isin(['OFF'])]\n",
    "    unlock = data[data['type'].isin(['UNLOCK'])]\n",
    "    screen = data[data['type'].isin(['ON','OFF'])]\n",
    "    #data = data.reset_index()\n",
    "    \n",
    "    Duration = []\n",
    "    #Calculate duration for each user\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub_screen = screen.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode) # sort screen events by timestamp\n",
    "        sub_screen = sub_screen.reset_index()\n",
    "        sub_screen['screen_state'] = sub_screen['type'].shift().fillna('OFF') # create a new column to keep the previous screen event\n",
    "        sub_screen.loc[0, 'screen_state'] = 'OFF'\n",
    "        sub_screen = sub_screen[sub_screen['screen_state'] != sub_screen['type']]\n",
    "        sub_screen.index = pd.to_datetime(sub_screen.index) # convert index to DatetimeIndex\n",
    "        sub_screen['duration'] = sub_screen['timestamp'] - sub_screen['timestamp'].shift()\n",
    "        sub_screen.loc[0, 'duration'] = pd.Timedelta(0)\n",
    "        sub_screen = sub_screen[sub_screen['duration'] > pd.Timedelta(0)]\n",
    "        sub_screen['duration_sec'] = sub_screen['duration'].dt.total_seconds()\n",
    "        Duration.append(sub_screen)\n",
    "\n",
    "    Duration = pd.concat(Duration, axis=0, ignore_index=True).set_index(\n",
    "            ['pcode', 'timestamp']\n",
    "        ) \n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'EVENT': data['type'].astype('object'),\n",
    "        'DUR': Duration['duration_sec'].astype('float32')\n",
    "    }\n",
    "\n",
    "# OnOffEvent.csv\n",
    "def _proc_on_off(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['type'].astype('object')\n",
    "\n",
    "\n",
    "# PowerSaveEvent.csv\n",
    "def _proc_power_save(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['type'].astype('object')\n",
    "\n",
    "\n",
    "# ChargeEvent.csv\n",
    "def _proc_charge(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['type'].astype('object')\n",
    "\n",
    "\n",
    "# Location.csv\n",
    "def _proc_location(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    def _haversine(_lat1, _lat2, _lng1, _lng2) -> float:\n",
    "        if np.isnan(_lat1) or np.isnan(_lat2) or np.isnan(_lng1) or np.isnan(_lng2):\n",
    "            return 0.0\n",
    "        \n",
    "        _lat1_r, _lat2_r, _lng1_r, _lng2_r = np.radians(_lat1), np.radians(_lat2), np.radians(_lng1), np.radians(_lng2)\n",
    "        _lat = _lat2_r - _lat1_r\n",
    "        _lng = _lng2_r - _lng1_r\n",
    "        _R = 6371008.8\n",
    "        _d = np.sin(_lat * 0.5) ** 2 + np.cos(_lat1_r) * np.cos(_lat2_r) * np.sin(_lng * 0.5) ** 2\n",
    "        return 2 * _R * np.arcsin(np.sqrt(_d))\n",
    "    \n",
    "    new_data = []\n",
    "    DISTANCE_MAX_IN_METRE = 100 #@param {type:\"slider\", min:25, max:500, step:25}\n",
    "    REGION_SIZE_IN_METRE = 250 #@param {type:\"slider\", min:25, max:500, step:25}\n",
    "    MAXIMUM_TIME_IN_MIN = 60 #@param {type:\"slider\", min:60, max:120, step:20}\n",
    "    MINIMUM_TIME_IN_MIN = 5 #@param {type:\"slider\", min:1, max:15, step:1}    \n",
    "    \n",
    "\n",
    "    #We need to do clustering individually\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            _latitude=lambda x: x['latitude'].shift(1),\n",
    "            _longitude=lambda x: x['longitude'].shift(1),\n",
    "            dist=lambda x: x.apply(\n",
    "                lambda y: _haversine(y['latitude'], y['_latitude'], y['longitude'], y['_longitude']),\n",
    "                axis=1\n",
    "            ),        \n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        # Convert the 'timestamp' column to Unix timestamps\n",
    "        sub['timestamp'] = sub['timestamp'].apply(lambda x: int(pd.Timestamp(x).timestamp() * 1000))\n",
    "\n",
    "        sub = sub[sub['accuracy']<100] #filter out those with accuracy below 100\n",
    "\n",
    "        latlon_rad = np.radians(\n",
    "            sub.loc[:, ['latitude', 'longitude']].to_numpy()\n",
    "        )\n",
    "\n",
    "        timestamps = sub.loc[:, 'timestamp'].values\n",
    "        cluster = PoiCluster(\n",
    "                d_max=DISTANCE_MAX_IN_METRE, r_max=REGION_SIZE_IN_METRE, t_max=MAXIMUM_TIME_IN_MIN * 60 * 1000, \n",
    "                t_min=MINIMUM_TIME_IN_MIN * 60 * 1000\n",
    "            ).fit(\n",
    "                X=latlon_rad, \n",
    "                timestamps=timestamps\n",
    "            )\n",
    "        labels = cluster.predict(X=latlon_rad)\n",
    "        sub = sub.assign(cluster =labels)\n",
    "\n",
    "        # replace empty strings with None\n",
    "        sub['cluster'].replace('', 'NONE', inplace=True)\n",
    "\n",
    "        sub[['mid_latitude','mid_longitude']] = sub.groupby('cluster', group_keys=False).apply(lambda x: midpoint(x)).apply(pd.Series)\n",
    "\n",
    "        # convert the timestamp column to a datetime object\n",
    "        sub=sub.assign(\n",
    "                _timestamp=lambda x: pd.to_datetime(x['timestamp'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "            )\n",
    "\n",
    "        # Sort the data by timestamp in ascending order\n",
    "        sub = sub.sort_values(by='_timestamp')\n",
    "        sub['day_of_week'] = sub['_timestamp'].dt.dayofweek\n",
    "        sub['hour_of_day'] = sub['_timestamp'].dt.hour\n",
    "        sub['day_or_night'] = sub['_timestamp'].apply(lambda x: 1 if x.hour >= 9 and x.hour < 18 else 0)\n",
    "        sub['wkday_or_wkend'] = sub['_timestamp'].apply(lambda x: 1 if x.dayofweek <=4  else 0)\n",
    "        # Calculate the difference between consecutive timestamps for each location cluster\n",
    "        sub['duration'] = sub['_timestamp'].diff()\n",
    "        # Replace missing values with 0\n",
    "        sub = sub.fillna(pd.Timedelta(seconds=0))\n",
    "        home = sub[sub['day_or_night']==0]['duration'].groupby(sub['cluster']).sum().idxmax()\n",
    "        work = sub[sub['day_or_night']==1 ][ sub['wkday_or_wkend']==1][sub['cluster']!=home]['duration'].groupby(sub['cluster']).sum().idxmax()\n",
    "        #Assign values to home and work clusters\n",
    "        condition_home = sub['cluster'] == home\n",
    "        condition_work = sub['cluster'] == work\n",
    "        condition_none = sub['cluster'] == 'NONE'\n",
    "        sub.loc[condition_home,'label']='home'\n",
    "        sub.loc[condition_work,'label']='work'\n",
    "        sub.loc[condition_none,'label']='none'\n",
    "\n",
    "        radius = 100  # meters\n",
    "        mask = sub['label'].isna()\n",
    "        sub['label'] = sub[mask].groupby('cluster', group_keys=False).apply(lambda x: label_cluster(x, radius)).apply(pd.Series)\n",
    "\n",
    "        #Assign values again to home and work clusters\n",
    "        condition_home = sub['cluster'] == home\n",
    "        condition_work = sub['cluster'] == work\n",
    "        condition_none = sub['cluster'] == 'NONE'\n",
    "        sub.loc[condition_home,'label']='home'\n",
    "        sub.loc[condition_work,'label']='work'\n",
    "        sub.loc[condition_none,'label']='none'\n",
    "\n",
    "        centers = sub[sub['label']=='others'].groupby('cluster').mean()\n",
    "        distances_kaist = centers.apply(lambda row: haversine(center_lat_kaist, center_lon_kaist, row['latitude'], row['longitude']), axis=1)\n",
    "        distances_munji = centers.apply(lambda row: haversine(center_lat_munji, center_lon_munji, row['latitude'], row['longitude']), axis=1)\n",
    "\n",
    "        # Check which cluster centers are within the circle\n",
    "        in_circle_kaist = distances_kaist <= _radius_kaist\n",
    "        cluster_centers_in_circle_kaist = centers[in_circle_kaist]\n",
    "\n",
    "        in_circle_munji = distances_munji <= _radius_munji\n",
    "        cluster_centers_in_circle_munji = centers[in_circle_munji]\n",
    "\n",
    "        cluster_centers_in_circle = pd.concat([cluster_centers_in_circle_kaist, cluster_centers_in_circle_munji])\n",
    "\n",
    "        condition_work_other = sub['cluster'].isin(cluster_centers_in_circle.index)\n",
    "        sub.loc[condition_work_other, 'label'] = 'work'\n",
    "\n",
    "\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "    \n",
    "\n",
    "    return {\n",
    "        'CLS': new_data['cluster'].astype('object'),\n",
    "        'LABEL': new_data['label'].astype('object'),\n",
    "        'DST': new_data['dist'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# ActivityEvent.csv\n",
    "def _proc_activity_event(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return {\n",
    "        'UNK': data['confidenceUnknown'].astype('float32'),\n",
    "        'FOT': data['confidenceOnFoot'].astype('float32'),\n",
    "        'WLK': data['confidenceWalking'].astype('float32'),\n",
    "        'VHC': data['confidenceInVehicle'].astype('float32'),\n",
    "        'BCC': data['confidenceOnBicycle'].astype('float32'),\n",
    "        'RUN': data['confidenceRunning'].astype('float32'),\n",
    "        'TLT': data['confidenceTilting'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# ActivityTransition.csv\n",
    "def _proc_activity_transition(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data = data.loc[\n",
    "        lambda x: x['transitionType'].isin(['ENTER_WALKING', 'ENTER_STILL', 'ENTER_IN_VEHICLE', 'ENTER_ON_BICYCLE', 'ENTER_RUNNING']), :\n",
    "    ].assign(\n",
    "        type=lambda x: x['transitionType'].str.replace('ENTER_', '')\n",
    "    )\n",
    "    \n",
    "    return data['type'].astype('object')\n",
    "\n",
    "\n",
    "# WiFi.csv\n",
    "def _proc_wifi(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "    \n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            bssid=lambda x: x['bssid'].str.cat(x['frequency'].astype(str), sep='-')\n",
    "        )\n",
    "        t = sub.index.unique().array\n",
    "        for cur_t, prev_t in zip(t, t.shift(1)):\n",
    "            if cur_t is pd.NaT or prev_t is pd.NaT:\n",
    "                continue\n",
    "\n",
    "            prev = sub.loc[[prev_t], :]\n",
    "            cur = sub.loc[[cur_t], :]\n",
    "            intersect = np.intersect1d(prev['bssid'], cur['bssid'])\n",
    "            union = np.union1d(prev['bssid'], cur['bssid'])\n",
    "            w = np.repeat(1 / len(intersect), len(intersect)) if len(intersect) else 1.0\n",
    "            prev_intersect = prev.loc[\n",
    "                lambda x: x['bssid'].isin(intersect), :\n",
    "            ].sort_values('bssid')\n",
    "            cur_intersect = cur.loc[\n",
    "                lambda x: x['bssid'].isin(intersect), :\n",
    "            ].sort_values('bssid')\n",
    "            prev_rssi = prev_intersect['rssi']\n",
    "            cur_rssi = cur_intersect['rssi']\n",
    "\n",
    "            new_data.append(dict(\n",
    "                pcode=pcode,\n",
    "                timestamp=cur_t,\n",
    "                cosine=1 - dist.cosine(prev_rssi, cur_rssi) if len(intersect) > 0 else 0,\n",
    "                euclidean=1 / (1 + dist.euclidean(prev_rssi, cur_rssi, w)) if len(intersect) > 0 else 0,\n",
    "                manhattan=1 / (1 + dist.cityblock(prev_rssi, cur_rssi, w)) if len(intersect) > 0 else 0,\n",
    "                jaccard = len(intersect) / len(union) if len(union) > 0 else 0\n",
    "            ))\n",
    "            \n",
    "    new_data = pd.DataFrame(new_data).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'COS': new_data['cosine'].astype('float32'),\n",
    "        'EUC': new_data['euclidean'].astype('float32'),\n",
    "        'MAN': new_data['manhattan'].astype('float32'),\n",
    "        'JAC': new_data['jaccard'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# InstalledApp.csv\n",
    "def _proc_installed_app(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "    \n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(axis=0, level='timestamp')\n",
    "        t = sub.index.unique().array\n",
    "        for cur_t, prev_t in zip(t, t.shift(1)):\n",
    "            if cur_t is pd.NaT or prev_t is pd.NaT:\n",
    "                continue\n",
    "\n",
    "            prev = sub.loc[[prev_t], :]\n",
    "            cur = sub.loc[[cur_t], :]\n",
    "            intersect = np.intersect1d(prev['packageName'], cur['packageName'])\n",
    "            union = np.union1d(prev['packageName'], cur['packageName'])\n",
    "            new_data.append(dict(\n",
    "                pcode=pcode,\n",
    "                timestamp=cur_t,\n",
    "                jaccard = len(intersect) / len(union) if len(union) > 0 else 0\n",
    "            ))\n",
    "            \n",
    "    new_data = pd.DataFrame(new_data).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "       'JAC': new_data['jaccard'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "#MediaEvent.csv\n",
    "def _proc_media_event(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = defaultdict(list)\n",
    "    \n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        )\n",
    "\n",
    "        video = sub.loc[\n",
    "            lambda x: x['mimetype'].str.startswith('video'), :\n",
    "        ].assign(\n",
    "            event=1,\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        image = sub.loc[\n",
    "            lambda x: x['mimetype'].str.startswith('image'), :\n",
    "        ].assign(\n",
    "            event=1,\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        media = sub.assign(\n",
    "            event=1,\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data['VID'].append(video)\n",
    "        new_data['IMG'].append(image)\n",
    "        new_data['ALL'].append(media)\n",
    "\n",
    "    return {\n",
    "        k: pd.concat(\n",
    "            v, axis=0, ignore_index=True\n",
    "        ).set_index(\n",
    "            ['pcode', 'timestamp']\n",
    "        )['event'].astype('float32') \n",
    "        for k, v in new_data.items()\n",
    "    }\n",
    "\n",
    "\n",
    "# MessageEvent.csv\n",
    "def _proc_message_event(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = defaultdict(list)\n",
    "    \n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        )\n",
    "\n",
    "        sent = sub.loc[\n",
    "            lambda x: x['messageBox'] == 'SENT', :\n",
    "        ].assign(\n",
    "            event=1,\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        recv = sub.loc[\n",
    "            lambda x: x['messageBox'] == 'INBOX', :\n",
    "        ].assign(\n",
    "            event=1,\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        msg = sub.assign(\n",
    "            event=1,\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data['SNT'].append(sent)\n",
    "        new_data['RCV'].append(recv)\n",
    "        new_data['ALL'].append(msg)\n",
    "\n",
    "    return {\n",
    "        k: pd.concat(\n",
    "            v, axis=0, ignore_index=True\n",
    "        ).set_index(\n",
    "            ['pcode', 'timestamp']\n",
    "        )['event'].astype('float32') \n",
    "        for k, v in new_data.items()\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# UltraViolet.csv\n",
    "def _proc_ultra_violet(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "    \n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            exposure=lambda x: (x['totalExposure'] - x['totalExposure'].shift(1)),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'INT': new_data['intensity'].astype('object'),\n",
    "        'EXP': new_data['exposure'].dropna().astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AmbientLight.csv\n",
    "def _proc_ambient_light(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    return data['brightness'].astype('float32')\n",
    "    \n",
    "\n",
    "# StepCount.csv\n",
    "def _proc_step_count(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            steps=lambda x: (x['totalSteps'] - x['totalSteps'].shift(1)),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return new_data['steps'].dropna().astype('float32')\n",
    "    \n",
    "\n",
    "\n",
    "# Acceleration.csv\n",
    "def _proc_acceleration(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data = data.assign(\n",
    "        mag=lambda x: np.sqrt(np.square(x['x']) + np.square(x['y']) + np.square(x['z']))\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'AXX': data['x'].astype('float32'),\n",
    "        'AXY': data['y'].astype('float32'),\n",
    "        'AXZ': data['z'].astype('float32'),\n",
    "        'MAG': data['mag'].astype('float32')\n",
    "    }\n",
    "\n",
    "# SkinTemperature.csv\n",
    "def _proc_skin_temperature(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    temperature = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['temperature'] = trim_outlier(v['temperature'], threshold=3.0)\n",
    "        v= v[~v['temperature'].isnull()]\n",
    "        # Z-score normalize column 'temperature'\n",
    "#         v['temperature'] = (v['temperature'] - v['temperature'].mean()) / v['temperature'].std()\n",
    "        temperature.append(v)\n",
    "\n",
    "    temperature = pd.concat(temperature, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    \n",
    "    return temperature['temperature'].astype('float32')\n",
    "\n",
    "\n",
    "# RRI.csv\n",
    "def _proc_rri(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    RRI = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['interval'] = trim_outlier(v['interval'], threshold=3.0)\n",
    "        v= v[~v['interval'].isnull()]\n",
    "        # Z-score normalize column 'interval'\n",
    "#         v['interval'] = (v['interval'] - v['interval'].mean()) / v['interval'].std()\n",
    "        RRI.append(v)\n",
    "\n",
    "    RRI = pd.concat(RRI, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    return RRI['interval'].astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# HR.csv\n",
    "def _proc_hr(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    data['bpm'] = data.loc[(data['bpm'] >= 30) | (data['bpm'] <= 220), 'bpm']\n",
    "    data= data[~data['bpm'].isnull()]\n",
    "    HRT = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "        v['bpm'] = trim_outlier(v['bpm'], threshold=3.0)\n",
    "        v= v[~v['bpm'].isnull()]\n",
    "        # Z-score normalize column 'bpm'\n",
    "#         v['bpm'] = (v['bpm'] - v['bpm'].mean()) / v['bpm'].std()\n",
    "        HRT.append(v)\n",
    "\n",
    "    HRT = pd.concat(HRT, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    return HRT['bpm'].astype('float32')\n",
    "    \n",
    "\n",
    "# EDA.csv\n",
    "def _proc_eda(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "\n",
    "    # Apply a median filter with a window size of window_size_sec seconds\n",
    "    window_size_sec = 5\n",
    "    window_size = window_size_sec * 2  # Multiply by the sampling frequency (2 Hz)\n",
    "\n",
    "   #Make the window size odd if it is even\n",
    "    if window_size % 2 == 0:\n",
    "        window_size += 1\n",
    "\n",
    "    data[\"conductance\"] = 1 / (data[\"resistance\"] / 1000) # divide by 1000 to convert k to \n",
    "    data['conductance'] =data.loc[(data['conductance'] >= 0.01) & (data['conductance'] <= 100), 'conductance']\n",
    "    data= data[~data['conductance'].isnull()]\n",
    "\n",
    "\n",
    "    eda = []\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        v = data.loc[(pcode, ), :].sort_index(axis=0,level='timestamp').assign(pcode=pcode)\n",
    "        v = v.reset_index()\n",
    "\n",
    "        eda_data = v['conductance'].to_numpy()\n",
    "        eda_data = medfilt(eda_data, window_size)\n",
    "        # Reshape to 2D with a single column\n",
    "#         eda_data = eda_data.reshape(-1, 1)\n",
    "        eda_data = eda_data.reshape(-1)\n",
    "        # assuming your data is a numpy array with shape (n_samples, n_features)\n",
    "#         scaler = MinMaxScaler()\n",
    "#         eda_data_scaled = scaler.fit_transform(eda_data)\n",
    "#         eda_data = scaler.inverse_transform(eda_data_scaled).reshape(-1)\n",
    "\n",
    "        v['conductance'] =eda_data\n",
    "        v= v[~v['conductance'].isnull()]\n",
    "\n",
    "        eda.append(v)\n",
    "\n",
    "    eda = pd.concat(eda, axis=0, ignore_index=True).set_index(\n",
    "                ['pcode', 'timestamp']\n",
    "            ) \n",
    "    \n",
    "    return eda['conductance'].astype('float32')\n",
    "\n",
    "\n",
    "# Distance.csv\n",
    "def _proc_distance(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            distance=lambda x: x['totalDistance'] - x['totalDistance'].shift(1),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'DST': new_data['distance'].dropna().astype('float32'),\n",
    "        'MOT': new_data['motionType'].astype('object'),\n",
    "        'PAC': new_data['pace'].astype('float32'),\n",
    "        'SPD': new_data['speed'].astype('float32')\n",
    "    }\n",
    "\n",
    "\n",
    "# Calorie.csv\n",
    "def _proc_calories(data: pd.DataFrame) -> Union[pd.Series, Dict[str, pd.Series]]:\n",
    "    new_data = []\n",
    "\n",
    "    for pcode in data.index.get_level_values('pcode').unique():\n",
    "        sub = data.loc[(pcode, ), :].sort_index(\n",
    "            axis=0, level='timestamp'\n",
    "        ).assign(\n",
    "            calories=lambda x: x['totalCalories'] - x['totalCalories'].shift(1),\n",
    "            pcode=pcode\n",
    "        ).reset_index()\n",
    "\n",
    "        new_data.append(sub)\n",
    "\n",
    "    new_data = pd.concat(new_data, axis=0, ignore_index=True).set_index(\n",
    "        ['pcode', 'timestamp']\n",
    "    )\n",
    "\n",
    "    return new_data['calories'].dropna().astype('float32')           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install poi-clustering==0.0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gc\n",
    "from functools import reduce\n",
    "import warnings\n",
    "from pandas.errors import PerformanceWarning\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=PerformanceWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "FUNC_PROC = {\n",
    "    'Acceleration': _proc_acceleration,\n",
    "    'AmbientLight': _proc_ambient_light,\n",
    "    'Calorie': _proc_calories,\n",
    "    'Distance': _proc_distance,\n",
    "    'EDA': _proc_eda,\n",
    "    'HR': _proc_hr,\n",
    "    'RRI': _proc_rri,\n",
    "    'SkinTemperature': _proc_skin_temperature,\n",
    "    'StepCount': _proc_step_count,\n",
    "    'UltraViolet': _proc_ultra_violet,\n",
    "    'ActivityEvent': _proc_activity_event,\n",
    "    'ActivityTransition': _proc_activity_transition,\n",
    "    'AppUsageEvent': _proc_app_usage,\n",
    "    'BatteryEvent': _proc_battery,\n",
    "    'CallEvent': _proc_call,\n",
    "    'Connectivity': _proc_connectivity,\n",
    "    'DataTraffic': _proc_data_traffic,\n",
    "    'InstalledApp': _proc_installed_app,\n",
    "    'Location': _proc_location,\n",
    "    'MediaEvent': _proc_media_event,\n",
    "    'MessageEvent': _proc_message_event,\n",
    "    'WiFi': _proc_wifi,\n",
    "    'ScreenEvent': _proc_screen,\n",
    "    'RingerModeEvent': _proc_ringer_mode,\n",
    "    'ChargeEvent': _proc_charge,\n",
    "    'PowerSaveEvent': _proc_power_save,\n",
    "    'OnOffEvent': _proc_on_off\n",
    "}\n",
    "\n",
    "\n",
    "def _process(data_type: str):\n",
    "    log(f'Begin to processing data: {data_type}')\n",
    "    \n",
    "    abbrev = DATA_TYPES[data_type]\n",
    "    data_raw = _load_data(data_type)\n",
    "    data_proc = FUNC_PROC[data_type](data_raw)\n",
    "    result = dict()\n",
    "    \n",
    "    if type(data_proc) is dict:\n",
    "        for k, v in data_proc.items():\n",
    "            result[f'{abbrev}_{k}'] = v\n",
    "    else:\n",
    "        result[abbrev] = data_proc\n",
    "        \n",
    "    log(f'Complete processing data: {data_type}')\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "#with on_ray(num_cpus=6):\n",
    "with on_ray():\n",
    "    jobs = []\n",
    "    \n",
    "    func = ray.remote(_process).remote\n",
    "    \n",
    "    for data_type in DATA_TYPES:\n",
    "        job = func(data_type)\n",
    "        jobs.append(job)\n",
    "\n",
    "    jobs = ray.get(jobs)\n",
    "    jobs = reduce(lambda a, b: {**a, **b}, jobs)\n",
    "    dump(jobs, os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "\n",
    "    del jobs\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ACC_AXX #####\n",
      "- # Inst.: {'n': 77, 'sum': 123260001, 'mean': 1600779.2337662338, 'SD': 473426.34254662704, 'med': 1616756.0, 'range': (489289, 2464554), 'conf.': (1493324.634822134, 1708233.8327103336), 'nan_count': 0}\n",
      "- Samp. period: {'n': 123259924, 'sum': 41213652.71599994, 'mean': 0.33436376868121337, 'SD': 113.32762322571338, 'med': 0.13, 'range': (0.001, 347544.66), 'conf.': (0.3143571853179482, 0.35437035204447853), 'nan_count': 0}\n",
      "- Values: {'n': 123260001, 'sum': -5999699.5, 'mean': -0.048675153, 'SD': 0.6191499, 'med': -0.06616211, 'range': (-7.995117, 7.999756), 'conf.': (-0.048784456594055885, -0.04856585021489263), 'nan_count': 0}\n",
      "\n",
      "##### ACC_AXY #####\n",
      "- # Inst.: {'n': 77, 'sum': 123260001, 'mean': 1600779.2337662338, 'SD': 473426.34254662704, 'med': 1616756.0, 'range': (489289, 2464554), 'conf.': (1493324.634822134, 1708233.8327103336), 'nan_count': 0}\n",
      "- Samp. period: {'n': 123259924, 'sum': 41213652.71599994, 'mean': 0.33436376868121337, 'SD': 113.32762322571338, 'med': 0.13, 'range': (0.001, 347544.66), 'conf.': (0.3143571853179482, 0.35437035204447853), 'nan_count': 0}\n",
      "- Values: {'n': 123260001, 'sum': 21869622.0, 'mean': 0.17742676, 'SD': 0.57513875, 'med': 0.22387695, 'range': (-7.995117, 7.9990234), 'conf.': (0.1773252218623611, 0.1775282889942673), 'nan_count': 0}\n",
      "\n",
      "##### ACC_AXZ #####\n",
      "- # Inst.: {'n': 77, 'sum': 123260001, 'mean': 1600779.2337662338, 'SD': 473426.34254662704, 'med': 1616756.0, 'range': (489289, 2464554), 'conf.': (1493324.634822134, 1708233.8327103336), 'nan_count': 0}\n",
      "- Samp. period: {'n': 123259924, 'sum': 41213652.71599994, 'mean': 0.33436376868121337, 'SD': 113.32762322571338, 'med': 0.13, 'range': (0.001, 347544.66), 'conf.': (0.3143571853179482, 0.35437035204447853), 'nan_count': 0}\n",
      "- Values: {'n': 123260001, 'sum': 27721322.0, 'mean': 0.2249012, 'SD': 0.5024594, 'med': 0.21386719, 'range': (-8.0, 7.9990234), 'conf.': (0.22481249640517365, 0.22498990227646698), 'nan_count': 0}\n",
      "\n",
      "##### ACC_MAG #####\n",
      "- # Inst.: {'n': 77, 'sum': 123260001, 'mean': 1600779.2337662338, 'SD': 473426.34254662704, 'med': 1616756.0, 'range': (489289, 2464554), 'conf.': (1493324.634822134, 1708233.8327103336), 'nan_count': 0}\n",
      "- Samp. period: {'n': 123259924, 'sum': 41213652.71599994, 'mean': 0.33436376868121337, 'SD': 113.32762322571338, 'med': 0.13, 'range': (0.001, 347544.66), 'conf.': (0.3143571853179482, 0.35437035204447853), 'nan_count': 0}\n",
      "- Values: {'n': 123260001, 'sum': 125006250.0, 'mean': 1.0141672, 'SD': 0.1499644, 'med': 1.0013473, 'range': (0.0061859665, 13.854715), 'conf.': (1.014140715254147, 1.01419366394202), 'nan_count': 0}\n",
      "\n",
      "##### AML #####\n",
      "- # Inst.: {'n': 77, 'sum': 31948974, 'mean': 414921.74025974027, 'SD': 122176.94279182944, 'med': 416936.0, 'range': (125402, 643940), 'conf.': (387190.9758132746, 442652.5047062059), 'nan_count': 0}\n",
      "- Samp. period: {'n': 31948897, 'sum': 41213635.991999924, 'mean': 1.2899861923871714, 'SD': 222.607981838843, 'med': 0.5, 'range': (0.001, 347544.869), 'conf.': (1.2127962165083053, 1.3671761682660375), 'nan_count': 0}\n",
      "- Values: {'n': 31948974, 'sum': 11939903000.0, 'mean': 373.7179, 'SD': 2573.6665, 'med': 39.0, 'range': (0.0, 65535.0), 'conf.': (372.8254701135408, 374.6103209020842), 'nan_count': 0}\n",
      "\n",
      "##### CAL #####\n",
      "- # Inst.: {'n': 77, 'sum': 15601437, 'mean': 202616.06493506493, 'SD': 59660.549453893436, 'med': 203675.0, 'range': (61196, 314215), 'conf.': (189074.78123744018, 216157.34863268968), 'nan_count': 0}\n",
      "- Samp. period: {'n': 15601360, 'sum': 41213462.12199992, 'mean': 2.641658299148274, 'SD': 318.55899283864454, 'med': 1.025, 'range': (0.001, 347545.58), 'conf.': (2.4835856378177157, 2.7997309604788327), 'nan_count': 0}\n",
      "- Values: {'n': 15601437, 'sum': 728224.0, 'mean': 0.046676725, 'SD': 4.0165553, 'med': 0.0, 'range': (0.0, 1468.0), 'conf.': (0.04468366880914382, 0.04866978148916551), 'nan_count': 0}\n",
      "\n",
      "##### DST_DST #####\n",
      "- # Inst.: {'n': 77, 'sum': 15658384, 'mean': 203355.63636363635, 'SD': 64968.13128573705, 'med': 206891.0, 'range': (30, 319156), 'conf.': (188609.67936026378, 218101.59336700893), 'nan_count': 0}\n",
      "- Samp. period: {'n': 15658307, 'sum': 41209556.30000211, 'mean': 2.6318015287350103, 'SD': 318.24679499959257, 'med': 1.009000192, 'range': (0.000999936, 347546.808999936), 'conf.': (2.4741712072099538, 2.789431850260067), 'nan_count': 0}\n",
      "- Values: {'n': 15658384, 'sum': 223762060.0, 'mean': 14.29024, 'SD': 547.05695, 'med': 0.0, 'range': (0.0, 704408.0), 'conf.': (14.019279035101407, 14.561201540460116), 'nan_count': 0}\n",
      "\n",
      "##### DST_MOT #####\n",
      "- # Inst.: {'n': 77, 'sum': 15658461, 'mean': 203356.63636363635, 'SD': 64968.13128573705, 'med': 206892.0, 'range': (31, 319157), 'conf.': (188610.67936026378, 218102.59336700893), 'nan_count': 0}\n",
      "- Values: {'n': 15658461, 'cardinality': 4, 'value_count': 'IDLE:14312951, WALKING:1312097, JOGGING:33213, RUNNING:200'}\n",
      "\n",
      "##### DST_PAC #####\n",
      "- # Inst.: {'n': 77, 'sum': 15658461, 'mean': 203356.63636363635, 'SD': 64968.13128573705, 'med': 206892.0, 'range': (31, 319157), 'conf.': (188610.67936026378, 218102.59336700893), 'nan_count': 0}\n",
      "- Samp. period: {'n': 15658384, 'sum': 41219633.3800005, 'mean': 2.632432144977445, 'SD': 318.2560407682013, 'med': 1.009000192, 'range': (0.000999936, 347546.808999936), 'conf.': (2.474797631530051, 2.7900666584248386), 'nan_count': 0}\n",
      "- Values: {'n': 15658461, 'sum': 1729413100.0, 'mean': 110.44592, 'SD': 366.63028, 'med': 0.0, 'range': (0.0, 3225.0), 'conf.': (110.2643286750883, 110.6275170280367), 'nan_count': 0}\n",
      "\n",
      "##### DST_SPD #####\n",
      "- # Inst.: {'n': 77, 'sum': 15658461, 'mean': 203356.63636363635, 'SD': 64968.13128573705, 'med': 206892.0, 'range': (31, 319157), 'conf.': (188610.67936026378, 218102.59336700893), 'nan_count': 0}\n",
      "- Samp. period: {'n': 15658384, 'sum': 41219633.3800005, 'mean': 2.632432144977445, 'SD': 318.2560407682013, 'med': 1.009000192, 'range': (0.000999936, 347546.808999936), 'conf.': (2.474797631530051, 2.7900666584248386), 'nan_count': 0}\n",
      "- Values: {'n': 15658461, 'sum': 187088180.0, 'mean': 11.948056, 'SD': 36.67668, 'med': 0.0, 'range': (0.0, 695.0), 'conf.': (11.929890040668512, 11.96622240134809), 'nan_count': 0}\n",
      "\n",
      "##### EDA #####\n",
      "- # Inst.: {'n': 77, 'sum': 67394745, 'mean': 875256.4285714285, 'SD': 273225.3772774521, 'med': 896350.0, 'range': (85472, 1351680), 'conf.': (813241.8748844261, 937270.9822584309), 'nan_count': 0}\n",
      "- Samp. period: {'n': 67394668, 'sum': 40989170.088999934, 'mean': 0.6081960384314072, 'SD': 161.94256711971843, 'med': 0.199, 'range': (0.001, 353032.812), 'conf.': (0.569532967238612, 0.6468591096242025), 'nan_count': 0}\n",
      "- Values: {'n': 67394745, 'sum': 111476456.0, 'mean': 1.6540823, 'SD': 1.9634264, 'med': 0.984252, 'range': (0.010111019, 52.63158), 'conf.': (1.6536135391946702, 1.654551057362947), 'nan_count': 0}\n",
      "\n",
      "##### HRT #####\n",
      "- # Inst.: {'n': 77, 'sum': 12159285, 'mean': 157912.7922077922, 'SD': 47479.122599566595, 'med': 164497.0, 'range': (35256, 249247), 'conf.': (147136.35325910462, 168689.23115647977), 'nan_count': 0}\n",
      "- Samp. period: {'n': 12159208, 'sum': 40967080.97200004, 'mean': 3.369222812209483, 'SD': 384.19542551752625, 'med': 0.996, 'range': (0.001, 351692.576), 'conf.': (3.1532755611693113, 3.5851700632496546), 'nan_count': 0}\n",
      "- Values: {'n': 12159285, 'sum': 908401300.0, 'mean': 74.70844, 'SD': 7.2163944, 'med': 74.0, 'range': (49.0, 107.0), 'conf.': (74.70438653452933, 74.71249884144723), 'nan_count': 0}\n",
      "\n",
      "##### RRI #####\n",
      "- # Inst.: {'n': 77, 'sum': 18763555, 'mean': 243682.53246753247, 'SD': 74235.45597527831, 'med': 251298.0, 'range': (74879, 418195), 'conf.': (226833.15077418007, 260531.91416088486), 'nan_count': 0}\n",
      "- Samp. period: {'n': 18763478, 'sum': 41177652.52699998, 'mean': 2.1945639570126594, 'SD': 290.5577303431614, 'med': 0.775, 'range': (0.001, 347549.243), 'conf.': (2.0630947987762434, 2.3260331152490754), 'nan_count': 0}\n",
      "- Values: {'n': 18763555, 'sum': 14224239000.0, 'mean': 758.078, 'SD': 140.68759, 'med': 763.232, 'range': (298.656, 1310.768), 'conf.': (758.0143459026909, 758.1416599566841), 'nan_count': 0}\n",
      "\n",
      "##### SKT #####\n",
      "- # Inst.: {'n': 77, 'sum': 494548, 'mean': 6422.701298701299, 'SD': 1941.5402056434139, 'med': 6569.0, 'range': (1731, 9861), 'conf.': (5982.025727061111, 6863.376870341486), 'nan_count': 0}\n",
      "- Samp. period: {'n': 494471, 'sum': 41081740.981, 'mean': 83.08220498472105, 'SD': 1817.4598946050305, 'med': 30.082, 'range': (0.006, 347580.739), 'conf.': (78.01645703539607, 88.14795293404602), 'nan_count': 0}\n",
      "- Values: {'n': 494548, 'sum': 16131178.0, 'mean': 32.618023, 'SD': 1.5108176, 'med': 32.77, 'range': (25.49, 37.16), 'conf.': (32.61381219274048, 32.62223364466186), 'nan_count': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### STP #####\n",
      "- # Inst.: {'n': 77, 'sum': 15848379, 'mean': 205823.1038961039, 'SD': 60607.39763375781, 'med': 206902.0, 'range': (62163, 319174), 'conf.': (192066.91202315246, 219579.29576905532), 'nan_count': 0}\n",
      "- Samp. period: {'n': 15848302, 'sum': 41213448.95900005, 'mean': 2.600496189370953, 'SD': 316.0718354069503, 'med': 1.009, 'range': (0.001, 347546.809), 'conf.': (2.4448843796869193, 2.7561079990549864), 'nan_count': 0}\n",
      "- Values: {'n': 15848379, 'sum': 2924804.0, 'mean': 0.1845491, 'SD': 6.332922, 'med': 0.0, 'range': (0.0, 8796.0), 'conf.': (0.18143121007628105, 0.18766697641663888), 'nan_count': 0}\n",
      "\n",
      "##### ULV_INT #####\n",
      "- # Inst.: {'n': 77, 'sum': 264692, 'mean': 3437.5584415584417, 'SD': 1017.6239287455036, 'med': 3495.0, 'range': (1044, 5373), 'conf.': (3206.5861417259757, 3668.5307413909077), 'nan_count': 0}\n",
      "- Values: {'n': 264692, 'cardinality': 4, 'value_count': 'NONE:260364, LOW:4301, MEDIUM:26, HIGH:1'}\n",
      "\n",
      "##### ULV_EXP #####\n",
      "- # Inst.: {'n': 77, 'sum': 264615, 'mean': 3436.5584415584417, 'SD': 1017.6239287455036, 'med': 3494.0, 'range': (1043, 5372), 'conf.': (3205.5861417259757, 3667.5307413909077), 'nan_count': 0}\n",
      "- Samp. period: {'n': 264538, 'sum': 41069430.691, 'mean': 155.24964538554008, 'SD': 2474.243660853903, 'med': 59.998, 'range': (0.012, 347610.692), 'conf.': (145.8210171649021, 164.67827360617807), 'nan_count': 0}\n",
      "- Values: {'n': 264615, 'sum': 33120000.0, 'mean': 125.16297, 'SD': 2961.9224, 'med': 0.0, 'range': (0.0, 300000.0), 'conf.': (113.877582879293, 136.44836011387108), 'nan_count': 0}\n",
      "\n",
      "##### ACE_UNK #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 77627.03, 'mean': 0.0905338, 'SD': 0.15446506, 'med': 0.01, 'range': (0.0, 1.0), 'conf.': (0.09020685304139024, 0.09086074780490035), 'nan_count': 0}\n",
      "\n",
      "##### ACE_FOT #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 141488.58, 'mean': 0.16501339, 'SD': 0.30429167, 'med': 0.01, 'range': (0.0, 1.0), 'conf.': (0.16436931100607285, 0.16565746459245315), 'nan_count': 0}\n",
      "\n",
      "##### ACE_WLK #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 140625.14, 'mean': 0.16400638, 'SD': 0.30332258, 'med': 0.01, 'range': (0.0, 1.0), 'conf.': (0.16336435663453572, 0.16464840781935222), 'nan_count': 0}\n",
      "\n",
      "##### ACE_VHC #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 73268.586, 'mean': 0.085450694, 'SD': 0.18684648, 'med': 0.01, 'range': (0.0, 1.0), 'conf.': (0.08505520669029926, 0.08584618123961713), 'nan_count': 0}\n",
      "\n",
      "##### ACE_BCC #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 35811.67, 'mean': 0.04176595, 'SD': 0.11612063, 'med': 0.0, 'range': (0.0, 1.0), 'conf.': (0.04152016471532068, 0.04201173652502813), 'nan_count': 0}\n",
      "\n",
      "##### ACE_RUN #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 18982.562, 'mean': 0.022138726, 'SD': 0.046682358, 'med': 0.0, 'range': (0.0, 1.0), 'conf.': (0.02203991608508362, 0.022237535847346647), 'nan_count': 0}\n",
      "\n",
      "##### ACE_TLT #####\n",
      "- # Inst.: {'n': 77, 'sum': 857437, 'mean': 11135.545454545454, 'SD': 4325.836148396645, 'med': 11085.0, 'range': (2640, 22938), 'conf.': (10153.701085845014, 12117.389823245894), 'nan_count': 0}\n",
      "- Samp. period: {'n': 857360, 'sum': 43179845.23399999, 'mean': 50.363727295418485, 'SD': 631.3182326494627, 'med': 15.19, 'range': (0.001, 260838.132), 'conf.': (49.02739203647505, 51.70006255436192), 'nan_count': 0}\n",
      "- Values: {'n': 857437, 'sum': 98346.0, 'mean': 0.11469764, 'SD': 0.31865692, 'med': 0.0, 'range': (0.0, 1.0), 'conf.': (0.11402315971443419, 0.11537212553432222), 'nan_count': 0}\n",
      "\n",
      "##### ACT #####\n",
      "- # Inst.: {'n': 77, 'sum': 25508, 'mean': 331.27272727272725, 'SD': 172.48910235322697, 'med': 304.0, 'range': (116, 1197), 'conf.': (292.1225033627252, 370.4229511827293), 'nan_count': 0}\n",
      "- Values: {'n': 25508, 'cardinality': 5, 'value_count': 'WALKING:11151, STILL:10419, IN_VEHICLE:2441, ON_BICYCLE:1169, RUNNING:328'}\n",
      "\n",
      "##### APP_DUR_UNKNOWN #####\n",
      "- # Inst.: {'n': 77, 'sum': 612855, 'mean': 7959.1558441558445, 'SD': 3265.5557279328627, 'med': 7189.0, 'range': (2357, 16399), 'conf.': (7217.965611294912, 8700.346077016777), 'nan_count': 0}\n",
      "- Samp. period: {'n': 612778, 'sum': 43303088.65800001, 'mean': 70.66684616288445, 'SD': 812.1328565465413, 'med': 2.543, 'range': (0.008, 260988.448), 'conf.': (68.63343853880266, 72.70025378696624), 'nan_count': 0}\n",
      "- Values: {'n': 612855, 'sum': 11928188.0, 'mean': 19.463312, 'SD': 297.71707, 'med': 2.031, 'range': (0.001, 181324.3), 'conf.': (18.717938868770887, 20.208685429324817), 'nan_count': 0}\n",
      "\n",
      "##### APP_DUR_SOCIAL #####\n",
      "- # Inst.: {'n': 77, 'sum': 308555, 'mean': 4007.2077922077924, 'SD': 2339.446652622111, 'med': 2996.0, 'range': (685, 10744), 'conf.': (3476.2185353438963, 4538.1970490716885), 'nan_count': 0}\n",
      "- Samp. period: {'n': 308478, 'sum': 42914996.35999999, 'mean': 139.11849908259256, 'SD': 1317.9400759909304, 'med': 2.913, 'range': (0.009, 260997.634), 'conf.': (134.46763807119726, 143.76936009398787), 'nan_count': 0}\n",
      "- Values: {'n': 308555, 'sum': 6784603.0, 'mean': 21.98831, 'SD': 701.8823, 'med': 0.028, 'range': (0.001, 260988.4), 'conf.': (19.51175583743537, 24.464863883023614), 'nan_count': 0}\n",
      "\n",
      "##### APP_DUR_SYSTEM #####\n",
      "- # Inst.: {'n': 77, 'sum': 169689, 'mean': 2203.753246753247, 'SD': 879.2654403691059, 'med': 2117.0, 'range': (732, 5912), 'conf.': (2004.1844716993655, 2403.3220218071283), 'nan_count': 0}\n",
      "- Samp. period: {'n': 169612, 'sum': 43187824.658999994, 'mean': 254.62717649105014, 'SD': 1612.9293401831392, 'med': 17.549500000000002, 'range': (0.009, 261125.782), 'conf.': (246.95111854263308, 262.3032344394672), 'nan_count': 0}\n",
      "- Values: {'n': 169689, 'sum': 16234803.0, 'mean': 95.67387, 'SD': 925.4963, 'med': 0.036, 'range': (0.001, 43850.62), 'conf.': (91.27035594039333, 100.07737660355198), 'nan_count': 0}\n",
      "\n",
      "##### APP_DUR_HEALTH #####\n",
      "- # Inst.: {'n': 77, 'sum': 42659, 'mean': 554.012987012987, 'SD': 560.6612518293042, 'med': 391.0, 'range': (84, 3146), 'conf.': (426.7584923966859, 681.267481629288), 'nan_count': 0}\n",
      "- Samp. period: {'n': 42582, 'sum': 41517428.013000004, 'mean': 974.9994836550657, 'SD': 4897.08354568806, 'med': 11.773499999999999, 'range': (0.016, 263883.138), 'conf.': (928.4853516043344, 1021.513615705797), 'nan_count': 0}\n",
      "- Values: {'n': 42659, 'sum': 2584181.2, 'mean': 60.577633, 'SD': 475.0941, 'med': 0.039, 'range': (0.002, 21147.51), 'conf.': (56.069105617507226, 65.08616019059825), 'nan_count': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### APP_DUR_ENTER #####\n",
      "- # Inst.: {'n': 77, 'sum': 36453, 'mean': 473.4155844155844, 'SD': 395.2068196277059, 'med': 319.0, 'range': (14, 2132), 'conf.': (383.71463943936385, 563.116529391805), 'nan_count': 0}\n",
      "- Samp. period: {'n': 36376, 'sum': 41768602.328, 'mean': 1148.2461603254894, 'SD': 5811.97783815336, 'med': 23.566000000000003, 'range': (0.022, 277304.547), 'conf.': (1088.5180161034461, 1207.9743045475327), 'nan_count': 0}\n",
      "- Values: {'n': 36453, 'sum': 2335370.0, 'mean': 64.06523, 'SD': 756.2654, 'med': 0.048, 'range': (0.001, 63777.387), 'conf.': (56.30150720754747, 71.8289554389369), 'nan_count': 0}\n",
      "\n",
      "##### APP_DUR_INFO #####\n",
      "- # Inst.: {'n': 76, 'sum': 32210, 'mean': 423.8157894736842, 'SD': 507.7195475332503, 'med': 245.5, 'range': (12, 2255), 'conf.': (307.79690291401306, 539.8346760333554), 'nan_count': 0}\n",
      "- Samp. period: {'n': 32134, 'sum': 38745227.595, 'mean': 1205.7393289039646, 'SD': 7456.57857296946, 'med': 10.771, 'range': (0.014, 315231.609), 'conf.': (1124.208538258819, 1287.2701195491102), 'nan_count': 0}\n",
      "- Values: {'n': 32210, 'sum': 1859898.8, 'mean': 57.742897, 'SD': 575.1806, 'med': 0.05, 'range': (0.002, 32832.87), 'conf.': (51.46125359990011, 64.0245404674827), 'nan_count': 0}\n",
      "\n",
      "##### APP_DUR_WORK #####\n",
      "- # Inst.: {'n': 77, 'sum': 23238, 'mean': 301.7922077922078, 'SD': 259.6424331583289, 'med': 237.0, 'range': (44, 1893), 'conf.': (242.86060425316165, 360.723811331254), 'nan_count': 0}\n",
      "- Samp. period: {'n': 23161, 'sum': 40193398.855000004, 'mean': 1735.3913412633308, 'SD': 8831.553028332115, 'med': 6.77, 'range': (0.011, 317108.112), 'conf.': (1621.6471529399803, 1849.1355295866813), 'nan_count': 0}\n",
      "- Values: {'n': 23238, 'sum': 1577057.0, 'mean': 67.86543, 'SD': 692.17664, 'med': 0.042, 'range': (0.002, 28987.441), 'conf.': (58.965468224645136, 76.76539725387049), 'nan_count': 0}\n",
      "\n",
      "##### APP_CAT #####\n",
      "- # Inst.: {'n': 77, 'sum': 1229259, 'mean': 15964.402597402597, 'SD': 6533.851266692281, 'med': 14379.0, 'range': (4715, 32800), 'conf.': (14481.400270903054, 17447.40492390214), 'nan_count': 0}\n",
      "- Values: {'n': 1229259, 'cardinality': 7, 'value_count': 'UNKNOWN:614333, SOCIAL:309427, SYSTEM:170106, HEALTH:42703, ENTER:36554, INFO:32868, WORK:23268'}\n",
      "\n",
      "##### BAT_LEV #####\n",
      "- # Inst.: {'n': 77, 'sum': 1160326, 'mean': 15069.16883116883, 'SD': 7677.663567303528, 'med': 12795.0, 'range': (2872, 42124), 'conf.': (13326.552957674054, 16811.784704663605), 'nan_count': 0}\n",
      "- Samp. period: {'n': 1160249, 'sum': 43417685.226999976, 'mean': 37.4210063762175, 'SD': 425.26809182747127, 'med': 10.168, 'range': (0.001, 261248.657), 'conf.': (36.64719387577137, 38.194818876663625), 'nan_count': 0}\n",
      "- Values: {'n': 1160326, 'sum': 73058440.0, 'mean': 62.96372, 'SD': 28.00724, 'med': 66.0, 'range': (0.0, 100.0), 'conf.': (62.91275848114728, 63.014678347466), 'nan_count': 0}\n",
      "\n",
      "##### BAT_STA #####\n",
      "- # Inst.: {'n': 77, 'sum': 1160326, 'mean': 15069.16883116883, 'SD': 7677.663567303528, 'med': 12795.0, 'range': (2872, 42124), 'conf.': (13326.552957674054, 16811.784704663605), 'nan_count': 0}\n",
      "- Values: {'n': 1160326, 'cardinality': 4, 'value_count': 'CHARGING:651709, DISCHARGING:423437, FULL:81850, NOT_CHARGING:3330'}\n",
      "\n",
      "##### BAT_TMP #####\n",
      "- # Inst.: {'n': 77, 'sum': 1160326, 'mean': 15069.16883116883, 'SD': 7677.663567303528, 'med': 12795.0, 'range': (2872, 42124), 'conf.': (13326.552957674054, 16811.784704663605), 'nan_count': 0}\n",
      "- Samp. period: {'n': 1160249, 'sum': 43417685.226999976, 'mean': 37.4210063762175, 'SD': 425.26809182747127, 'med': 10.168, 'range': (0.001, 261248.657), 'conf.': (36.64719387577137, 38.194818876663625), 'nan_count': 0}\n",
      "- Values: {'n': 1160326, 'sum': 37831990.0, 'mean': 32.60462, 'SD': 4.1624484, 'med': 32.7, 'range': (9.7, 81.3), 'conf.': (32.59704819946333, 32.61219557495073), 'nan_count': 0}\n",
      "\n",
      "##### CAE_DUR #####\n",
      "- # Inst.: {'n': 62, 'sum': 766, 'mean': 12.35483870967742, 'SD': 12.462529772651086, 'med': 8.5, 'range': (1, 61), 'conf.': (9.1899487514926, 15.519728667862239), 'nan_count': 0}\n",
      "- Samp. period: {'n': 704, 'sum': 15115419.07, 'mean': 21470.765724431818, 'SD': 39403.519431867004, 'med': 5897.8225, 'range': (12.695, 344362.143), 'conf.': (18555.050342865878, 24386.48110599776), 'nan_count': 0}\n",
      "- Values: {'n': 766, 'sum': 62122000.0, 'mean': 81099.22, 'SD': 150926.19, 'med': 38000.0, 'range': (1000.0, 1963000.0), 'conf.': (70394.23620735909, 91804.20129264091), 'nan_count': 0}\n",
      "\n",
      "##### CAE_CNT #####\n",
      "- # Inst.: {'n': 62, 'sum': 766, 'mean': 12.35483870967742, 'SD': 12.462529772651086, 'med': 8.5, 'range': (1, 61), 'conf.': (9.1899487514926, 15.519728667862239), 'nan_count': 0}\n",
      "- Samp. period: {'n': 704, 'sum': 15115419.07, 'mean': 21470.765724431818, 'SD': 39403.519431867004, 'med': 5897.8225, 'range': (12.695, 344362.143), 'conf.': (18555.050342865878, 24386.48110599776), 'nan_count': 0}\n",
      "- Values: {'n': 766, 'sum': 5401, 'mean': 7.050913838120104, 'SD': 29.787899775244604, 'med': 1.0, 'range': (0, 350), 'conf.': (4.938099936450915, 9.163727739789294), 'nan_count': 0}\n",
      "\n",
      "##### CON #####\n",
      "- # Inst.: {'n': 77, 'sum': 40304, 'mean': 523.4285714285714, 'SD': 352.0607538992243, 'med': 472.0, 'range': (39, 1686), 'conf.': (443.5205821293222, 603.3365607278207), 'nan_count': 0}\n",
      "- Values: {'n': 40304, 'cardinality': 3, 'value_count': 'DISCONNECTED:31289, WIFI:8553, MOBILE:462'}\n",
      "\n",
      "##### DAT_RCV #####\n",
      "- # Inst.: {'n': 77, 'sum': 692935, 'mean': 8999.155844155845, 'SD': 3664.6841935630578, 'med': 8428.0, 'range': (1584, 19668), 'conf.': (8167.374561859926, 9830.937126451763), 'nan_count': 0}\n",
      "- Samp. period: {'n': 692858, 'sum': 43067429.30399998, 'mean': 62.15909941719657, 'SD': 807.6512193118494, 'med': 15.033, 'range': (11.534, 261869.448), 'conf.': (60.257361853764074, 64.06083698062906), 'nan_count': 0}\n",
      "- Values: {'n': 692935, 'sum': 937801800.0, 'mean': 1353.3762, 'SD': 9590.346, 'med': 40.0, 'range': (0.0, 847233.0), 'conf.': (1330.7955486666247, 1375.9568927396253), 'nan_count': 0}\n",
      "\n",
      "##### DAT_SNT #####\n",
      "- # Inst.: {'n': 77, 'sum': 692935, 'mean': 8999.155844155845, 'SD': 3664.6841935630578, 'med': 8428.0, 'range': (1584, 19668), 'conf.': (8167.374561859926, 9830.937126451763), 'nan_count': 0}\n",
      "- Samp. period: {'n': 692858, 'sum': 43067429.30399998, 'mean': 62.15909941719657, 'SD': 807.6512193118494, 'med': 15.033, 'range': (11.534, 261869.448), 'conf.': (60.257361853764074, 64.06083698062906), 'nan_count': 0}\n",
      "- Values: {'n': 692935, 'sum': 186407140.0, 'mean': 269.011, 'SD': 8837.798, 'med': 11.0, 'range': (0.0, 844800.0), 'conf.': (248.2022041435586, 289.8197685126914), 'nan_count': 0}\n",
      "\n",
      "##### INS_JAC #####\n",
      "- # Inst.: {'n': 77, 'sum': 3839, 'mean': 49.857142857142854, 'SD': 9.046247092920103, 'med': 52.0, 'range': (12, 55), 'conf.': (47.80389662650409, 51.91038908778162), 'nan_count': 0}\n",
      "- Samp. period: {'n': 3762, 'sum': 41897818.849, 'mean': 11137.112931685273, 'SD': 6717.757339781898, 'med': 10810.0215, 'range': (10800.001, 271385.388), 'conf.': (10922.377952792569, 11351.847910577977), 'nan_count': 0}\n",
      "- Values: {'n': 3839, 'sum': 3834.7275, 'mean': 0.99888706, 'SD': 0.024531089, 'med': 1.0, 'range': (0.13846155, 1.0), 'conf.': (0.9981108277528373, 0.9996632963926705), 'nan_count': 0}\n",
      "\n",
      "##### LOC_CLS #####\n",
      "- # Inst.: {'n': 77, 'sum': 765130, 'mean': 9936.753246753247, 'SD': 5862.139593131873, 'med': 8526.0, 'range': (1870, 26960), 'conf.': (8606.21076881271, 11267.295724693784), 'nan_count': 0}\n",
      "- Values: {'n': 765130, 'cardinality': 1221, 'value_count': 'NONE:552547, FD479A:2518, 281974:2408, D2786E:2377, 0C7723:2368, 47BC15:1985, 29D0E4:1977, 4B47F6:1849, CA5462:1770, 3AD3C4:1757, 7E9545:1750, 6FC1AE:1712, 05301A:1682, 53E0D3:1645, 1F5313:1619, 5BD8C7:1552, 2371A8:1533, 93CA70:1481, 23B45A:1446, A99F5D:1414, ...'}\n",
      "\n",
      "##### LOC_LABEL #####\n",
      "- # Inst.: {'n': 77, 'sum': 765130, 'mean': 9936.753246753247, 'SD': 5862.139593131873, 'med': 8526.0, 'range': (1870, 26960), 'conf.': (8606.21076881271, 11267.295724693784), 'nan_count': 0}\n",
      "- Values: {'n': 765130, 'cardinality': 7, 'value_count': 'none:552547, eating:63162, home:60708, work:58270, social:18434, others:7281, gym:4728'}\n",
      "\n",
      "##### LOC_DST #####\n",
      "- # Inst.: {'n': 77, 'sum': 765130, 'mean': 9936.753246753247, 'SD': 5862.139593131873, 'med': 8526.0, 'range': (1870, 26960), 'conf.': (8606.21076881271, 11267.295724693784), 'nan_count': 0}\n",
      "- Samp. period: {'n': 765053, 'sum': 42725874.24799999, 'mean': 55.846946875575924, 'SD': 907.8659717610384, 'med': 2.0, 'range': (0.001, 261313.101), 'conf.': (53.81260117589836, 57.88129257525349), 'nan_count': 0}\n",
      "- Values: {'n': 765130, 'sum': 146576720.0, 'mean': 191.571, 'SD': 37645.066, 'med': 9.06008, 'range': (0.0, 11726499.0), 'conf.': (107.22019439655669, 275.92180389445895), 'nan_count': 0}\n",
      "\n",
      "##### MED_VID #####\n",
      "- # Inst.: {'n': 16, 'sum': 50, 'mean': 3.125, 'SD': 3.4229616805723473, 'med': 2.0, 'range': (1, 14), 'conf.': (1.3010324703692735, 4.9489675296307265), 'nan_count': 0}\n",
      "- Samp. period: {'n': 34, 'sum': 1131591.334, 'mean': 33282.09805882353, 'SD': 77492.15453791979, 'med': 249.952, 'range': (10.484, 304151.576), 'conf.': (6243.807110294143, 60320.38900735292), 'nan_count': 0}\n",
      "- Values: {'n': 50, 'sum': 50.0, 'mean': 1.0, 'SD': 0.0, 'med': 1.0, 'range': (1.0, 1.0), 'conf.': (nan, nan), 'nan_count': 0}\n",
      "\n",
      "##### MED_IMG #####\n",
      "- # Inst.: {'n': 68, 'sum': 1764, 'mean': 25.941176470588236, 'SD': 31.531496858183676, 'med': 14.0, 'range': (1, 158), 'conf.': (18.308928252705993, 33.57342468847048), 'nan_count': 0}\n",
      "- Samp. period: {'n': 1696, 'sum': 19498767.881, 'mean': 11496.915024174528, 'SD': 32675.806031851756, 'med': 147.77249999999998, 'range': (0.063, 458846.323), 'conf.': (9940.69247372538, 13053.137574623677), 'nan_count': 0}\n",
      "- Values: {'n': 1764, 'sum': 1764.0, 'mean': 1.0, 'SD': 0.0, 'med': 1.0, 'range': (1.0, 1.0), 'conf.': (nan, nan), 'nan_count': 0}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### MED_ALL #####\n",
      "- # Inst.: {'n': 68, 'sum': 1814, 'mean': 26.676470588235293, 'SD': 32.195967660966296, 'med': 15.0, 'range': (1, 159), 'conf.': (18.883386171450674, 34.46955500501991), 'nan_count': 0}\n",
      "- Samp. period: {'n': 1746, 'sum': 19530305.077, 'mean': 11185.741739404353, 'SD': 32116.61130432838, 'med': 149.0435, 'range': (0.063, 458846.323), 'conf.': (9678.242774201177, 12693.24070460753), 'nan_count': 0}\n",
      "- Values: {'n': 1814, 'sum': 1814.0, 'mean': 1.0, 'SD': 0.0, 'med': 1.0, 'range': (1.0, 1.0), 'conf.': (nan, nan), 'nan_count': 0}\n",
      "\n",
      "##### MSG_SNT #####\n",
      "- # Inst.: {'n': 45, 'sum': 833, 'mean': 18.511111111111113, 'SD': 33.52924247593585, 'med': 11.0, 'range': (1, 209), 'conf.': (8.437811520087541, 28.584410702134683), 'nan_count': 0}\n",
      "- Samp. period: {'n': 788, 'sum': 12483112.686999999, 'mean': 15841.51356218274, 'SD': 52292.23992475608, 'med': 303.0, 'range': (0.948, 503792.0), 'conf.': (12184.802498109848, 19498.22462625563), 'nan_count': 0}\n",
      "- Values: {'n': 833, 'sum': 833.0, 'mean': 1.0, 'SD': 0.0, 'med': 1.0, 'range': (1.0, 1.0), 'conf.': (nan, nan), 'nan_count': 0}\n",
      "\n",
      "##### MSG_RCV #####\n",
      "- # Inst.: {'n': 66, 'sum': 1758, 'mean': 26.636363636363637, 'SD': 34.17585128696594, 'med': 17.5, 'range': (1, 233), 'conf.': (18.234890780702816, 35.037836492024454), 'nan_count': 0}\n",
      "- Samp. period: {'n': 1692, 'sum': 20848153.739, 'mean': 12321.60386465721, 'SD': 30843.81236785002, 'med': 1610.5, 'range': (0.584, 426967.0), 'conf.': (10850.894268886808, 13792.313460427613), 'nan_count': 0}\n",
      "- Values: {'n': 1758, 'sum': 1758.0, 'mean': 1.0, 'SD': 0.0, 'med': 1.0, 'range': (1.0, 1.0), 'conf.': (nan, nan), 'nan_count': 0}\n",
      "\n",
      "##### MSG_ALL #####\n",
      "- # Inst.: {'n': 66, 'sum': 2591, 'mean': 39.25757575757576, 'SD': 61.801247337688686, 'med': 22.0, 'range': (1, 442), 'conf.': (24.064932929345936, 54.45021858580558), 'nan_count': 0}\n",
      "- Samp. period: {'n': 2525, 'sum': 21158724.135, 'mean': 8379.692726732674, 'SD': 25685.474909155768, 'med': 302.559, 'range': (0.042, 426967.0), 'conf.': (7377.3567687881605, 9382.028684677187), 'nan_count': 0}\n",
      "- Values: {'n': 2591, 'sum': 2591.0, 'mean': 1.0, 'SD': 0.0, 'med': 1.0, 'range': (1.0, 1.0), 'conf.': (nan, nan), 'nan_count': 0}\n",
      "\n",
      "##### WIF_COS #####\n",
      "- # Inst.: {'n': 77, 'sum': 632015, 'mean': 8207.987012987012, 'SD': 7444.732430407115, 'med': 6649.0, 'range': (1323, 59399), 'conf.': (6518.240022457556, 9897.734003516469), 'nan_count': 0}\n",
      "- Samp. period: {'n': 631938, 'sum': 43155863.75099998, 'mean': 68.29129400510806, 'SD': 728.8783419917986, 'med': 13.788, 'range': (0.009, 260934.687), 'conf.': (66.49421681060578, 70.08837119961034), 'nan_count': 0}\n",
      "- Values: {'n': 632015, 'sum': 608502.6, 'mean': 0.96279776, 'SD': 0.18386734, 'med': 0.9992121, 'range': (0.0, 1.0), 'conf.': (0.9623444566913765, 0.9632510652355034), 'nan_count': 0}\n",
      "\n",
      "##### WIF_EUC #####\n",
      "- # Inst.: {'n': 77, 'sum': 632015, 'mean': 8207.987012987012, 'SD': 7444.732430407115, 'med': 6649.0, 'range': (1323, 59399), 'conf.': (6518.240022457556, 9897.734003516469), 'nan_count': 0}\n",
      "- Samp. period: {'n': 631938, 'sum': 43155863.75099998, 'mean': 68.29129400510806, 'SD': 728.8783419917986, 'med': 13.788, 'range': (0.009, 260934.687), 'conf.': (66.49421681060578, 70.08837119961034), 'nan_count': 0}\n",
      "- Values: {'n': 632015, 'sum': 205010.02, 'mean': 0.32437524, 'SD': 0.2883837, 'med': 0.2204812, 'range': (0.0, 1.0), 'conf.': (0.3236642643784266, 0.325086219611289), 'nan_count': 0}\n",
      "\n",
      "##### WIF_MAN #####\n",
      "- # Inst.: {'n': 77, 'sum': 632015, 'mean': 8207.987012987012, 'SD': 7444.732430407115, 'med': 6649.0, 'range': (1323, 59399), 'conf.': (6518.240022457556, 9897.734003516469), 'nan_count': 0}\n",
      "- Samp. period: {'n': 631938, 'sum': 43155863.75099998, 'mean': 68.29129400510806, 'SD': 728.8783419917986, 'med': 13.788, 'range': (0.009, 260934.687), 'conf.': (66.49421681060578, 70.08837119961034), 'nan_count': 0}\n",
      "- Values: {'n': 632015, 'sum': 233692.9, 'mean': 0.3697585, 'SD': 0.2903466, 'med': 0.27083334, 'range': (0.0, 1.0), 'conf.': (0.3690426698213406, 0.3704743036741428), 'nan_count': 0}\n",
      "\n",
      "##### WIF_JAC #####\n",
      "- # Inst.: {'n': 77, 'sum': 632015, 'mean': 8207.987012987012, 'SD': 7444.732430407115, 'med': 6649.0, 'range': (1323, 59399), 'conf.': (6518.240022457556, 9897.734003516469), 'nan_count': 0}\n",
      "- Samp. period: {'n': 631938, 'sum': 43155863.75099998, 'mean': 68.29129400510806, 'SD': 728.8783419917986, 'med': 13.788, 'range': (0.009, 260934.687), 'conf.': (66.49421681060578, 70.08837119961034), 'nan_count': 0}\n",
      "- Values: {'n': 632015, 'sum': 345646.47, 'mean': 0.546896, 'SD': 0.28432044, 'med': 0.53846157, 'range': (0.0, 1.0), 'conf.': (0.5461950207018483, 0.5475969409680735), 'nan_count': 0}\n",
      "\n",
      "##### SCR_EVENT #####\n",
      "- # Inst.: {'n': 77, 'sum': 207137, 'mean': 2690.090909090909, 'SD': 998.2933091534162, 'med': 2718.0, 'range': (512, 5034), 'conf.': (2463.5061217158936, 2916.6756964659244), 'nan_count': 0}\n",
      "- Values: {'n': 207137, 'cardinality': 3, 'value_count': 'ON:77317, OFF:77233, UNLOCK:52587'}\n",
      "\n",
      "##### SCR_DUR #####\n",
      "- # Inst.: {'n': 77, 'sum': 154356, 'mean': 2004.6233766233765, 'SD': 747.6612313172085, 'med': 1977.0, 'range': (355, 3716), 'conf.': (1834.9250929894658, 2174.3216602572875), 'nan_count': 0}\n",
      "- Samp. period: {'n': 154279, 'sum': 43269407.74200001, 'mean': 280.4620702882441, 'SD': 1622.5995211608692, 'med': 36.762, 'range': (0.063, 261409.696), 'conf.': (272.3653444473877, 288.5587961291005), 'nan_count': 0}\n",
      "- Values: {'n': 154356, 'sum': 43282892.0, 'mean': 280.40952, 'SD': 1622.2684, 'med': 36.753, 'range': (0.063, 261409.7), 'conf.': (272.31646104693635, 288.5025697147824), 'nan_count': 0}\n",
      "\n",
      "##### RNG #####\n",
      "- # Inst.: {'n': 76, 'sum': 1242, 'mean': 16.342105263157894, 'SD': 15.946203419898165, 'med': 11.5, 'range': (1, 87), 'conf.': (12.698241688042252, 19.985968838273536), 'nan_count': 0}\n",
      "- Values: {'n': 1242, 'cardinality': 3, 'value_count': 'VIBRATE:488, SILENT:402, NORMAL:352'}\n",
      "\n",
      "##### CHG #####\n",
      "- # Inst.: {'n': 77, 'sum': 11570, 'mean': 150.25974025974025, 'SD': 272.06749368673997, 'med': 72.0, 'range': (4, 2112), 'conf.': (88.5079939108227, 212.0114866086578), 'nan_count': 0}\n",
      "- Values: {'n': 11570, 'cardinality': 2, 'value_count': 'DISCONNECTED:5818, CONNECTED:5752'}\n",
      "\n",
      "##### PWS #####\n",
      "- # Inst.: {'n': 16, 'sum': 370, 'mean': 23.125, 'SD': 62.0127675026146, 'med': 4.0, 'range': (1, 254), 'conf.': (-9.919271278080963, 56.16927127808096), 'nan_count': 0}\n",
      "- Values: {'n': 370, 'cardinality': 2, 'value_count': 'ACTIVATE:211, DEACTIVATE:159'}\n",
      "\n",
      "##### ONF #####\n",
      "- # Inst.: {'n': 47, 'sum': 184, 'mean': 3.9148936170212765, 'SD': 2.857711057548792, 'med': 3.0, 'range': (1, 16), 'conf.': (3.0758382188645337, 4.753949015178019), 'nan_count': 0}\n",
      "- Values: {'n': 184, 'cardinality': 2, 'value_count': 'ON:95, OFF:89'}\n",
      "\n",
      "# categorical data: 13 / # numeric data: 48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "\n",
    "# Get the column data types\n",
    "column_dtypes = {k: v.dtype for k, v in DATA.items()}\n",
    "\n",
    "# Count the number of categorical and numeric columns\n",
    "N_NUMERIC = sum(d.kind.islower() or d.kind == 'f' for d in column_dtypes.values())\n",
    "N_CATEGORICAL = len(column_dtypes) - N_NUMERIC\n",
    "\n",
    "for k, v in DATA.items():\n",
    "    if v.dtype.kind.isupper() or v.dtype.kind == 'b':\n",
    "        # Categorical column\n",
    "        inst = v.groupby('pcode').count()\n",
    "        print('#' * 5, k, '#' * 5)\n",
    "        print('- # Inst.:', summary(inst))\n",
    "        print('- Values:', summary(v))\n",
    "        print('')\n",
    "    else:\n",
    "        # Numeric column\n",
    "        if k == 'LOC_DST':\n",
    "            v_temp = v.reset_index()\n",
    "            v_temp['timestamp'] = pd.to_datetime(v_temp['timestamp'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "            v_temp = v_temp.set_index(['pcode', 'timestamp'])\n",
    "            \n",
    "            pcode_groups = v_temp.groupby('pcode')\n",
    "            sam = pd.concat([\n",
    "                (group.reset_index(level='timestamp')['timestamp'] - group.reset_index(level='timestamp')['timestamp'].shift(1)).dropna().dt.total_seconds()\n",
    "                for _, group in pcode_groups\n",
    "            ])\n",
    "            print('#' * 5, k, '#' * 5)\n",
    "            print('- # Inst.:', summary(pcode_groups.count()))\n",
    "            print('- Samp. period:', summary(sam))\n",
    "            print('- Values:', summary(v_temp))\n",
    "            print('')\n",
    "        else:\n",
    "            pcode_groups = v.groupby('pcode')\n",
    "            sam = pd.concat([\n",
    "                (group.reset_index(level='timestamp')['timestamp'] - group.reset_index(level='timestamp')['timestamp'].shift(1)).dropna().dt.total_seconds()\n",
    "                for _, group in pcode_groups\n",
    "            ])\n",
    "            print('#' * 5, k, '#' * 5)\n",
    "            print('- # Inst.:', summary(pcode_groups.count()))\n",
    "            print('- Samp. period:', summary(sam))\n",
    "            print('- Values:', summary(v))\n",
    "            print('')\n",
    "\n",
    "print(f'# categorical data: {N_CATEGORICAL} / # numeric data: {N_NUMERIC}')\n",
    "del DATA\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the distribution of preprocessed sensor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 17:01:25,377\tINFO worker.py:1432 -- Connecting to existing Ray cluster at address: 192.168.1.28:6379...\n",
      "2023-06-02 17:01:25,431\tINFO worker.py:1616 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 40705 MiB, 4 objects, write throughput 933 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 50882 MiB, 5 objects, write throughput 916 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 71234 MiB, 7 objects, write throughput 1059 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 132293 MiB, 13 objects, write throughput 1173 MiB/s.\n",
      "\u001b[2m\u001b[36m(raylet)\u001b[0m Spilled 264586 MiB, 26 objects, write throughput 1140 MiB/s.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m DATA \u001b[38;5;241m=\u001b[39m load(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(PATH_INTERMEDIATE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproc.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m on_ray():\n\u001b[0;32m---> 47\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprocess_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremote\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEXP_DATE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mEXP_DATE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m DIST_DATA \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(results)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(DIST_DATA)\n",
      "File \u001b[0;32m~/miniconda3/envs/sci-data/lib/python3.9/site-packages/ray/_private/client_mode_hook.py:105\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sci-data/lib/python3.9/site-packages/ray/_private/worker.py:2515\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2510\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2511\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject_refs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2512\u001b[0m     )\n\u001b[1;32m   2514\u001b[0m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2515\u001b[0m values, debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2516\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[1;32m   2517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/miniconda3/envs/sci-data/lib/python3.9/site-packages/ray/_private/worker.py:742\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    737\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to call `get` on the value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_ref\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is not an ray.ObjectRef.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    739\u001b[0m         )\n\u001b[1;32m    741\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 742\u001b[0m data_metadata_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore_worker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_task_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_ms\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m debugger_breakpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (data, metadata) \u001b[38;5;129;01min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:1664\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:201\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ray\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta as td\n",
    "from ray.util.multiprocessing import Pool\n",
    "from contextlib import contextmanager\n",
    "from Funcs.Utility import load\n",
    "\n",
    "@ray.remote\n",
    "def process_p(p, DATA, EXP_DATE):\n",
    "    raw_data = {key: df.loc[p] for key, df in DATA.items() if p in df.index.get_level_values('pcode')}\n",
    "    dist_temp = []\n",
    "\n",
    "    for data_type, data_values in raw_data.items():\n",
    "        data_values.index = pd.to_datetime(data_values.index, unit='ms', utc=True).tz_convert(DEFAULT_TZ)\n",
    "        data_sub = pd.concat([\n",
    "            data_values.to_frame().reset_index().assign(pcode=p)\n",
    "        ]).merge(\n",
    "            EXP_DATE, on='pcode', how='left'\n",
    "        ).loc[\n",
    "            lambda x: ((x['timestamp'] - x['start_day']).dt.total_seconds() >= 0) & ((x['end_day'] - x['timestamp']).dt.total_seconds() >= 0), :\n",
    "        ].assign(\n",
    "            day = lambda x: np.floor((x['timestamp'] - x['start_day']).dt.total_seconds() / 60 / 60 / 24)\n",
    "        ).groupby(\n",
    "            ['pcode', 'day']\n",
    "        ).count()['timestamp'].reset_index().assign(\n",
    "            type=data_type\n",
    "        )\n",
    "\n",
    "        dist_temp.append(data_sub)\n",
    "        \n",
    "    return pd.concat(dist_temp)\n",
    "\n",
    "\n",
    "\n",
    "LABEL = pd.read_csv(os.path.join(PATH_INTERMEDIATE, 'proc', 'LABELS_PROC.csv'), index_col=['pcode','timestamp'],parse_dates=True)\n",
    "EXP_DATE = LABEL.reset_index().groupby(['pcode']).agg(\n",
    "    start_day=pd.NamedAgg(column='timestamp', aggfunc=lambda x: x.min().replace(hour=0, minute=0, second=0, microsecond=0)),\n",
    "    end_day=pd.NamedAgg(column='timestamp', aggfunc=lambda x: (x.max() + td(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)),\n",
    ")\n",
    "EXP_DATE['start_day'] = pd.to_datetime(EXP_DATE['start_day'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "EXP_DATE['end_day'] = pd.to_datetime(EXP_DATE['end_day'], unit='ms', utc=True).dt.tz_convert(DEFAULT_TZ)\n",
    "DATA = load(os.path.join(PATH_INTERMEDIATE, 'proc.pkl'))\n",
    "\n",
    "with on_ray():\n",
    "    results = ray.get([process_p.remote(p, DATA, EXP_DATE) for p in EXP_DATE.index])\n",
    "\n",
    "DIST_DATA = pd.concat(results)\n",
    "print(DIST_DATA)\n",
    "\n",
    "del DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a visualization package\n",
    "#https://altair-viz.github.io/getting_started/overview.html\n",
    "import altair as alt \n",
    "\n",
    "#If you are certain you would like to embed your dataset within the visualization specification, you can disable the MaxRows check with the following:\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "selection = alt.selection_single(\n",
    "    fields=['type'],\n",
    "    bind=alt.binding_select(\n",
    "        options=DIST_DATA['type'].unique(),\n",
    "        name='Data Type: '\n",
    "    )\n",
    ")\n",
    "\n",
    "chart=alt.Chart(DIST_DATA).mark_rect().encode(\n",
    "     x=alt.X('day:O', title='Time (days)'),\n",
    "     y=alt.Y('pcode:O', title='Pcode'),\n",
    "     color=alt.Color('timestamp:Q', title='Count')\n",
    ").transform_filter(\n",
    "    selection\n",
    ").add_selection(\n",
    "    selection\n",
    ").properties(\n",
    "    title='# Instances',\n",
    "    width=300,\n",
    "    height=800\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
