{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(PATH_INTERMEDIATE, 'feat',f'stress-fixed.pkl')\n",
    "\n",
    "X, y, groups, t, datetimes = load(p)\n",
    "##############################################\n",
    "# #Remove users with extreme label distribution\n",
    "# # Create a DataFrame from y, groups, t, datetimes\n",
    "# info_df = pd.DataFrame({\n",
    "#     'y': y,\n",
    "#     'groups': groups,\n",
    "#     't': t,\n",
    "#     'datetimes': pd.to_datetime(datetimes)  # assuming 'datetimes' needs conversion to datetime\n",
    "# })\n",
    "\n",
    "# # Calculate majority/minority ratio for each group\n",
    "# def calculate_ratio(group):\n",
    "#     counts = group['y'].value_counts()\n",
    "#     if len(counts) > 1:\n",
    "#         majority = counts.max()\n",
    "#         minority = counts.min()\n",
    "#         ratio = majority / minority\n",
    "#     else:\n",
    "#         ratio = np.inf  # Infinite ratio if there's no minority class\n",
    "#     return ratio\n",
    "\n",
    "# # Apply the function per group\n",
    "# group_ratios = info_df.groupby('groups').apply(calculate_ratio)\n",
    "\n",
    "# # Filter groups based on the ratio\n",
    "# filtered_groups = group_ratios[group_ratios <= 4].index\n",
    "\n",
    "# # Filter the original DataFrame 'info_df' to remove skewed groups\n",
    "# filtered_info = info_df[info_df['groups'].isin(filtered_groups)]\n",
    "\n",
    "# # Use the indices of the filtered info to refine 'X'\n",
    "# X_filtered = X.loc[filtered_info.index]\n",
    "\n",
    "# # Extracting other arrays from the filtered info\n",
    "# y_filtered = filtered_info['y'].values\n",
    "# groups_filtered = filtered_info['groups'].values\n",
    "# t_filtered = filtered_info['t'].values\n",
    "# datetimes_filtered = filtered_info['datetimes'].values\n",
    "\n",
    "# X, y, groups, t, datetimes = X_filtered, y_filtered, groups_filtered, t_filtered, datetimes_filtered\n",
    "\n",
    "# Now 'X_filtered', 'y_filtered', 'groups_filtered', 't_filtered', 'datetimes_filtered'\n",
    "# are ready to be used for further analysis or modeling\n",
    "################################################\n",
    "# #Remove neutral state samples\n",
    "# y =  LABELS_PROC['stressLevel'].to_numpy()\n",
    "\n",
    "# # Create a mask that selects all samples where y is not equal to 3 (neutral state)\n",
    "# mask = y != 3\n",
    "\n",
    "# # Apply this mask to filter out the neutral samples from all arrays\n",
    "# X_filtered = X[mask]  # X is a DataFrame, it uses boolean indexing directly\n",
    "# y_filtered = y[mask]  # y, groups, t, datetimes are numpy arrays or similar structures\n",
    "# groups_filtered = groups[mask]\n",
    "# t_filtered = t[mask]\n",
    "# datetimes_filtered = datetimes[mask]\n",
    "\n",
    "# y = (y_filtered > 3).astype(int)\n",
    "# X = X_filtered\n",
    "# groups = groups_filtered\n",
    "# t = t_filtered\n",
    "# datetimes = datetimes_filtered\n",
    "\n",
    "################################################\n",
    "#Use mean threshold for all users (only training set,\\ \n",
    "#we need to use raw value and binarize after data splitting)\n",
    "# y =  LABELS_PROC['stressLevel'].to_numpy()\n",
    "#Use user speicifc mean threshold\n",
    "# y =LABELS_PROC['stress_user_mean'].to_numpy()\n",
    "#Use fixed threshold\n",
    "#         y =LABELS_PROC['stress_fixed'].to_numpy()\n",
    "#Use three categories (fixed threshold) \n",
    "#        y =LABELS_PROC['stress_fixed_tri'].to_numpy()\n",
    "\n",
    "\n",
    "#The following code is designed for reordering for the sake of time series split \n",
    "#################################################\n",
    "# Create a DataFrame with user_id and datetime\n",
    "\n",
    "df = pd.DataFrame({'user_id': groups, 'datetime': datetimes, 'label': y})\n",
    "\n",
    "# df_merged = pd.merge(df, X, left_index=True, right_index=True)\n",
    "df_merged = pd.merge(df, X, left_index=True, right_index=True)\n",
    "\n",
    "# Normalize the datetime for each user only needed for timeseries split/groupk partil personalization\n",
    "#         df_merged['datetime'] = df_merged.groupby('user_id')['datetime'].transform(lambda x: x - x.min())\n",
    "# df_merged['datetime'] = df_merged.groupby('user_id')['datetime'].transform(lambda x: x - x.min().normalize())\n",
    "\n",
    "# Sort the DataFrame by datetime\n",
    "df_merged = df_merged.sort_values(by=['user_id', 'datetime'])\n",
    "# df_merged = df_merged.sort_values(by=['datetime'])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "# df_merged = df_merged.sample(frac=1, random_state=RANDOM_STATE)\n",
    "\n",
    "# Update groups and datetimes\n",
    "groups = df_merged['user_id'].to_numpy()\n",
    "datetimes = df_merged['datetime'].to_numpy()  \n",
    "y = df_merged['label'].to_numpy()\n",
    "X = df_merged.drop(columns=['user_id', 'datetime', 'label'])\n",
    "\n",
    "#The following code is for shuffling the temporal order for all users\n",
    "########################################################\n",
    "\n",
    "# # Assuming 'groups', 'datetimes', 'y', and 'X' are already defined and loaded\n",
    "# # Create a DataFrame with user_id, datetime, and label\n",
    "# df = pd.DataFrame({\n",
    "#     'user_id': groups,\n",
    "#     'datetime': datetimes,\n",
    "#     'label': y\n",
    "# })\n",
    "\n",
    "# # Merge the new DataFrame with the features DataFrame 'X'\n",
    "# # Ensure 'X' is indexed the same way as 'groups', 'datetimes', and 'y'\n",
    "# df_merged = pd.merge(df, X, left_index=True, right_index=True)\n",
    "\n",
    "# # Shuffle the DataFrame\n",
    "# # This disregards the temporal ordering completely and randomizes all entries\n",
    "# df_merged = df_merged.sample(frac=1, random_state=42)  # Use a fixed seed for reproducibility\n",
    "\n",
    "# # Extract the shuffled 'groups', 'datetimes', 'y', and 'X' from the shuffled DataFrame\n",
    "# groups_shuffled = df_merged['user_id'].to_numpy()\n",
    "# datetimes_shuffled = df_merged['datetime'].to_numpy()\n",
    "# y_shuffled = df_merged['label'].to_numpy()\n",
    "# X_shuffled = df_merged.drop(columns=['user_id', 'datetime', 'label'])\n",
    "\n",
    "# # Optionally, you can convert 'X_shuffled' back to the correct type if it needs to be a DataFrame\n",
    "# X_shuffled = pd.DataFrame(X_shuffled, columns=X.columns)\n",
    "\n",
    "# X, y, groups, datetimes = X_shuffled, y_shuffled, groups_shuffled, datetimes_shuffled\n",
    "\n",
    "\n",
    "#The following code is for only using 1st day\n",
    "###########################################\n",
    "# filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_day.csv'),index_col=0)\n",
    "# # filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_week.csv'),index_col=0)\n",
    "# X_filtered = X[~X.index.isin(filtered_df.index)]\n",
    "# y_series = pd.Series(y, index=X.index)\n",
    "# y_filtered = y_series[~y_series.index.isin(filtered_df.index)]\n",
    "# y_filtered = y_filtered.values\n",
    "# groups_series = pd.Series(groups, index=X.index)\n",
    "# groups_filtered = groups_series[~groups_series.index.isin(filtered_df.index)]\n",
    "# groups_filtered = groups_filtered.values\n",
    "# X,y, groups=X_filtered,y_filtered, groups_filtered\n",
    "# #The following code is for excluding using 1st day\n",
    "# ###########################################\n",
    "# # filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_week.csv'),index_col=0)\n",
    "# filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_day.csv'),index_col=0)\n",
    "# X_filtered = X[X.index.isin(filtered_df.index)]\n",
    "# y_series = pd.Series(y, index=X.index)\n",
    "# y_filtered = y_series[y_series.index.isin(filtered_df.index)]\n",
    "# y_filtered = y_filtered.values\n",
    "# groups_series = pd.Series(groups, index=X.index)\n",
    "# groups_filtered = groups_series[groups_series.index.isin(filtered_df.index)]\n",
    "# groups_filtered = groups_filtered.values\n",
    "# datetimes_series = pd.Series(datetimes, index=X.index)\n",
    "# datetimes_filtered = datetimes_series[datetimes_series.index.isin(filtered_df.index)]\n",
    "# datetimes_filtered = datetimes_filtered.values\n",
    "# X,y, groups, datetimes=X_filtered,y_filtered, groups_filtered, datetimes_filtered\n",
    "\n",
    "\n",
    "###########################################\n",
    "#The following code is for similar-user model\n",
    "###########################################\n",
    "#         similar_user = pd.read_csv(os.path.join(PATH_INTERMEDIATE,  'similar_user.csv'))\n",
    "#         cluster_label = similar_user['cluster'].value_counts().index[0] #N number clusters\n",
    "#         similar_users_in_cluster = similar_user[similar_user['cluster'] == cluster_label]['pcode']\n",
    "\n",
    "#         # Check if each value in 'groups' is in 'similar_users_in_cluster'\n",
    "#         mask = np.isin(groups, similar_users_in_cluster)\n",
    "\n",
    "#         # Filter 'groups' based on the mask\n",
    "#         filtered_groups = groups[mask]\n",
    "#         # Filter 'X' and 'y' based on the mask\n",
    "#         X_filtered = X[mask]\n",
    "#         y_filtered = y[mask]\n",
    "#         X,y, groups=X_filtered,y_filtered, filtered_groups\n",
    "###########################################\n",
    "#Remove low frequency features\n",
    "#         mask = ['CAE#', 'MED#', 'ONF#', 'PWS#', 'RNG#','MSG#' ]\n",
    "#         X = X.loc[:, [all(m not in str(x) for m in mask) for x in X.columns]]\n",
    "\n",
    "#Divide the features into different categories\n",
    "feat_current = X.loc[:,[('#VAL' in str(x)) or ('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_dsc = X.loc[:,[('#DSC' in str(x))  for x in X.keys()]]  \n",
    "feat_yesterday = X.loc[:,[('Yesterday' in str(x))  for x in X.keys()]]  \n",
    "feat_today = X.loc[:,[('Today' in str(x))  for x in X.keys()]]  \n",
    "feat_sleep = X.loc[:,[('Sleep' in str(x))  for x in X.keys()]]  \n",
    "feat_time = X.loc[:,[('Time' in str(x))  for x in X.keys()]]  \n",
    "feat_pif = X.loc[:,[('PIF' in str(x))  for x in X.keys()]]  \n",
    "feat_ImmediatePast = X.loc[:,[('ImmediatePast_15' in str(x))  for x in X.keys()]]\n",
    "#Divide the time window features into sensor/past stress label\n",
    "feat_current_sensor = X.loc[:,[('#VAL' in str(x))  for x in X.keys()]]  \n",
    "feat_current_ESM = X.loc[:,[('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_ImmediatePast_sensor = feat_ImmediatePast.loc[:,[('ESM' not in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_ImmediatePast_ESM = feat_ImmediatePast.loc[:,[('ESM'  in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_today_sensor = feat_today.loc[:,[('ESM' not in str(x))  for x in feat_today.keys()]]  \n",
    "feat_today_ESM = feat_today.loc[:,[('ESM'  in str(x)) for x in feat_today.keys()]]  \n",
    "feat_yesterday_sensor = feat_yesterday.loc[:,[('ESM' not in str(x)) for x in feat_yesterday.keys()]]  \n",
    "feat_yesterday_ESM = feat_yesterday.loc[:,[('ESM'  in str(x)) for x in feat_yesterday.keys()]]\n",
    "\n",
    "\n",
    "\n",
    "#Prepare the final feature set\n",
    "feat_baseline = pd.concat([ feat_time,feat_dsc,feat_current_sensor, feat_ImmediatePast_sensor],axis=1)\n",
    "#The following code is for calculating aggregated features\n",
    "########################################################################\n",
    "# # Define a function to split the column name into sensor and attribute\n",
    "# def split_column_name(col_name):\n",
    "#     parts = col_name.rsplit(\"#\", 1)  # Split on last occurrence of '#'\n",
    "#     return parts[0]  # This gives you 'Sensor#Attribute'\n",
    "\n",
    "# # Get a list of unique sensor-attribute combinations\n",
    "# df=feat_today_sensor\n",
    "# sensor_attributes = df.columns.map(split_column_name).unique()\n",
    "\n",
    "# # Create a list to hold the aggregated results\n",
    "# agg_results = []\n",
    "\n",
    "# # Loop over each sensor-attribute, select the appropriate columns, compute the mean and std\n",
    "# for sensor_attribute in sensor_attributes:\n",
    "#     # Select columns for this sensor-attribute\n",
    "#     cols_to_aggregate = [col for col in df.columns if col.startswith(sensor_attribute)]\n",
    "#     # Compute the mean and std and store in the new DataFrame\n",
    "#     agg_results.append(df[cols_to_aggregate].mean(axis=1).rename(sensor_attribute + '|'+ 'MEAN'))\n",
    "#     agg_results.append(df[cols_to_aggregate].std(axis=1).rename(sensor_attribute + '|'+'STD'))\n",
    "\n",
    "# # Concatenate all the results into a single DataFrame\n",
    "# agg_feature = pd.concat(agg_results, axis=1)\n",
    "\n",
    "######################################################################\n",
    "feat_final = pd.concat([feat_baseline],axis=1)\n",
    "\n",
    "#         # Fill NaN values with zeros\n",
    "#         feat_final = feat_final.fillna(0)\n",
    "\n",
    "#         # Find the maximum non-infinity value and minimum non-negative infinity value across the entire dataframe\n",
    "#         max_val = feat_final[feat_final != np.inf].max().max()\n",
    "#         min_val = feat_final[feat_final != -np.inf].min().min()\n",
    "\n",
    "#         # Replace positive and negative infinity values\n",
    "#         feat_final.replace(np.inf, max_val, inplace=True)\n",
    "#         feat_final.replace(-np.inf, min_val, inplace=True)\n",
    "\n",
    "X = feat_final\n",
    "cats = X.columns[X.dtypes == bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class EvXGBClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_size=None,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        self.random_state = random_state\n",
    "        self.eval_size = eval_size\n",
    "        self.eval_metric = eval_metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.model = XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            eval_metric=self.eval_metric,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    @property\n",
    "    def feature_names_in_(self):\n",
    "        return self.model.feature_names_in_\n",
    "\n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: np.ndarray):\n",
    "        if self.eval_size:\n",
    "            splitter = StratifiedShuffleSplit(random_state=self.random_state, test_size=self.eval_size)\n",
    "            I_train, I_eval = next(splitter.split(X, y))\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X.iloc[I_eval, :], y[I_eval]\n",
    "            else:\n",
    "                X_train, y_train = X[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X[I_eval, :], y[I_eval]\n",
    "                \n",
    "            self.model = self.model.fit(\n",
    "                X=X_train, y=y_train, \n",
    "                eval_set=[(X_eval, y_eval)],\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.model = self.model.fit(X=X, y=y, verbose=False)\n",
    "        # After fitting, store the best iteration\n",
    "        # self.best_iteration_ = self.model.get_booster().best_iteration\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        return self.model.predict(X)\n",
    "        # return self.model.predict(X, iteration_range=(0, self.best_iteration_ + 1))\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        return self.model.predict_proba(X)\n",
    "        # return self.model.predict_proba(X, iteration_range=(0, self.best_iteration_ + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-05 12:52:37</td></tr>\n",
       "<tr><td>Running for: </td><td>00:41:24.64        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.4/62.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using HyperBand: num_stopped=0 total_brackets=4<br>Round #0:<br>  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} <br>  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 8} <br>  Bracket(Max Size (n)=5, Milestone (r)=27, completed=3.9%): {TERMINATED: 16} <br>  Bracket(Max Size (n)=34, Milestone (r)=3, completed=4.0%): {PENDING: 1, RUNNING: 16, TERMINATED: 19} <br>Logical resource usage: 16.0/16 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  ... 45 more trials not shown (6 RUNNING, 38 TERMINATED)\n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  colsample_bylevel</th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">   early_stopping_round\n",
       "s</th><th style=\"text-align: right;\">     gamma</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  num_parallel_tree</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">     auc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_038c71ae</td><td>RUNNING   </td><td>143.248.55.56:23903</td><td style=\"text-align: right;\">           0.744045</td><td style=\"text-align: right;\">          0.613917</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.280997  </td><td style=\"text-align: right;\">      0.0128936</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\"> 0.6253    </td><td style=\"text-align: right;\">    3.23294 </td><td style=\"text-align: right;\">   0.97199 </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_083eed8f</td><td>RUNNING   </td><td>143.248.55.56:24078</td><td style=\"text-align: right;\">           0.811652</td><td style=\"text-align: right;\">          0.795021</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.463734  </td><td style=\"text-align: right;\">      0.0330865</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\"> 0.26386   </td><td style=\"text-align: right;\">    2.95114 </td><td style=\"text-align: right;\">   0.652531</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_272867bb</td><td>RUNNING   </td><td>143.248.55.56:23992</td><td style=\"text-align: right;\">           0.563744</td><td style=\"text-align: right;\">          0.544932</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.104066  </td><td style=\"text-align: right;\">      0.198822 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 1.9766    </td><td style=\"text-align: right;\">    0.739045</td><td style=\"text-align: right;\">   0.625555</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_28b1bcbb</td><td>RUNNING   </td><td>143.248.55.56:23934</td><td style=\"text-align: right;\">           0.741496</td><td style=\"text-align: right;\">          0.809392</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.175487  </td><td style=\"text-align: right;\">      0.103722 </td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.44077   </td><td style=\"text-align: right;\">    2.04281 </td><td style=\"text-align: right;\">   0.894838</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_30265d4b</td><td>RUNNING   </td><td>143.248.55.56:24020</td><td style=\"text-align: right;\">           0.648931</td><td style=\"text-align: right;\">          0.50289 </td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.131694  </td><td style=\"text-align: right;\">      0.177487 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 1.70094   </td><td style=\"text-align: right;\">    1.0537  </td><td style=\"text-align: right;\">   0.752383</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_3162b685</td><td>RUNNING   </td><td>143.248.55.56:23739</td><td style=\"text-align: right;\">           0.617387</td><td style=\"text-align: right;\">          0.883565</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.00775953</td><td style=\"text-align: right;\">      0.0111692</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.51432   </td><td style=\"text-align: right;\">    2.52235 </td><td style=\"text-align: right;\">   0.687768</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_3eb40ecd</td><td>RUNNING   </td><td>143.248.55.56:23875</td><td style=\"text-align: right;\">           0.775536</td><td style=\"text-align: right;\">          0.697857</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.394713  </td><td style=\"text-align: right;\">      0.0438033</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\"> 0.357067  </td><td style=\"text-align: right;\">    3.49673 </td><td style=\"text-align: right;\">   0.701404</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_3f0ab335</td><td>RUNNING   </td><td>143.248.55.56:23848</td><td style=\"text-align: right;\">           0.811129</td><td style=\"text-align: right;\">          0.837363</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.313157  </td><td style=\"text-align: right;\">      0.0252451</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\"> 1.01748   </td><td style=\"text-align: right;\">    4.3933  </td><td style=\"text-align: right;\">   0.970256</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_7525d3a8</td><td>RUNNING   </td><td>143.248.55.56:24136</td><td style=\"text-align: right;\">           0.929159</td><td style=\"text-align: right;\">          0.650466</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.376834  </td><td style=\"text-align: right;\">      0.014173 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\"> 0.416999  </td><td style=\"text-align: right;\">    3.87743 </td><td style=\"text-align: right;\">   0.997191</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_7647fc0e</td><td>RUNNING   </td><td>143.248.55.56:23821</td><td style=\"text-align: right;\">           0.713526</td><td style=\"text-align: right;\">          0.66665 </td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.0393925 </td><td style=\"text-align: right;\">      0.075068 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.27787   </td><td style=\"text-align: right;\">    4.02202 </td><td style=\"text-align: right;\">   0.932321</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_d0bf52b0</td><td>PENDING   </td><td>                   </td><td style=\"text-align: right;\">           0.520367</td><td style=\"text-align: right;\">          0.776987</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.264626  </td><td style=\"text-align: right;\">      0.05019  </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.73783   </td><td style=\"text-align: right;\">    1.41404 </td><td style=\"text-align: right;\">   0.785905</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_00cd3768</td><td>TERMINATED</td><td>143.248.55.56:23821</td><td style=\"text-align: right;\">           0.875898</td><td style=\"text-align: right;\">          0.812968</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.479051  </td><td style=\"text-align: right;\">      0.0206886</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\"> 0.198074  </td><td style=\"text-align: right;\">    3.81455 </td><td style=\"text-align: right;\">   0.79399 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         758.643</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_02082ed0</td><td>TERMINATED</td><td>143.248.55.56:23848</td><td style=\"text-align: right;\">           0.825008</td><td style=\"text-align: right;\">          0.738169</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.394878  </td><td style=\"text-align: right;\">      0.0106742</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 0.949967  </td><td style=\"text-align: right;\">    3.93402 </td><td style=\"text-align: right;\">   0.793724</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         765.493</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_02844055</td><td>TERMINATED</td><td>143.248.55.56:23875</td><td style=\"text-align: right;\">           0.994677</td><td style=\"text-align: right;\">          0.998415</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.144719  </td><td style=\"text-align: right;\">      0.0104616</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 1.46659   </td><td style=\"text-align: right;\">    4.23301 </td><td style=\"text-align: right;\">   0.758218</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         762.283</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_04c75479</td><td>TERMINATED</td><td>143.248.55.56:23821</td><td style=\"text-align: right;\">           0.745071</td><td style=\"text-align: right;\">          0.717718</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.17443   </td><td style=\"text-align: right;\">      0.0840225</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.435     </td><td style=\"text-align: right;\">    1.53756 </td><td style=\"text-align: right;\">   0.909985</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         773.109</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_14e98f97</td><td>TERMINATED</td><td>143.248.55.56:24020</td><td style=\"text-align: right;\">           0.953149</td><td style=\"text-align: right;\">          0.626323</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.259536  </td><td style=\"text-align: right;\">      0.0212626</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 0.00460999</td><td style=\"text-align: right;\">    0.505779</td><td style=\"text-align: right;\">   0.823008</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         702.323</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_229bb21c</td><td>TERMINATED</td><td>143.248.55.56:23903</td><td style=\"text-align: right;\">           0.557071</td><td style=\"text-align: right;\">          0.906896</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.328977  </td><td style=\"text-align: right;\">      0.0246864</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 0.530612  </td><td style=\"text-align: right;\">    1.86115 </td><td style=\"text-align: right;\">   0.865321</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         719.636</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_2a62c79a</td><td>TERMINATED</td><td>143.248.55.56:24109</td><td style=\"text-align: right;\">           0.648851</td><td style=\"text-align: right;\">          0.520695</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.490993  </td><td style=\"text-align: right;\">      0.16233  </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 1.63676   </td><td style=\"text-align: right;\">    0.945557</td><td style=\"text-align: right;\">   0.742092</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         771.049</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_2b3cf091</td><td>TERMINATED</td><td>143.248.55.56:24051</td><td style=\"text-align: right;\">           0.626887</td><td style=\"text-align: right;\">          0.966882</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.225765  </td><td style=\"text-align: right;\">      0.0121513</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\"> 1.10039   </td><td style=\"text-align: right;\">    3.37098 </td><td style=\"text-align: right;\">   0.649416</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         788.229</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_2d9f9abb</td><td>TERMINATED</td><td>143.248.55.56:24078</td><td style=\"text-align: right;\">           0.838326</td><td style=\"text-align: right;\">          0.670843</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.078793  </td><td style=\"text-align: right;\">      0.103205 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.56261   </td><td style=\"text-align: right;\">    2.91138 </td><td style=\"text-align: right;\">   0.774206</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         786.406</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "<tr><td>objective_2e2ea60a</td><td>TERMINATED</td><td>143.248.55.56:23704</td><td style=\"text-align: right;\">           0.671533</td><td style=\"text-align: right;\">          0.656671</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.273601  </td><td style=\"text-align: right;\">      0.0359881</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\"> 1.78144   </td><td style=\"text-align: right;\">    1.34515 </td><td style=\"text-align: right;\">   0.848479</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         772.408</td><td style=\"text-align: right;\">-0.646493</td><td style=\"text-align: right;\">0.646493</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 4x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_3 with AUC: 0.687756520587846\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_3 with AUC: 0.6984310869853039\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_2 with AUC: 0.6527901527901528\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_16 with AUC: 0.6336845319896167\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_19 with AUC: 0.6217036708839987\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_22 with AUC: 0.6212920237310482\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_23 with AUC: 0.6039089937395022\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_19 with AUC: 0.6217036708839987\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_16 with AUC: 0.6273901019663731\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_19 with AUC: 0.6217036708839987\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_23 with AUC: 0.613817207037546\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_23 with AUC: 0.613817207037546\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_27 with AUC: 0.6177373073924798\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_34 with AUC: 0.645871742488415\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_31 with AUC: 0.6690813914218169\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_32 with AUC: 0.6588476278578037\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_3 with AUC: 0.687756520587846\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_41 with AUC: 0.6294335155122361\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_39 with AUC: 0.6703606917021551\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_43 with AUC: 0.6823888091822095\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_39 with AUC: 0.6703606917021551\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_41 with AUC: 0.6294335155122361\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_41 with AUC: 0.6294335155122361\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_40 with AUC: 0.6302573145245559\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_46 with AUC: 0.6311976201138763\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_43 with AUC: 0.6823888091822095\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_2 with AUC: 0.6527901527901528\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_46 with AUC: 0.6311976201138763\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_46 with AUC: 0.6311976201138763\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_3 with AUC: 0.6984310869853039\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_2 with AUC: 0.6527901527901528\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_3 with AUC: 0.687756520587846\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_3 with AUC: 0.6984310869853039\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_23 with AUC: 0.6039089937395022\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_19 with AUC: 0.6217036708839987\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_19 with AUC: 0.6217036708839987\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_23 with AUC: 0.613817207037546\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_27 with AUC: 0.6177373073924798\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_27 with AUC: 0.6177373073924798\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_32 with AUC: 0.6588476278578037\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_34 with AUC: 0.645871742488415\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_34 with AUC: 0.645871742488415\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_34 with AUC: 0.645871742488415\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_31 with AUC: 0.6690813914218169\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_32 with AUC: 0.6588476278578037\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_40 with AUC: 0.6302573145245559\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_32 with AUC: 0.6588476278578037\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_40 with AUC: 0.6302573145245559\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_41 with AUC: 0.6294335155122361\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_43 with AUC: 0.6823888091822095\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_46 with AUC: 0.6311976201138763\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_43 with AUC: 0.6823888091822095\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_26 with AUC: 0.6190953016720707\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_0 with AUC: 0.6586663120803138\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_27 with AUC: 0.6177373073924798\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_3 with AUC: 0.6984310869853039\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_2 with AUC: 0.6527901527901528\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_16 with AUC: 0.6273901019663731\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_16 with AUC: 0.6273901019663731\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_22 with AUC: 0.6212920237310482\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_16 with AUC: 0.6336845319896167\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_16 with AUC: 0.6273901019663731\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_19 with AUC: 0.6217036708839987\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_23 with AUC: 0.613817207037546\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_22 with AUC: 0.6255438365194463\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_40 with AUC: 0.6302573145245559\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_23 with AUC: 0.6039089937395022\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_24 with AUC: 0.6785094637223975\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_25 with AUC: 0.6477588923530793\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_23 with AUC: 0.613817207037546\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m \n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_21 with AUC: 0.6594904240766074\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_31 with AUC: 0.6690813914218169\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_32 with AUC: 0.6588476278578037\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_31 with AUC: 0.6690813914218169\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_30 with AUC: 0.6650882200311364\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_29 with AUC: 0.6256184444884227\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_33 with AUC: 0.6661698956780924\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_34 with AUC: 0.645871742488415\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_34 with AUC: 0.645871742488415\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_37 with AUC: 0.6290285788770489\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_35 with AUC: 0.6300061257263954\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_36 with AUC: 0.655459924690694\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_39 with AUC: 0.6660536843463674\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_39 with AUC: 0.6703606917021551\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_40 with AUC: 0.6302573145245559\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_39 with AUC: 0.6703606917021551\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_42 with AUC: 0.6409685863874346\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_38 with AUC: 0.6654333140975592\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_43 with AUC: 0.6823888091822095\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_41 with AUC: 0.6294335155122361\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_46 with AUC: 0.6311976201138763\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_24 with AUC: 0.6767350157728705\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_44 with AUC: 0.645456180804265\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_2 with AUC: 0.6464871464871464\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_1 with AUC: 0.6441123188405797\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_45 with AUC: 0.6612103653629486\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_2 with AUC: 0.6527901527901528\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_46 with AUC: 0.6311976201138763\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_27 with AUC: 0.6177373073924798\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_5 with AUC: 0.6513971598717361\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_2 with AUC: 0.6527901527901528\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23903)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24051)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_6 with AUC: 0.6381752701080432\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_23 with AUC: 0.613817207037546\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23646)\u001b[0m Training completed for Fold_12 with AUC: 0.6601283300844705\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24078)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_4 with AUC: 0.6376402723490103\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24020)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23934)\u001b[0m Training completed for Fold_7 with AUC: 0.6562718656574009\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23875)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_9 with AUC: 0.6707330028328613\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_37 with AUC: 0.630902336494281\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_10 with AUC: 0.6682490832896805\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_16 with AUC: 0.6273901019663731\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23739)\u001b[0m Training completed for Fold_28 with AUC: 0.6416915022150624\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_11 with AUC: 0.6315077755240027\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24109)\u001b[0m Training completed for Fold_8 with AUC: 0.632450763010304\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23992)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_15 with AUC: 0.637378856583978\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23677)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23848)\u001b[0m Training completed for Fold_18 with AUC: 0.6346348884381339\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_13 with AUC: 0.6497761946791074\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23961)\u001b[0m Training completed for Fold_41 with AUC: 0.6294335155122361\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=24136)\u001b[0m Training completed for Fold_17 with AUC: 0.6297740720817644\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23704)\u001b[0m Training completed for Fold_20 with AUC: 0.6615086720508407\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=23821)\u001b[0m Training completed for Fold_14 with AUC: 0.6168158503469778\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, hp, fmin, tpe\n",
    "from sklearn.model_selection import LeaveOneGroupOut, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ray import tune\n",
    "from ray.tune import with_parameters\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import traceback\n",
    "import ray\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    metrics: dict\n",
    "    duration: float\n",
    "\n",
    "def log(message: str):\n",
    "    print(message)  # Simple logging to stdout or enhance as needed\n",
    "\n",
    "def train_fold(dir_result: str, fold_name: str, X_train, y_train, X_test, y_test, C_cat, C_num, estimator, normalize, select, oversample, random_state):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        if normalize:\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "        \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            \n",
    "        if select:\n",
    "            # # Removing low variance features\n",
    "            # X_train = exclude_low_variance(X_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            # #Removing highly correlated features\n",
    "            # X_train = remove_pairwise_corr(X_train, outcome_variable= y_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            if isinstance(select, SelectFromModel):\n",
    "                select = [select]\n",
    "                \n",
    "            for i, s in enumerate(select):\n",
    "                C = np.asarray(X_train.columns)\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "\n",
    "        if oversample:\n",
    "            if len(C_cat) > 0:\n",
    "                sampler = SMOTENC(categorical_features=[X_train.columns.get_loc(c) for c in C_cat], random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator = clone(estimator).fit(X_train, y_train)\n",
    "        y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, y_pred, average=None)\n",
    "\n",
    "        result = FoldResult(\n",
    "            name=fold_name,\n",
    "            metrics={'AUC': auc_score},\n",
    "            duration=time.time() - start_time\n",
    "        )\n",
    "        log(f'Training completed for {fold_name} with AUC: {auc_score}')\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f'Error in {fold_name}: {traceback.format_exc()}')\n",
    "        return None\n",
    "\n",
    "def perform_cross_validation(X, y, groups, estimator, normalize=False, select=None, oversample=False, random_state=None):\n",
    "    if not ray.is_initialized():\n",
    "        ray.init()\n",
    "\n",
    "    futures = []\n",
    "    splitter = LeaveOneGroupOut()  # Or any other CV strategy\n",
    "    for idx, (train_idx, test_idx) in enumerate(splitter.split(X, y, groups)):\n",
    "        X_train_eval, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train_eval, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Split training set into internal training and evaluation sets\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(X_train_eval, y_train_eval, test_size=0.2, random_state=random_state)\n",
    "\n",
    "        C_cat = np.asarray(sorted(cats))\n",
    "        C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "        job = train_fold('path_to_results', f'Fold_{idx}', X_train, y_train, X_eval, y_eval, C_cat, C_num, estimator, normalize, select, oversample, random_state)\n",
    "        futures.append(job)\n",
    "\n",
    "    results = futures\n",
    "    return results\n",
    "\n",
    "def objective(params, X, y, groups):\n",
    "    SELECT_LASSO = SelectFromModel(\n",
    "            estimator=LogisticRegression(\n",
    "            penalty='l1' \n",
    "            ,solver='liblinear'\n",
    "            , C=1, random_state=RANDOM_STATE, max_iter=4000\n",
    "        ),\n",
    "        threshold = 0.005\n",
    "    )\n",
    "    # Example usage\n",
    "    estimator = EvXGBClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        eval_metric='logloss', \n",
    "        eval_size=0.2,\n",
    "        objective='binary:logistic', \n",
    "        verbosity=0,\n",
    "        **params\n",
    "    )  \n",
    "\n",
    "    results = perform_cross_validation(X, y, groups, estimator, normalize=True, select=[SELECT_LASSO], oversample=True, random_state=42)\n",
    "    auc_values = [results[i].metrics['AUC'] for i in range(len(results))]\n",
    "\n",
    "    mean_auc = np.mean(auc_values)\n",
    "    return {'loss': -mean_auc, 'auc': mean_auc, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(3, 11)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 250, 500]),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.5, 5.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'num_parallel_tree': hp.choice('num_parallel_tree', [1, 10, 20]),\n",
    "    'early_stopping_rounds': hp.choice('early_stopping_rounds', [10, 30, 50]),\n",
    "}\n",
    "\n",
    "# Setup HyperOpt search with Ray Tune\n",
    "algo = HyperOptSearch(space, metric=\"auc\", mode=\"max\")\n",
    "\n",
    "# Define the scheduler for early stopping\n",
    "scheduler = HyperBandScheduler(time_attr=\"training_iteration\", metric=\"auc\", mode=\"max\")\n",
    "with on_ray():\n",
    "    # Assuming X, y, and groups are predefined datasets\n",
    "    analysis = tune.run(\n",
    "        with_parameters(objective, X=X, y=y, groups=groups),\n",
    "        num_samples=100,\n",
    "        search_alg=algo,\n",
    "        resources_per_trial={\"cpu\": 1},\n",
    "        verbose=1,\n",
    "        scheduler=scheduler\n",
    "        \n",
    "    )\n",
    "\n",
    "# Train the final model using the best hyperparameters\n",
    "best_params = analysis.best_config\n",
    "final_estimator = EvXGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', \n",
    "    eval_size=0.2,\n",
    "    objective='binary:logistic', \n",
    "    verbosity=0,\n",
    "    **best_params\n",
    ")\n",
    "final_estimator.fit(X, y)\n",
    "\n",
    "# Evaluate on the final test set\n",
    "y_pred = final_estimator.predict_proba(X)[:, 1]\n",
    "final_auc = roc_auc_score(y, y_pred)\n",
    "print(f'Final AUC on the held-out test set: {final_auc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
