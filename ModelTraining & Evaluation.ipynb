{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback as tb\n",
    "from contextlib import contextmanager\n",
    "from typing import Tuple, Dict, Union, Generator, List\n",
    "from dataclasses import dataclass\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneGroupOut, StratifiedShuffleSplit, RepeatedStratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "import time\n",
    "import ray\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    estimator: BaseEstimator\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: np.ndarray\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: np.ndarray\n",
    "    categories: Dict[str, Dict[int, str]] = None\n",
    "\n",
    "\n",
    "def _split(\n",
    "        alg: str,\n",
    "        X: Union[pd.DataFrame, np.ndarray] = None,\n",
    "        y: np.ndarray = None,\n",
    "        groups: np.ndarray = None,\n",
    "        random_state: int = None,\n",
    "        n_splits: int = None,\n",
    "        n_repeats: int = None,\n",
    "        test_ratio: float = None\n",
    ") -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n",
    "    if alg == 'holdout':\n",
    "        splitter = StratifiedShuffleSplit(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif alg == 'kfold':\n",
    "        if n_repeats and n_repeats > 1:\n",
    "            splitter = RepeatedStratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                n_repeats=n_repeats,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "        else:\n",
    "            splitter = StratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                random_state=random_state,\n",
    "                shuffle=False if random_state is None else True,\n",
    "            )\n",
    "    elif alg == 'logo':\n",
    "        splitter = LeaveOneGroupOut()\n",
    "    elif alg == 'groupk':\n",
    "        splitter = GroupKFold(n_splits=n_splits \n",
    ")\n",
    "    else:\n",
    "        raise ValueError('\"alg\" should be one of \"holdout\", \"kfold\", \"logo\", or \"groupk\".')\n",
    "\n",
    "    split = splitter.split(X, y, groups)\n",
    "\n",
    "    for I_train, I_test in split:\n",
    "        yield I_train, I_test\n",
    "\n",
    "\n",
    "def _train(\n",
    "    dir_result: str,\n",
    "    name: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray,\n",
    "    C_cat: np.ndarray,\n",
    "    C_num: np.ndarray,\n",
    "    estimator: BaseEstimator,\n",
    "    normalize: bool = False,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None,\n",
    "    categories: Union[List, Dict[str, Dict[int, str]]] = None\n",
    "):\n",
    "    @contextmanager\n",
    "    def _log(task_type: str):\n",
    "        log(f'In progress: {task_type}.')\n",
    "        _t = time.time()\n",
    "        _err = None\n",
    "        _result = dict()\n",
    "        \n",
    "        try:\n",
    "            yield _result\n",
    "        except:\n",
    "            _err = tb.format_exc()\n",
    "        finally:\n",
    "            _e = time.time() - _t\n",
    "            if _err:\n",
    "                _msg = f'Failure: {task_type} ({_e:.2f}s). Keep running without this task. Caused by: \\n{_err}' \n",
    "            else:\n",
    "                _msg = f'Success: {task_type} ({_e:.2f}s).' \n",
    "                if _result:\n",
    "                    _r = '\\n'.join([f'- {k}: {v}' for k, v in _result.items()])\n",
    "                    _msg = f'{_msg}\\n{_r}'\n",
    "            log(_msg)\n",
    "    \n",
    "    if normalize:\n",
    "        with _log(f'[{name}] Normalizing numeric features'):\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "         \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "           \n",
    "    if select:\n",
    "        if isinstance(select, SelectFromModel):\n",
    "            select = [select]\n",
    "            \n",
    "        for i, s in enumerate(select):\n",
    "            with _log(f'[{name}] {i+1}-th Feature selection') as r:\n",
    "                C = np.asarray(X_train.columns)\n",
    "                r['# Orig. Feat.'] = f'{len(C)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                r['# Sel. Feat.'] = f'{len(C_sel)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "\n",
    "    if oversample:\n",
    "        with _log(f'[{name}] Oversampling') as r:\n",
    "            if len(C_cat):\n",
    "                M = np.isin(X_train.columns, C_cat)\n",
    "                sampler = SMOTENC(categorical_features=M, random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    with _log(f'[{name}] Training'):\n",
    "        estimator = estimator.fit(X_train, y_train)\n",
    "        result = FoldResult(\n",
    "            name=name,\n",
    "            estimator=estimator,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            categories=categories\n",
    "        )\n",
    "        dump(result, os.path.join(dir_result, f'{name}.pkl'))\n",
    "    \n",
    "\n",
    "def cross_val(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    groups: np.ndarray,\n",
    "    path: str,\n",
    "    name: str,\n",
    "    estimator: BaseEstimator,\n",
    "    categories: List[str] = None,\n",
    "    normalize: bool = False,\n",
    "    split: str = None,\n",
    "    split_params: Dict[str, any] = None,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None\n",
    "):\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError('\"path\" does not exist.')\n",
    "    \n",
    "    if not split:\n",
    "        raise ValueError('\"split\" should be specified.')\n",
    "    \n",
    "    if not ray.is_initialized():\n",
    "        raise EnvironmentError('\"ray\" should be initialized.')\n",
    "    \n",
    "    jobs = []\n",
    "    func = ray.remote(_train).remote\n",
    "\n",
    "    categories = list() if categories is None else categories\n",
    "    C_cat = np.asarray(sorted(categories))\n",
    "    C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "    split_params = split_params or dict()\n",
    "    splitter = _split(alg=split, X=X, y=y, groups=groups, random_state=random_state, **split_params)\n",
    "\n",
    "    for idx_fold, (I_train, I_test) in enumerate(splitter):\n",
    "        if split == 'logo':\n",
    "            FOLD_NAME = str(np.unique(groups[I_test]).item(0))\n",
    "        else:\n",
    "            FOLD_NAME = str(idx_fold + 1)\n",
    "\n",
    "        X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "        X_test, y_test = X.iloc[I_test, :], y[I_test]\n",
    "\n",
    "        job = func(\n",
    "            dir_result=path,\n",
    "            name=f'{name}#{FOLD_NAME}',\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            C_cat=C_cat,\n",
    "            C_num=C_num,\n",
    "            categories=categories,\n",
    "            estimator=clone(estimator),\n",
    "            normalize=normalize,\n",
    "            select=select,\n",
    "            oversample=oversample,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        jobs.append(job)\n",
    "    ray.get(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor Modification on XGBClassifer\n",
    "This modification allows XGBClassifiers to automatically generate evaluation sets during pipeline (without passing any argument in \"fit\" function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class EvXGBClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_size=None,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        self.random_state = random_state\n",
    "        self.eval_size = eval_size\n",
    "        self.eval_metric = eval_metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.model = XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            eval_metric=self.eval_metric,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    @property\n",
    "    def feature_names_in_(self):\n",
    "        return self.model.feature_names_in_\n",
    "\n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: np.ndarray):\n",
    "        if self.eval_size:\n",
    "            splitter = StratifiedShuffleSplit(random_state=self.random_state, test_size=self.eval_size)\n",
    "            I_train, I_eval = next(splitter.split(X, y))\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X.iloc[I_eval, :], y[I_eval]\n",
    "            else:\n",
    "                X_train, y_train = X[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X[I_eval, :], y[I_eval]\n",
    "                \n",
    "            self.model = self.model.fit(\n",
    "                X=X_train, y=y_train, \n",
    "                eval_set=[(X_eval, y_eval)],\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.model = self.model.fit(X=X, y=y, verbose=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 21:51:39,506\tINFO worker.py:1432 -- Connecting to existing Ray cluster at address: 192.168.1.28:6379...\n",
      "2023-05-28 21:51:39,523\tINFO worker.py:1616 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=45025)\u001b[0m [23-05-28 21:51:40] In progress: [dummy#P02] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=45025)\u001b[0m [23-05-28 21:51:40] Success: [dummy#P02] Normalizing numeric features (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=45025)\u001b[0m [23-05-28 21:51:40] In progress: [dummy#P02] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=1753780, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:41] Success: [dummy#P47] Training (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=1753780, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:42] Success: [dummy#P50] Training (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=1753780, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:42] Success: [dummy#P51] Training (0.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=1753918, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:46] In progress: [dummy#P72] Normalizing numeric features.\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753918, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:46] Success: [dummy#P72] Normalizing numeric features (0.08s).\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753918, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:46] In progress: [dummy#P72] Training.\u001b[32m [repeated 41x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:46] Success: [dummy#P77] Training (0.02s).\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753918, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:47] In progress: [dummy#P79] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753918, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:47] Success: [dummy#P79] Normalizing numeric features (0.09s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753918, ip=192.168.1.27)\u001b[0m [23-05-28 21:51:47] In progress: [dummy#P79] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46894)\u001b[0m [23-05-28 21:51:52] Success: [dummy#P42] Training (10.58s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46902)\u001b[0m [23-05-28 21:51:58] Success: [dummy#P05] Training (16.12s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46960)\u001b[0m [23-05-28 21:52:05] Success: [dummy#P19] Training (23.56s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46995)\u001b[0m [23-05-28 21:52:12] Success: [dummy#P30] Training (29.64s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:13] In progress: [rf_ns#P01] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:13] Success: [rf_ns#P01] Normalizing numeric features (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:13] In progress: [rf_ns#P01] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:14] Success: [rf_ns#P01] 1-th Feature selection (0.78s).\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m - # Sel. Feat.: 142 (# Cat. = 0; # Num. = 142)\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:14] In progress: [rf_ns#P01] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:16] Success: [rf_ns#P47] Training (1.09s).\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754881, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:18] In progress: [rf_ns#P61] Normalizing numeric features.\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754881, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:18] Success: [rf_ns#P61] Normalizing numeric features (0.09s).\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754881, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:18] In progress: [rf_ns#P61] 1-th Feature selection.\u001b[32m [repeated 37x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:19] Success: [rf_ns#P67] 1-th Feature selection (0.30s).\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m - # Sel. Feat.: 134 (# Cat. = 0; # Num. = 134)\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:19] In progress: [rf_ns#P67] Training.\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46995)\u001b[0m [23-05-28 21:52:21] Success: [rf_ns#P08] Training (7.10s).\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m [23-05-28 21:52:22] In progress: [rf_ns#P72] Normalizing numeric features.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m [23-05-28 21:52:22] Success: [rf_ns#P72] Normalizing numeric features (0.08s).\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m [23-05-28 21:52:22] In progress: [rf_ns#P72] 1-th Feature selection.\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m [23-05-28 21:52:22] Success: [rf_ns#P72] 1-th Feature selection (0.31s).\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 136 (# Cat. = 0; # Num. = 136)\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49158, ip=192.168.1.28)\u001b[0m [23-05-28 21:52:22] In progress: [rf_ns#P72] Training.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=49060, ip=192.168.1.28)\u001b[0m [23-05-28 21:52:27] Success: [rf_ns#P76] Training (4.94s).\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46981)\u001b[0m [23-05-28 21:52:33] Success: [rf_ns#P26] Training (18.32s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:37] In progress: [rf_os#P02] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:37] Success: [rf_os#P02] Normalizing numeric features (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:37] In progress: [rf_os#P02] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=47002)\u001b[0m [23-05-28 21:52:37] Success: [rf_ns#P79] Training (18.68s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:38] Success: [rf_os#P02] 1-th Feature selection (0.81s).\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m - # Sel. Feat.: 136 (# Cat. = 0; # Num. = 136)\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:38] In progress: [rf_os#P02] Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:38] Success: [rf_os#P02] Oversampling (0.18s).\n",
      "\u001b[2m\u001b[36m(_train pid=47023)\u001b[0m [23-05-28 21:52:38] In progress: [rf_os#P02] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:42] In progress: [rf_os#P72] Normalizing numeric features.\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:42] Success: [rf_os#P72] Normalizing numeric features (0.10s).\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:42] In progress: [rf_os#P72] 1-th Feature selection.\u001b[32m [repeated 40x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:43] Success: [rf_os#P69] Training (0.77s).\u001b[32m [repeated 19x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754698, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:43] Success: [rf_os#P76] 1-th Feature selection (0.44s).\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754698, ip=192.168.1.27)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754698, ip=192.168.1.27)\u001b[0m - # Sel. Feat.: 137 (# Cat. = 0; # Num. = 137)\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754698, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:43] In progress: [rf_os#P76] Oversampling.\u001b[32m [repeated 42x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754882, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:43] Success: [rf_os#P78] Oversampling (0.02s).\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754882, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:43] In progress: [rf_os#P78] Training.\u001b[32m [repeated 44x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:43] In progress: [rf_os#P79] Normalizing numeric features.\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:44] Success: [rf_os#P79] Normalizing numeric features (0.11s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:44] In progress: [rf_os#P79] 1-th Feature selection.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=47016)\u001b[0m [23-05-28 21:52:47] Success: [rf_os#P33] Training (8.76s).\u001b[32m [repeated 28x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:44] Success: [rf_os#P80] 1-th Feature selection (0.39s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m - # Sel. Feat.: 138 (# Cat. = 0; # Num. = 138)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:44] In progress: [rf_os#P80] Oversampling.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:44] Success: [rf_os#P80] Oversampling (0.02s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:44] In progress: [rf_os#P80] Training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1753912, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:52] In progress: [xgb_ns#P67] Normalizing numeric features.\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:52] Success: [xgb_ns#P69] Normalizing numeric features (0.10s).\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:52] In progress: [xgb_ns#P69] 1-th Feature selection.\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754882, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:53] Success: [xgb_ns#P60] Training (0.75s).\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:53] Success: [xgb_ns#P69] 1-th Feature selection (0.30s).\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m - # Sel. Feat.: 134 (# Cat. = 0; # Num. = 134)\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754925, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:53] In progress: [xgb_ns#P69] Training.\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46939)\u001b[0m [23-05-28 21:52:56] In progress: [xgb_os#P02] Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=47002)\u001b[0m [23-05-28 21:52:56] Success: [xgb_os#P01] Oversampling (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=1754882, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:57] In progress: [xgb_os#P50] Normalizing numeric features.\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:58] Success: [xgb_os#P51] Normalizing numeric features (0.08s).\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:58] In progress: [xgb_os#P51] 1-th Feature selection.\u001b[32m [repeated 38x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=46974)\u001b[0m [23-05-28 21:52:58] Success: [xgb_os#P03] Training (1.61s).\u001b[32m [repeated 29x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:58] Success: [xgb_os#P52] 1-th Feature selection (0.32s).\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m - # Sel. Feat.: 131 (# Cat. = 0; # Num. = 131)\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754904, ip=192.168.1.27)\u001b[0m [23-05-28 21:52:58] In progress: [xgb_os#P52] Training.\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:01] In progress: [xgb_os#P70] Oversampling.\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:01] Success: [xgb_os#P70] Oversampling (0.03s).\u001b[32m [repeated 39x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:01] In progress: [xgb_os#P80] Normalizing numeric features.\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:01] Success: [xgb_os#P80] Normalizing numeric features (0.11s).\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:01] In progress: [xgb_os#P80] 1-th Feature selection.\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754882, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:02] Success: [xgb_os#P77] Training (0.31s).\u001b[32m [repeated 34x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:02] Success: [xgb_os#P80] 1-th Feature selection (0.43s).\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m - # Sel. Feat.: 138 (# Cat. = 0; # Num. = 138)\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:02] In progress: [xgb_os#P80] Training.\u001b[32m [repeated 16x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:02] In progress: [xgb_os#P80] Oversampling.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=1754741, ip=192.168.1.27)\u001b[0m [23-05-28 21:53:02] Success: [xgb_os#P80] Oversampling (0.02s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from eli5.sklearn.permutation_importance import PermutationImportance\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "ESTIMATOR_DUMMY = DummyClassifier(strategy='prior')\n",
    "ESTIMATOR_RF = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "ESTIMATOR_XGB = EvXGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', \n",
    "    eval_size=0.2,\n",
    "    early_stopping_rounds=10, \n",
    "    objective='binary:logistic', \n",
    "    verbosity=0,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "SELECT_SVC = SelectFromModel(\n",
    "    estimator=LinearSVC(\n",
    "        penalty='l1',\n",
    "        loss='squared_hinge',\n",
    "        dual=False,\n",
    "        tol=1e-3,\n",
    "        C=1e-2,\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    threshold=1e-5\n",
    ")\n",
    "\n",
    "# CLS = ['valence', 'arousal', 'stress', 'disturbance']\n",
    "CLS = ['stress']\n",
    "SETTINGS = [\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_DUMMY),\n",
    "        oversample=False,\n",
    "        select=None,\n",
    "        name='dummy'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_os'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_os'\n",
    "    )\n",
    "]\n",
    "\n",
    "p = os.path.join(PATH_INTERMEDIATE, 'feat',f'stress.pkl')\n",
    "par_dir = os.path.join(PATH_INTERMEDIATE, 'eval', 'stress')\n",
    "\n",
    "if os.path.isdir(par_dir):\n",
    "    # Get a list of all the files in the folder\n",
    "    files = os.listdir(par_dir)\n",
    "\n",
    "    # Delete all the files in the folder\n",
    "    for file in files:\n",
    "        if file !='.ipynb_checkpoints':\n",
    "            os.remove(os.path.join(par_dir, file))\n",
    "os.makedirs(par_dir, exist_ok=True)\n",
    "\n",
    "#with on_ray(num_cpus=6):\n",
    "with on_ray():\n",
    "    for l, s in product(\n",
    "        CLS, SETTINGS\n",
    "    ):       \n",
    "        X, y, groups, t, datetimes = load(p)\n",
    "        #The following code is for excluding 1st day\n",
    "        ###########################################\n",
    "        filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_day.csv'),index_col=0)\n",
    "        X_filtered = X[X.index.isin(filtered_df.index)]\n",
    "        y_series = pd.Series(y, index=X.index)\n",
    "        y_filtered = y_series[y_series.index.isin(filtered_df.index)]\n",
    "        y_filtered = y_filtered.values\n",
    "        groups_series = pd.Series(groups, index=X.index)\n",
    "        groups_filtered = groups_series[groups_series.index.isin(filtered_df.index)]\n",
    "        groups_filtered = groups_filtered.values\n",
    "        X,y, groups=X_filtered,y_filtered, groups_filtered\n",
    "        \n",
    "        \n",
    "        ###########################################\n",
    "        #The following code is for similar-user model\n",
    "        ###########################################\n",
    "#         similar_user = pd.read_csv(os.path.join(PATH_INTERMEDIATE,  'similar_user.csv'))\n",
    "#         cluster_label = similar_user['cluster'].value_counts().index[0] #N number clusters\n",
    "#         similar_users_in_cluster = similar_user[similar_user['cluster'] == cluster_label]['pcode']\n",
    "\n",
    "#         # Check if each value in 'groups' is in 'similar_users_in_cluster'\n",
    "#         mask = np.isin(groups, similar_users_in_cluster)\n",
    "\n",
    "#         # Filter 'groups' based on the mask\n",
    "#         filtered_groups = groups[mask]\n",
    "#         # Filter 'X' and 'y' based on the mask\n",
    "#         X_filtered = X[mask]\n",
    "#         y_filtered = y[mask]\n",
    "#         X,y, groups=X_filtered,y_filtered, filtered_groups\n",
    "        ###########################################\n",
    "        \n",
    "        #Divide the features into different categories\n",
    "        feat_current = X.loc[:,[('#VAL' in str(x)) or ('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "        feat_dsc = X.loc[:,[('#DSC' in str(x))  for x in X.keys()]]  \n",
    "        feat_yesterday = X.loc[:,[('Yesterday' in str(x))  for x in X.keys()]]  \n",
    "        feat_today = X.loc[:,[('Today' in str(x))  for x in X.keys()]]  \n",
    "        feat_sleep = X.loc[:,[('Sleep' in str(x))  for x in X.keys()]]  \n",
    "        feat_time = X.loc[:,[('Time' in str(x))  for x in X.keys()]]  \n",
    "        feat_pif = X.loc[:,[('PIF' in str(x))  for x in X.keys()]]  \n",
    "        feat_ImmediatePast = X.loc[:,[('ImmediatePast' in str(x))  for x in X.keys()]]\n",
    "        #Divide the time window features into sensor/past stress label\n",
    "        feat_current_sensor = X.loc[:,[('#VAL' in str(x))  for x in X.keys()]]  \n",
    "        feat_current_ESM = X.loc[:,[('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "        feat_ImmediatePast_sensor = feat_ImmediatePast.loc[:,[('ESM' not in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "        feat_ImmediatePast_ESM = feat_ImmediatePast.loc[:,[('ESM'  in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "        feat_today_sensor = feat_today.loc[:,[('ESM' not in str(x)) for x in feat_today.keys()]]  \n",
    "        feat_today_ESM = feat_today.loc[:,[('ESM'  in str(x)) for x in feat_today.keys()]]  \n",
    "        feat_yesterday_sensor = feat_yesterday.loc[:,[('ESM' not in str(x)) for x in feat_yesterday.keys()]]  \n",
    "        feat_yesterday_ESM = feat_yesterday.loc[:,[('ESM'  in str(x)) for x in feat_yesterday.keys()]] \n",
    "        #Prepare the final feature set\n",
    "        feat_baseline = pd.concat([ feat_time,feat_dsc,feat_current_sensor, feat_ImmediatePast_sensor],axis=1)\n",
    "        feat_final = pd.concat([feat_current_ESM, feat_today_ESM, feat_today_sensor],axis=1)\n",
    "        X = feat_final\n",
    "        \n",
    "        cats = X.columns[X.dtypes == bool]\n",
    "        cross_val(\n",
    "            X=X, y=y, groups=groups,\n",
    "            path=par_dir,\n",
    "            categories=cats,\n",
    "            normalize=True,\n",
    "            split='logo',\n",
    "            split_params= {'n_splits' : 5},\n",
    "            random_state=RANDOM_STATE,\n",
    "            **s\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "from itertools import product\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, \\\n",
    "    confusion_matrix, precision_recall_fscore_support, \\\n",
    "    roc_auc_score, matthews_corrcoef, average_precision_score, \\\n",
    "    log_loss, brier_score_loss\n",
    "import scipy.stats.mstats as ms\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    classes: np.ndarray\n",
    ") -> Dict[str, any]:\n",
    "    R = {}\n",
    "    n_classes = len(classes)\n",
    "    is_multiclass = n_classes > 2\n",
    "    is_same_y = len(np.unique(y_true)) == 1\n",
    "    R['inst'] = len(y_true)\n",
    "    \n",
    "    for c in classes:\n",
    "        R[f'inst_{c}'] = np.sum(y_true == c)\n",
    "        \n",
    "    if not is_multiclass:\n",
    "        _, cnt = np.unique(y_true, return_counts=True)\n",
    "        \n",
    "        if len(cnt) > 1:\n",
    "            R['class_ratio'] = cnt[0] / cnt[1]\n",
    "        else:\n",
    "            R['class_ratio'] = np.nan\n",
    "\n",
    "    C = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=classes)\n",
    "    for (i1, c1), (i2, c2) in product(enumerate(classes), enumerate(classes)):\n",
    "        R[f'true_{c1}_pred_{c2}'] = C[i1, i2]\n",
    "\n",
    "    # Threshold Measure\n",
    "    R['acc'] = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['bac'] = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
    "    R['mcc'] = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    if is_multiclass:\n",
    "        for avg in ('macro', 'micro'):\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true,\n",
    "                y_pred=y_pred,\n",
    "                labels=classes,\n",
    "                average=avg, \n",
    "                zero_division=0\n",
    "            )\n",
    "            R[f'pre_{avg}'] = pre\n",
    "            R[f'rec_{avg}'] = rec\n",
    "            R[f'f1_{avg}'] = f1\n",
    "    else:\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true=y_true, y_pred=y_pred, pos_label=c, average='macro', zero_division=0\n",
    "        )\n",
    "        R[f'pre_macro'] = pre\n",
    "        R[f'rec_macro'] = rec\n",
    "        R[f'f1_macro'] = f1\n",
    "        \n",
    "        for c in classes:\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true, y_pred=y_pred, pos_label=c, average='binary', zero_division=0\n",
    "            )\n",
    "            R[f'pre_{c}'] = pre\n",
    "            R[f'rec_{c}'] = rec\n",
    "            R[f'f1_{c}'] = f1\n",
    "\n",
    "    # Ranking Measure\n",
    "    if is_multiclass:\n",
    "        for avg, mc in product(('macro', 'micro'), ('ovr', 'ovo')):\n",
    "            R[f'roauc_{avg}_{mc}'] = roc_auc_score(\n",
    "                y_true=y_true, y_score=y_prob,\n",
    "                average=avg, multi_class=mc, labels=classes\n",
    "            ) if not is_same_y else np.nan\n",
    "    else:\n",
    "        R[f'roauc'] = roc_auc_score(\n",
    "            y_true=y_true, y_score=y_prob[:, 1], average=None\n",
    "        ) if not is_same_y else np.nan\n",
    "        for i, c in enumerate(classes):\n",
    "            R[f'prauc_{c}'] = average_precision_score(\n",
    "                y_true=y_true, y_score=y_prob[:, i], pos_label=c, average=None\n",
    "            ) \n",
    "            R[f'prauc_ref_{c}'] = np.sum(y_true == c) / len(y_true)\n",
    "\n",
    "    # Probability Measure\n",
    "    R['log_loss'] = log_loss(y_true=y_true, y_pred=y_prob, labels=classes, normalize=True)\n",
    "\n",
    "    if not is_multiclass:\n",
    "        R[f'brier_loss'] = brier_score_loss(\n",
    "            y_true=y_true, y_prob=y_prob[:, 1], pos_label=classes[1]\n",
    "        )\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/tmp/ipykernel_32375/30616146.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_32375/30616146.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/tmp/ipykernel_32375/30616146.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/tmp/ipykernel_32375/30616146.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/tmp/ipykernel_32375/30616146.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
      "/home/iclab1209/miniconda3/envs/sci-data/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:891: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>split</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_inst</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>test_class_ratio</th>\n",
       "      <th>test_true_0_pred_0</th>\n",
       "      <th>test_true_0_pred_1</th>\n",
       "      <th>...</th>\n",
       "      <th>train_pre_1</th>\n",
       "      <th>train_rec_1</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_roauc</th>\n",
       "      <th>train_prauc_0</th>\n",
       "      <th>train_prauc_ref_0</th>\n",
       "      <th>train_prauc_1</th>\n",
       "      <th>train_prauc_ref_1</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>train_brier_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stress</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>P42</td>\n",
       "      <td>124</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954710</td>\n",
       "      <td>0.945291</td>\n",
       "      <td>0.949977</td>\n",
       "      <td>0.992216</td>\n",
       "      <td>0.992154</td>\n",
       "      <td>0.490402</td>\n",
       "      <td>0.992640</td>\n",
       "      <td>0.509598</td>\n",
       "      <td>0.173607</td>\n",
       "      <td>0.043792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stress</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>P49</td>\n",
       "      <td>135</td>\n",
       "      <td>70</td>\n",
       "      <td>48</td>\n",
       "      <td>22</td>\n",
       "      <td>2.181818</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951456</td>\n",
       "      <td>0.953139</td>\n",
       "      <td>0.952297</td>\n",
       "      <td>0.993132</td>\n",
       "      <td>0.993332</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.993232</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.169846</td>\n",
       "      <td>0.042335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>P55</td>\n",
       "      <td>131</td>\n",
       "      <td>49</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>1.227273</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937557</td>\n",
       "      <td>0.902741</td>\n",
       "      <td>0.919820</td>\n",
       "      <td>0.977657</td>\n",
       "      <td>0.975909</td>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.979965</td>\n",
       "      <td>0.515027</td>\n",
       "      <td>0.219437</td>\n",
       "      <td>0.061594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P52</td>\n",
       "      <td>131</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>12</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942910</td>\n",
       "      <td>0.897458</td>\n",
       "      <td>0.919623</td>\n",
       "      <td>0.977256</td>\n",
       "      <td>0.977019</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.978365</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.230496</td>\n",
       "      <td>0.063416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P69</td>\n",
       "      <td>134</td>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927456</td>\n",
       "      <td>0.905018</td>\n",
       "      <td>0.916100</td>\n",
       "      <td>0.976368</td>\n",
       "      <td>0.975964</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.978053</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.227396</td>\n",
       "      <td>0.063764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label     alg split  n_feature  test_inst  test_inst_0  test_inst_1  \\\n",
       "0  stress   rf_ns   P42        124         57           19           38   \n",
       "1  stress   rf_os   P49        135         70           48           22   \n",
       "2  stress  xgb_ns   P55        131         49           27           22   \n",
       "3  stress  xgb_os   P52        131         36           24           12   \n",
       "4  stress  xgb_os   P69        134         64           27           37   \n",
       "\n",
       "   test_class_ratio  test_true_0_pred_0  test_true_0_pred_1  ...  train_pre_1  \\\n",
       "0          0.500000                   9                  10  ...     0.954710   \n",
       "1          2.181818                  42                   6  ...     0.951456   \n",
       "2          1.227273                  23                   4  ...     0.937557   \n",
       "3          2.000000                  22                   2  ...     0.942910   \n",
       "4          0.729730                  27                   0  ...     0.927456   \n",
       "\n",
       "   train_rec_1  train_f1_1  train_roauc  train_prauc_0  train_prauc_ref_0  \\\n",
       "0     0.945291    0.949977     0.992216       0.992154           0.490402   \n",
       "1     0.953139    0.952297     0.993132       0.993332           0.500000   \n",
       "2     0.902741    0.919820     0.977657       0.975909           0.484973   \n",
       "3     0.897458    0.919623     0.977256       0.977019           0.500000   \n",
       "4     0.905018    0.916100     0.976368       0.975964           0.500000   \n",
       "\n",
       "   train_prauc_1  train_prauc_ref_1  train_log_loss  train_brier_loss  \n",
       "0       0.992640           0.509598        0.173607          0.043792  \n",
       "1       0.993232           0.500000        0.169846          0.042335  \n",
       "2       0.979965           0.515027        0.219437          0.061594  \n",
       "3       0.978365           0.500000        0.230496          0.063416  \n",
       "4       0.978053           0.500000        0.227396          0.063764  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "RESULTS_EVAL = []\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "#for l in ['valence', 'arousal', 'disturbance', 'stress']:\n",
    "for l in [ 'stress']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        if f == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        model, pid = f[:f.index('.pkl')].split('#')\n",
    "        res = load(os.path.join(dir_l, f))\n",
    "        X, y = res.X_test, res.y_test\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_prob = res.estimator.predict_proba(X)\n",
    "        ev_test = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_prob=y_prob,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        X, y = res.X_train, res.y_train\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_prob = res.estimator.predict_proba(X)\n",
    "        ev_train = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_prob=y_prob,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        RESULTS_EVAL.append({\n",
    "            'label': l,\n",
    "            'alg': model,\n",
    "            'split': pid,\n",
    "            'n_feature': len(X.columns),\n",
    "            **{\n",
    "                f'test_{k}': v for k, v in ev_test.items()\n",
    "            },\n",
    "            **{\n",
    "                f'train_{k}': v for k, v in ev_train.items()\n",
    "            }\n",
    "        })\n",
    "    \n",
    "RESULTS_EVAL = pd.DataFrame(RESULTS_EVAL)\n",
    "RESULTS_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>value_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>med</th>\n",
       "      <th>range</th>\n",
       "      <th>conf.</th>\n",
       "      <th>nan_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>split</td>\n",
       "      <td>47</td>\n",
       "      <td>47.0</td>\n",
       "      <td>P77:1, P13:1, P60:1, P80:1, P61:1, P23:1, P55:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>n_feature</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131177.0</td>\n",
       "      <td>2791.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2791.0</td>\n",
       "      <td>(2791, 2791)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2245.0</td>\n",
       "      <td>47.765957</td>\n",
       "      <td>11.591250</td>\n",
       "      <td>46.0</td>\n",
       "      <td>(30, 70)</td>\n",
       "      <td>(44.36263895311653, 51.1692759405005)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst_0</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>23.234043</td>\n",
       "      <td>12.724869</td>\n",
       "      <td>21.0</td>\n",
       "      <td>(0, 48)</td>\n",
       "      <td>(19.497881019487878, 26.9702040868951)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst_1</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>24.531915</td>\n",
       "      <td>13.051488</td>\n",
       "      <td>21.0</td>\n",
       "      <td>(4, 66)</td>\n",
       "      <td>(20.699854334552278, 28.363975452681764)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label    alg       metric   n  cardinality  \\\n",
       "0  stress  dummy        split  47         47.0   \n",
       "1  stress  dummy    n_feature  47          NaN   \n",
       "2  stress  dummy    test_inst  47          NaN   \n",
       "3  stress  dummy  test_inst_0  47          NaN   \n",
       "4  stress  dummy  test_inst_1  47          NaN   \n",
       "\n",
       "                                         value_count       sum         mean  \\\n",
       "0  P77:1, P13:1, P60:1, P80:1, P61:1, P23:1, P55:...       NaN          NaN   \n",
       "1                                                NaN  131177.0  2791.000000   \n",
       "2                                                NaN    2245.0    47.765957   \n",
       "3                                                NaN    1092.0    23.234043   \n",
       "4                                                NaN    1153.0    24.531915   \n",
       "\n",
       "          SD     med         range                                     conf.  \\\n",
       "0        NaN     NaN           NaN                                       NaN   \n",
       "1   0.000000  2791.0  (2791, 2791)                                (nan, nan)   \n",
       "2  11.591250    46.0      (30, 70)     (44.36263895311653, 51.1692759405005)   \n",
       "3  12.724869    21.0       (0, 48)    (19.497881019487878, 26.9702040868951)   \n",
       "4  13.051488    21.0       (4, 66)  (20.699854334552278, 28.363975452681764)   \n",
       "\n",
       "   nan_count  \n",
       "0        NaN  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SUMMARY_EVAL = []\n",
    "\n",
    "for row in RESULTS_EVAL.groupby(\n",
    "    ['label', 'alg']\n",
    ").agg(summary).reset_index().itertuples():\n",
    "    for k, v in row._asdict().items():\n",
    "        if type(v) is dict:\n",
    "            r = dict(\n",
    "                label=row.label,\n",
    "                alg=row.alg,\n",
    "                metric=k,\n",
    "                **v\n",
    "            )\n",
    "            SUMMARY_EVAL.append(r)\n",
    "\n",
    "SUMMARY_EVAL = pd.DataFrame(SUMMARY_EVAL)    \n",
    "SUMMARY_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"13\" halign=\"left\">mean_sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_bac</th>\n",
       "      <th>test_f1_0</th>\n",
       "      <th>test_f1_1</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>train_class_ratio</th>\n",
       "      <th>train_f1_0</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>train_inst_0</th>\n",
       "      <th>train_inst_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">stress</th>\n",
       "      <th>dummy</th>\n",
       "      <td>2791.0 (0.0)</td>\n",
       "      <td>0.511 (0.073)</td>\n",
       "      <td>0.001 (0.008)</td>\n",
       "      <td>0.627 (0.218)</td>\n",
       "      <td>0.325 (0.145)</td>\n",
       "      <td>23.234 (12.725)</td>\n",
       "      <td>24.532 (13.051)</td>\n",
       "      <td>0.947 (0.02)</td>\n",
       "      <td>0.014 (0.097)</td>\n",
       "      <td>0.664 (0.099)</td>\n",
       "      <td>0.339 (0.002)</td>\n",
       "      <td>1068.766 (12.725)</td>\n",
       "      <td>1128.468 (13.051)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ns</th>\n",
       "      <td>136.213 (4.452)</td>\n",
       "      <td>0.729 (0.108)</td>\n",
       "      <td>0.702 (0.239)</td>\n",
       "      <td>0.739 (0.163)</td>\n",
       "      <td>0.721 (0.108)</td>\n",
       "      <td>23.234 (12.725)</td>\n",
       "      <td>24.532 (13.051)</td>\n",
       "      <td>0.947 (0.02)</td>\n",
       "      <td>0.949 (0.001)</td>\n",
       "      <td>0.951 (0.001)</td>\n",
       "      <td>0.95 (0.001)</td>\n",
       "      <td>1068.766 (12.725)</td>\n",
       "      <td>1128.468 (13.051)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_os</th>\n",
       "      <td>136.213 (4.452)</td>\n",
       "      <td>0.725 (0.106)</td>\n",
       "      <td>0.71 (0.224)</td>\n",
       "      <td>0.727 (0.171)</td>\n",
       "      <td>0.719 (0.109)</td>\n",
       "      <td>23.234 (12.725)</td>\n",
       "      <td>24.532 (13.051)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.952 (0.001)</td>\n",
       "      <td>0.951 (0.001)</td>\n",
       "      <td>0.951 (0.001)</td>\n",
       "      <td>1128.532 (12.85)</td>\n",
       "      <td>1128.532 (12.85)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_ns</th>\n",
       "      <td>136.213 (4.452)</td>\n",
       "      <td>0.757 (0.09)</td>\n",
       "      <td>0.732 (0.215)</td>\n",
       "      <td>0.76 (0.145)</td>\n",
       "      <td>0.746 (0.101)</td>\n",
       "      <td>23.234 (12.725)</td>\n",
       "      <td>24.532 (13.051)</td>\n",
       "      <td>0.947 (0.02)</td>\n",
       "      <td>0.919 (0.006)</td>\n",
       "      <td>0.922 (0.006)</td>\n",
       "      <td>0.92 (0.006)</td>\n",
       "      <td>1068.766 (12.725)</td>\n",
       "      <td>1128.468 (13.051)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_os</th>\n",
       "      <td>136.213 (4.452)</td>\n",
       "      <td>0.752 (0.091)</td>\n",
       "      <td>0.73 (0.216)</td>\n",
       "      <td>0.749 (0.149)</td>\n",
       "      <td>0.739 (0.101)</td>\n",
       "      <td>23.234 (12.725)</td>\n",
       "      <td>24.532 (13.051)</td>\n",
       "      <td>1.0 (0.0)</td>\n",
       "      <td>0.923 (0.006)</td>\n",
       "      <td>0.921 (0.006)</td>\n",
       "      <td>0.922 (0.006)</td>\n",
       "      <td>1128.532 (12.85)</td>\n",
       "      <td>1128.532 (12.85)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean_sd                                               \\\n",
       "metric               n_feature       test_bac      test_f1_0      test_f1_1   \n",
       "label  alg                                                                    \n",
       "stress dummy      2791.0 (0.0)  0.511 (0.073)  0.001 (0.008)  0.627 (0.218)   \n",
       "       rf_ns   136.213 (4.452)  0.729 (0.108)  0.702 (0.239)  0.739 (0.163)   \n",
       "       rf_os   136.213 (4.452)  0.725 (0.106)   0.71 (0.224)  0.727 (0.171)   \n",
       "       xgb_ns  136.213 (4.452)   0.757 (0.09)  0.732 (0.215)   0.76 (0.145)   \n",
       "       xgb_os  136.213 (4.452)  0.752 (0.091)   0.73 (0.216)  0.749 (0.149)   \n",
       "\n",
       "                                                                \\\n",
       "metric         test_f1_macro      test_inst_0      test_inst_1   \n",
       "label  alg                                                       \n",
       "stress dummy   0.325 (0.145)  23.234 (12.725)  24.532 (13.051)   \n",
       "       rf_ns   0.721 (0.108)  23.234 (12.725)  24.532 (13.051)   \n",
       "       rf_os   0.719 (0.109)  23.234 (12.725)  24.532 (13.051)   \n",
       "       xgb_ns  0.746 (0.101)  23.234 (12.725)  24.532 (13.051)   \n",
       "       xgb_os  0.739 (0.101)  23.234 (12.725)  24.532 (13.051)   \n",
       "\n",
       "                                                                              \\\n",
       "metric        train_class_ratio     train_f1_0     train_f1_1 train_f1_macro   \n",
       "label  alg                                                                     \n",
       "stress dummy       0.947 (0.02)  0.014 (0.097)  0.664 (0.099)  0.339 (0.002)   \n",
       "       rf_ns       0.947 (0.02)  0.949 (0.001)  0.951 (0.001)   0.95 (0.001)   \n",
       "       rf_os          1.0 (0.0)  0.952 (0.001)  0.951 (0.001)  0.951 (0.001)   \n",
       "       xgb_ns      0.947 (0.02)  0.919 (0.006)  0.922 (0.006)   0.92 (0.006)   \n",
       "       xgb_os         1.0 (0.0)  0.923 (0.006)  0.921 (0.006)  0.922 (0.006)   \n",
       "\n",
       "                                                     \n",
       "metric              train_inst_0       train_inst_1  \n",
       "label  alg                                           \n",
       "stress dummy   1068.766 (12.725)  1128.468 (13.051)  \n",
       "       rf_ns   1068.766 (12.725)  1128.468 (13.051)  \n",
       "       rf_os    1128.532 (12.85)   1128.532 (12.85)  \n",
       "       xgb_ns  1068.766 (12.725)  1128.468 (13.051)  \n",
       "       xgb_os   1128.532 (12.85)   1128.532 (12.85)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_SUMMARY_EVAL = SUMMARY_EVAL.loc[\n",
    "    lambda x: x['metric'].isin(\n",
    "        ['n_feature', 'train_class_ratio', 'train_inst_0', 'train_inst_1', 'test_inst_0', 'test_inst_1', 'test_bac', 'test_f1_0' ,'test_f1_1', 'test_f1_macro', 'train_f1_0' ,'train_f1_1', 'train_f1_macro',]\n",
    "    )\n",
    "].round(3).assign(\n",
    "    mean_sd=lambda x: x['mean'].astype(str).str.cat(' (' + x['SD'].astype(str) + ')', sep='')\n",
    ").pivot(\n",
    "    index=['label', 'alg'], columns=['metric'], values=['mean_sd']\n",
    ")\n",
    "SUB_SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "\n",
    "\n",
    "def feature_importance(\n",
    "    estimator\n",
    "):\n",
    "    if not hasattr(estimator, 'feature_names_in_') or not hasattr(estimator, 'feature_importances_'):\n",
    "        return None\n",
    "    \n",
    "    names = estimator.feature_names_in_\n",
    "    importances = estimator.feature_importances_\n",
    "    \n",
    "    return names, importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "IMPORTANCE_EVAL = defaultdict(list)\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "# for l in ['valence', 'arousal', 'disturbance', 'stress']:\n",
    "for l in ['stress']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        if f!='.ipynb_checkpoints':\n",
    "            res = load(os.path.join(dir_l, f))\n",
    "\n",
    "            f_norm = f[:f.index('.pkl')]\n",
    "            alg = f_norm[:f.rindex('#')]\n",
    "\n",
    "            feat_imp = feature_importance(res.estimator)\n",
    "            if not feat_imp:\n",
    "                continue\n",
    "\n",
    "            names, importance = feat_imp\n",
    "            new_names = []\n",
    "            for n in names:\n",
    "                for c in res.categories:\n",
    "                    n = n.replace(f'{c}_', f'{c}=')\n",
    "                new_names.append(n)\n",
    "\n",
    "            d = pd.DataFrame(\n",
    "                importance.reshape(1, -1),\n",
    "                columns=new_names\n",
    "            )\n",
    "            IMPORTANCE_EVAL[(l, alg)].append(d)\n",
    "        \n",
    "\n",
    "IMPORTANCE_SUMMARY = []\n",
    "\n",
    "for (l, alg), v in IMPORTANCE_EVAL.items():\n",
    "    new_v = pd.concat(\n",
    "        v, axis=0\n",
    "    ).fillna(0.0).mean().reset_index().set_axis(\n",
    "        ['feature', 'importance'], axis=1\n",
    "    ).assign(\n",
    "        label=l,\n",
    "        alg=alg\n",
    "    )\n",
    "    IMPORTANCE_SUMMARY.append(new_v)\n",
    "    \n",
    "IMPORTANCE_SUMMARY = pd.concat(IMPORTANCE_SUMMARY, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attaching packages  tidyverse 1.3.2 \n",
      " ggplot2 3.4.0       purrr   1.0.0 \n",
      " tibble  3.1.8       dplyr   1.0.10\n",
      " tidyr   1.2.1       stringr 1.5.0 \n",
      " readr   2.1.3       forcats 0.5.2 \n",
      " Conflicts  tidyverse_conflicts() \n",
      " dplyr::filter() masks stats::filter()\n",
      " dplyr::lag()    masks stats::lag()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: sysfonts\n",
      "\n",
      "R[write to console]: Loading required package: showtextdb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggforce)\n",
    "library(ggpubr)\n",
    "library(showtext)\n",
    "library(rmcorr)\n",
    "library(patchwork)\n",
    "\n",
    "font_add_google(\n",
    "    name='Source Serif Pro',\n",
    "    family='ssp',\n",
    "    db_cache=FALSE\n",
    ")\n",
    "\n",
    "showtext_auto()\n",
    "\n",
    "THEME_DEFAULT <- theme_bw(\n",
    "    base_size=10,\n",
    "    base_family='ssp',\n",
    ") + theme(\n",
    "        axis.title.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "        axis.title.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "        axis.text.x=element_text(colour='grey20', size=10),\n",
    "        axis.text.y=element_text(colour='grey20', size=10),\n",
    "        strip.text.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "        strip.text.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "        legend.background=element_blank(),\n",
    "        legend.title=element_text(colour='grey20', size=10, face='bold'),\n",
    "        legend.text=element_text(colour='grey20', size=10),\n",
    "        legend.position='top',\n",
    "        legend.box.spacing= unit(0, 'cm'),\n",
    "        plot.subtitle=element_text(colour='grey20', size=10, hjust=.5),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panyu/miniconda3/envs/sci-data/lib/python3.9/site-packages/rpy2/robjects/pandas2ri.py:65: UserWarning: Error while trying to convert the column \"feature\". Fall back to string conversion. The error is: Series can only be of one type, or None (and here we have <class 'str'> and <class 'numpy.str_'>). If happening with a pandas DataFrame the method infer_objects() will normalize data types before conversion.\n",
      "  warnings.warn('Error while trying to convert '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i IMPORTANCE_SUMMARY -w 26 -h 32 -u cm\n",
    "\n",
    "plots <- list()\n",
    "\n",
    "#for (l in c('valence', 'arousal', 'stress', 'disturbance')) {\n",
    "for (l in c( 'stress')) {\n",
    "    data <- IMPORTANCE_SUMMARY %>% filter(\n",
    "        (label == l)\n",
    "    )\n",
    "\n",
    "    p_label <- ggplot() + geom_text(\n",
    "        aes(x=.5, y=.5),\n",
    "        label=str_to_title(l), \n",
    "        family='ssp', \n",
    "        fontface='bold',\n",
    "        size=4\n",
    "    ) + theme_void()\n",
    "\n",
    "    p_rf <- ggplot(\n",
    "        data %>% filter(alg == 'rf_os') %>% top_n(n=10, wt=importance),\n",
    "        aes(x=reorder(feature, -importance), y=importance),\n",
    "    ) + geom_col(\n",
    "    ) + THEME_DEFAULT + theme(\n",
    "        axis.text.x=element_text(angle=90, size=10, hjust=1, vjust=.5),\n",
    "        axis.title.x=element_blank(),\n",
    "        axis.title.y=element_blank()\n",
    "    ) + labs(\n",
    "        subtitle='Random Forest'\n",
    "    )\n",
    "    \n",
    "    p_xgb <- ggplot(\n",
    "        data %>% filter(alg == 'xgb_os') %>% top_n(n=10, wt=importance),\n",
    "        aes(x=reorder(feature, -importance), y=importance),\n",
    "    ) + geom_col(\n",
    "    ) + THEME_DEFAULT + theme(\n",
    "        axis.text.x=element_text(angle=90, size=10, hjust=1, vjust=.5),\n",
    "        axis.title.x=element_blank(),\n",
    "        axis.title.y=element_blank()\n",
    "    ) + labs(\n",
    "        subtitle='XGBoost'\n",
    "    )\n",
    "    \n",
    "    plots[[paste(l, 'label', sep='_')]] <- p_label\n",
    "    plots[[paste(l, 'rf', sep='_')]] <- p_rf\n",
    "    plots[[paste(l, 'xgb', sep='_')]] <- p_xgb\n",
    "}\n",
    "\n",
    "#p <- plots$arousal_label + plots$valence_label\n",
    "#p <- p / (plots$arousal_rf | plots$arousal_xgb | plots$valence_rf | plots$valence_xgb)\n",
    "#p <- p / (plots$stress_label + plots$disturbance_label)\n",
    "#p <- p / (plots$stress_rf | plots$stress_xgb | plots$disturbance_rf | plots$disturbance_xgb)\n",
    "p <- plots$stress_label \n",
    "p <- p / (plots$stress_rf | plots$stress_xgb)\n",
    "\n",
    "p <- p + plot_layout(\n",
    "    heights=c(1.1, 10, 1.1, 10)\n",
    ")\n",
    "\n",
    "ggsave(paste('./fig/imp.pdf'), plot=p, width=26, height=32, unit='cm', device=cairo_pdf)\n",
    "print(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
