{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import traceback as tb\n",
    "from contextlib import contextmanager\n",
    "from typing import Tuple, Dict, Union, Generator, List\n",
    "from dataclasses import dataclass\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.base import BaseEstimator, clone\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, LeaveOneGroupOut, StratifiedShuffleSplit, RepeatedStratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "import time\n",
    "import ray\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    estimator: BaseEstimator\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: np.ndarray\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: np.ndarray\n",
    "    categories: Dict[str, Dict[int, str]] = None\n",
    "\n",
    "\n",
    "def _split(\n",
    "        alg: str,\n",
    "        X: Union[pd.DataFrame, np.ndarray] = None,\n",
    "        y: np.ndarray = None,\n",
    "        groups: np.ndarray = None,\n",
    "        random_state: int = None,\n",
    "        n_splits: int = None,\n",
    "        n_repeats: int = None,\n",
    "        test_ratio: float = None\n",
    ") -> Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n",
    "    if alg == 'holdout':\n",
    "        splitter = StratifiedShuffleSplit(\n",
    "            n_splits=n_splits,\n",
    "            test_size=test_ratio,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif alg == 'kfold':\n",
    "        if n_repeats and n_repeats > 1:\n",
    "            splitter = RepeatedStratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                n_repeats=n_repeats,\n",
    "                random_state=random_state,\n",
    "            )\n",
    "        else:\n",
    "            splitter = StratifiedKFold(\n",
    "                n_splits=n_splits,\n",
    "                random_state=random_state,\n",
    "                shuffle=False if random_state is None else True,\n",
    "            )\n",
    "    elif alg == 'logo':\n",
    "        splitter = LeaveOneGroupOut()\n",
    "    elif alg == 'groupk':\n",
    "        splitter = GroupKFold(n_splits=n_splits \n",
    ")\n",
    "    else:\n",
    "        raise ValueError('\"alg\" should be one of \"holdout\", \"kfold\", \"logo\", or \"groupk\".')\n",
    "\n",
    "    split = splitter.split(X, y, groups)\n",
    "\n",
    "    for I_train, I_test in split:\n",
    "        yield I_train, I_test\n",
    "\n",
    "\n",
    "def _train(\n",
    "    dir_result: str,\n",
    "    name: str,\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_test: np.ndarray,\n",
    "    C_cat: np.ndarray,\n",
    "    C_num: np.ndarray,\n",
    "    estimator: BaseEstimator,\n",
    "    normalize: bool = False,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None,\n",
    "    categories: Union[List, Dict[str, Dict[int, str]]] = None\n",
    "):\n",
    "    @contextmanager\n",
    "    def _log(task_type: str):\n",
    "        log(f'In progress: {task_type}.')\n",
    "        _t = time.time()\n",
    "        _err = None\n",
    "        _result = dict()\n",
    "        \n",
    "        try:\n",
    "            yield _result\n",
    "        except:\n",
    "            _err = tb.format_exc()\n",
    "        finally:\n",
    "            _e = time.time() - _t\n",
    "            if _err:\n",
    "                _msg = f'Failure: {task_type} ({_e:.2f}s). Keep running without this task. Caused by: \\n{_err}' \n",
    "            else:\n",
    "                _msg = f'Success: {task_type} ({_e:.2f}s).' \n",
    "                if _result:\n",
    "                    _r = '\\n'.join([f'- {k}: {v}' for k, v in _result.items()])\n",
    "                    _msg = f'{_msg}\\n{_r}'\n",
    "            log(_msg)\n",
    "    \n",
    "    if normalize:\n",
    "        with _log(f'[{name}] Normalizing numeric features'):\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "         \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "           \n",
    "    if select:\n",
    "        if isinstance(select, SelectFromModel):\n",
    "            select = [select]\n",
    "            \n",
    "        for i, s in enumerate(select):\n",
    "            with _log(f'[{name}] {i+1}-th Feature selection') as r:\n",
    "                C = np.asarray(X_train.columns)\n",
    "                r['# Orig. Feat.'] = f'{len(C)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                r['# Sel. Feat.'] = f'{len(C_sel)} (# Cat. = {len(C_cat)}; # Num. = {len(C_num)})'\n",
    "\n",
    "    if oversample:\n",
    "        with _log(f'[{name}] Oversampling') as r:\n",
    "            if len(C_cat):\n",
    "                M = np.isin(X_train.columns, C_cat)\n",
    "                sampler = SMOTENC(categorical_features=M, random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    with _log(f'[{name}] Training'):\n",
    "        estimator = estimator.fit(X_train, y_train)\n",
    "        result = FoldResult(\n",
    "            name=name,\n",
    "            estimator=estimator,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            categories=categories\n",
    "        )\n",
    "        dump(result, os.path.join(dir_result, f'{name}.pkl'))\n",
    "    \n",
    "\n",
    "def cross_val(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    groups: np.ndarray,\n",
    "    path: str,\n",
    "    name: str,\n",
    "    estimator: BaseEstimator,\n",
    "    categories: List[str] = None,\n",
    "    normalize: bool = False,\n",
    "    split: str = None,\n",
    "    split_params: Dict[str, any] = None,\n",
    "    select: Union[List[SelectFromModel], SelectFromModel] = None,\n",
    "    oversample: bool = False,\n",
    "    random_state: int = None\n",
    "):\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError('\"path\" does not exist.')\n",
    "    \n",
    "    if not split:\n",
    "        raise ValueError('\"split\" should be specified.')\n",
    "    \n",
    "    if not ray.is_initialized():\n",
    "        raise EnvironmentError('\"ray\" should be initialized.')\n",
    "    \n",
    "    jobs = []\n",
    "    func = ray.remote(_train).remote\n",
    "\n",
    "    categories = list() if categories is None else categories\n",
    "    C_cat = np.asarray(sorted(categories))\n",
    "    C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "    split_params = split_params or dict()\n",
    "    splitter = _split(alg=split, X=X, y=y, groups=groups, random_state=random_state, **split_params)\n",
    "\n",
    "    for idx_fold, (I_train, I_test) in enumerate(splitter):\n",
    "        if split == 'logo':\n",
    "            FOLD_NAME = str(np.unique(groups[I_test]).item(0))\n",
    "        else:\n",
    "            FOLD_NAME = str(idx_fold + 1)\n",
    "\n",
    "        X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "        X_test, y_test = X.iloc[I_test, :], y[I_test]\n",
    "\n",
    "        job = func(\n",
    "            dir_result=path,\n",
    "            name=f'{name}#{FOLD_NAME}',\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            X_test=X_test,\n",
    "            y_test=y_test,\n",
    "            C_cat=C_cat,\n",
    "            C_num=C_num,\n",
    "            categories=categories,\n",
    "            estimator=clone(estimator),\n",
    "            normalize=normalize,\n",
    "            select=select,\n",
    "            oversample=oversample,\n",
    "            random_state=random_state\n",
    "        )\n",
    "        jobs.append(job)\n",
    "    ray.get(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor Modification on XGBClassifer\n",
    "This modification allows XGBClassifiers to automatically generate evaluation sets during pipeline (without passing any argument in \"fit\" function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class EvXGBClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_size=None,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        self.random_state = random_state\n",
    "        self.eval_size = eval_size\n",
    "        self.eval_metric = eval_metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.model = XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            eval_metric=self.eval_metric,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    @property\n",
    "    def feature_names_in_(self):\n",
    "        return self.model.feature_names_in_\n",
    "\n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: np.ndarray):\n",
    "        if self.eval_size:\n",
    "            splitter = StratifiedShuffleSplit(random_state=self.random_state, test_size=self.eval_size)\n",
    "            I_train, I_eval = next(splitter.split(X, y))\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X.iloc[I_eval, :], y[I_eval]\n",
    "            else:\n",
    "                X_train, y_train = X[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X[I_eval, :], y[I_eval]\n",
    "                \n",
    "            self.model = self.model.fit(\n",
    "                X=X_train, y=y_train, \n",
    "                eval_set=[(X_eval, y_eval)],\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.model = self.model.fit(X=X, y=y, verbose=False)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "        return self.model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-01 13:37:53,462\tINFO worker.py:1432 -- Connecting to existing Ray cluster at address: 192.168.1.28:6379...\n",
      "2023-06-01 13:37:53,507\tINFO worker.py:1616 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=157655)\u001b[0m [23-06-01 13:37:55] In progress: [dummy#P21] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=157670)\u001b[0m [23-06-01 13:37:55] Success: [dummy#P03] Normalizing numeric features (0.14s).\n",
      "\u001b[2m\u001b[36m(_train pid=157670)\u001b[0m [23-06-01 13:37:55] In progress: [dummy#P03] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=17122, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:01] In progress: [dummy#P47] Normalizing numeric features.\u001b[32m [repeated 25x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17072, ip=192.168.1.28)\u001b[0m [23-06-01 13:37:58] Success: [dummy#P45] Normalizing numeric features (0.11s).\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17072, ip=192.168.1.28)\u001b[0m [23-06-01 13:37:58] In progress: [dummy#P45] Training.\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157655)\u001b[0m [23-06-01 13:38:02] Success: [dummy#P21] Training (7.12s).\n",
      "\u001b[2m\u001b[36m(_train pid=17221, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:06] In progress: [dummy#P49] Normalizing numeric features.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17168, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:04] Success: [dummy#P48] Normalizing numeric features (0.11s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17168, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:04] In progress: [dummy#P48] Training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157663)\u001b[0m [23-06-01 13:38:08] Success: [dummy#P02] Training (12.77s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17072, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:12] In progress: [dummy#P51] Normalizing numeric features.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17268, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:10] Success: [dummy#P50] Normalizing numeric features (0.10s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17268, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:10] In progress: [dummy#P50] Training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m [23-06-01 13:38:13] Success: [dummy#P09] Training (17.44s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17391, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:17] In progress: [dummy#P53] Normalizing numeric features.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17323, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:16] Success: [dummy#P55] Normalizing numeric features (0.13s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17323, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:16] In progress: [dummy#P55] Training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157980)\u001b[0m [23-06-01 13:38:20] Success: [dummy#P26] Training (23.66s).\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:38:22] In progress: [dummy#P78] Normalizing numeric features.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17519, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:20] Success: [dummy#P60] Normalizing numeric features (0.09s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17519, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:20] In progress: [dummy#P60] Training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=158271)\u001b[0m [23-06-01 13:38:26] Success: [dummy#P33] Training (28.96s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:27] In progress: [dummy#P66] Normalizing numeric features.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17565, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:26] Success: [dummy#P61] Normalizing numeric features (0.09s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17565, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:26] In progress: [dummy#P61] Training.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157913)\u001b[0m [23-06-01 13:38:33] Success: [dummy#P76] Training (11.14s).\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:29] In progress: [dummy#P72] Normalizing numeric features.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:29] Success: [dummy#P72] Normalizing numeric features (0.13s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:29] In progress: [dummy#P72] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17168, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:39] Success: [dummy#P48] Training (34.81s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17221, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:45] Success: [dummy#P49] Training (38.53s).\n",
      "\u001b[2m\u001b[36m(_train pid=17268, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:49] Success: [dummy#P50] Training (38.74s).\n",
      "\u001b[2m\u001b[36m(_train pid=17322, ip=192.168.1.28)\u001b[0m [23-06-01 13:38:54] Success: [dummy#P52] Training (38.42s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17519, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:00] Success: [dummy#P60] Training (39.63s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:05] Success: [dummy#P72] Training (35.65s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:39:06] In progress: [rf_ns#P01] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:39:06] Success: [rf_ns#P01] Normalizing numeric features (0.13s).\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:39:06] In progress: [rf_ns#P01] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:39:07] Success: [rf_ns#P28] 1-th Feature selection (1.03s).\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m - # Sel. Feat.: 154 (# Cat. = 0; # Num. = 154)\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:39:07] In progress: [rf_ns#P28] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:39:10] Success: [rf_ns#P28] Training (2.86s).\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157655)\u001b[0m [23-06-01 13:39:06] In progress: [rf_ns#P42] Normalizing numeric features.\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157655)\u001b[0m [23-06-01 13:39:06] Success: [rf_ns#P42] Normalizing numeric features (0.38s).\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157655)\u001b[0m [23-06-01 13:39:06] In progress: [rf_ns#P42] 1-th Feature selection.\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m [23-06-01 13:39:07] Success: [rf_ns#P31] 1-th Feature selection (1.07s).\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m - # Sel. Feat.: 169 (# Cat. = 0; # Num. = 169)\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m [23-06-01 13:39:07] In progress: [rf_ns#P31] Training.\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157670)\u001b[0m [23-06-01 13:39:13] Success: [rf_ns#P35] Training (5.65s).\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:15] In progress: [rf_ns#P47] Normalizing numeric features.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:15] Success: [rf_ns#P47] Normalizing numeric features (0.11s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:15] In progress: [rf_ns#P47] 1-th Feature selection.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:16] Success: [rf_ns#P47] 1-th Feature selection (0.36s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 168 (# Cat. = 0; # Num. = 168)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:16] In progress: [rf_ns#P47] Training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:21] Success: [rf_ns#P48] Training (2.58s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:19] In progress: [rf_ns#P50] Normalizing numeric features.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:19] Success: [rf_ns#P50] Normalizing numeric features (0.10s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:19] In progress: [rf_ns#P50] 1-th Feature selection.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:23] Success: [rf_ns#P49] 1-th Feature selection (0.36s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 161 (# Cat. = 0; # Num. = 161)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:23] In progress: [rf_ns#P49] Training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:26] Success: [rf_ns#P51] Training (2.08s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:25] In progress: [rf_ns#P52] Normalizing numeric features.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:25] Success: [rf_ns#P52] Normalizing numeric features (0.11s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:25] In progress: [rf_ns#P52] 1-th Feature selection.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:29] Success: [rf_ns#P57] 1-th Feature selection (0.38s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 158 (# Cat. = 0; # Num. = 158)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:29] In progress: [rf_ns#P57] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:31] Success: [rf_ns#P57] Training (2.22s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:31] In progress: [rf_ns#P60] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:31] Success: [rf_ns#P60] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:31] In progress: [rf_ns#P60] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:32] Success: [rf_ns#P60] 1-th Feature selection (0.43s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 172 (# Cat. = 0; # Num. = 172)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:32] In progress: [rf_ns#P60] Training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:37] Success: [rf_ns#P61] Training (2.52s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:35] In progress: [rf_ns#P67] Normalizing numeric features.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:36] Success: [rf_ns#P67] Normalizing numeric features (0.11s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:36] In progress: [rf_ns#P67] 1-th Feature selection.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:38] Success: [rf_ns#P69] 1-th Feature selection (0.38s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 165 (# Cat. = 0; # Num. = 165)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:38] In progress: [rf_ns#P69] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:42] Success: [rf_ns#P70] Training (2.53s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:40] In progress: [rf_ns#P72] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:40] Success: [rf_ns#P72] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:40] In progress: [rf_ns#P72] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:43] Success: [rf_ns#P76] 1-th Feature selection (0.47s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 167 (# Cat. = 0; # Num. = 167)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:43] In progress: [rf_ns#P76] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17721, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:47] Success: [rf_ns#P77] Training (2.49s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:45] In progress: [rf_ns#P80] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:46] Success: [rf_ns#P80] Normalizing numeric features (0.11s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:46] In progress: [rf_ns#P80] 1-th Feature selection.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:46] Success: [rf_ns#P80] 1-th Feature selection (0.44s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 162 (# Cat. = 0; # Num. = 162)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:46] In progress: [rf_ns#P80] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157655)\u001b[0m [23-06-01 13:39:51] In progress: [rf_os#P08] Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=157691)\u001b[0m [23-06-01 13:39:51] Success: [rf_os#P12] Oversampling (0.11s).\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:39:49] Success: [rf_ns#P80] Training (3.05s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157747)\u001b[0m [23-06-01 13:39:50] In progress: [rf_os#P42] Normalizing numeric features.\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157829)\u001b[0m [23-06-01 13:39:50] Success: [rf_os#P26] Normalizing numeric features (0.33s).\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157829)\u001b[0m [23-06-01 13:39:50] In progress: [rf_os#P26] 1-th Feature selection.\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m [23-06-01 13:39:51] Success: [rf_os#P19] 1-th Feature selection (1.35s).\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m - # Sel. Feat.: 176 (# Cat. = 0; # Num. = 176)\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:39:52] In progress: [rf_os#P31] Training.\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m [23-06-01 13:39:51] In progress: [rf_os#P19] Oversampling.\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:39:52] Success: [rf_os#P31] Oversampling (0.10s).\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157698)\u001b[0m [23-06-01 13:39:58] Success: [rf_os#P19] Training (5.99s).\u001b[32m [repeated 20x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:12] In progress: [rf_os#P47] Normalizing numeric features.\n",
      "\u001b[2m\u001b[36m(_train pid=157662)\u001b[0m [23-06-01 13:39:58] Success: [rf_os#P21] Training (6.22s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:12] Success: [rf_os#P47] Normalizing numeric features (0.10s).\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:12] In progress: [rf_os#P47] 1-th Feature selection.\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:13] Success: [rf_os#P47] 1-th Feature selection (0.36s).\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 168 (# Cat. = 0; # Num. = 168)\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:13] In progress: [rf_os#P47] Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:13] Success: [rf_os#P47] Oversampling (0.06s).\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:13] In progress: [rf_os#P47] Training.\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:16] In progress: [rf_os#P51] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] Success: [rf_os#P48] Training (3.40s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] Success: [rf_os#P51] Normalizing numeric features (0.10s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] In progress: [rf_os#P51] 1-th Feature selection.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] Success: [rf_os#P51] 1-th Feature selection (0.40s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 164 (# Cat. = 0; # Num. = 164)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] In progress: [rf_os#P51] Oversampling.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] Success: [rf_os#P51] Oversampling (0.03s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:17] In progress: [rf_os#P51] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:23] In progress: [rf_os#P60] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] Success: [rf_os#P53] Training (2.94s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] Success: [rf_os#P55] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] In progress: [rf_os#P55] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] Success: [rf_os#P55] 1-th Feature selection (0.42s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 163 (# Cat. = 0; # Num. = 163)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] In progress: [rf_os#P55] Oversampling.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] Success: [rf_os#P55] Oversampling (0.03s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:22] In progress: [rf_os#P55] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:28] In progress: [rf_os#P70] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] Success: [rf_os#P61] Training (2.02s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] Success: [rf_os#P66] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] In progress: [rf_os#P66] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] Success: [rf_os#P66] 1-th Feature selection (0.46s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 162 (# Cat. = 0; # Num. = 162)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] In progress: [rf_os#P66] Oversampling.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] Success: [rf_os#P66] Oversampling (0.03s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:27] In progress: [rf_os#P66] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:33] In progress: [rf_os#P76] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:32] Success: [rf_os#P69] Training (2.16s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:32] Success: [rf_os#P75] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:32] In progress: [rf_os#P75] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:33] Success: [rf_os#P75] 1-th Feature selection (0.40s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 150 (# Cat. = 0; # Num. = 150)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:33] In progress: [rf_os#P75] Oversampling.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:33] Success: [rf_os#P75] Oversampling (0.03s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:33] In progress: [rf_os#P75] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:38] In progress: [rf_os#P80] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:38] Success: [rf_os#P77] Training (2.85s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:38] Success: [rf_os#P80] Normalizing numeric features (0.08s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:38] In progress: [rf_os#P80] 1-th Feature selection.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:39] Success: [rf_os#P80] 1-th Feature selection (0.43s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 162 (# Cat. = 0; # Num. = 162)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:39] In progress: [rf_os#P80] Oversampling.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:39] Success: [rf_os#P80] Oversampling (0.03s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:39] In progress: [rf_os#P80] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=157691)\u001b[0m [23-06-01 13:40:42] In progress: [xgb_ns#P23] Normalizing numeric features.\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:40:41] Success: [rf_os#P80] Training (2.41s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:40:42] Success: [xgb_ns#P08] Normalizing numeric features (0.18s).\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:40:42] In progress: [xgb_ns#P08] 1-th Feature selection.\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:40:43] Success: [xgb_ns#P08] 1-th Feature selection (1.13s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m - # Sel. Feat.: 158 (# Cat. = 0; # Num. = 158)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157712)\u001b[0m [23-06-01 13:40:43] In progress: [xgb_ns#P08] Training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:05] In progress: [xgb_ns#P47] Normalizing numeric features.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=158046)\u001b[0m [23-06-01 13:40:48] Success: [xgb_ns#P35] Training (3.89s).\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=158357)\u001b[0m [23-06-01 13:40:43] Success: [xgb_ns#P42] Normalizing numeric features (0.36s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=158357)\u001b[0m [23-06-01 13:40:43] In progress: [xgb_ns#P42] 1-th Feature selection.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157691)\u001b[0m [23-06-01 13:40:44] Success: [xgb_ns#P23] 1-th Feature selection (1.26s).\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157691)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157691)\u001b[0m - # Sel. Feat.: 166 (# Cat. = 0; # Num. = 166)\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157691)\u001b[0m [23-06-01 13:40:44] In progress: [xgb_ns#P23] Training.\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:09] In progress: [xgb_ns#P51] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:10] Success: [xgb_ns#P50] Training (1.25s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:10] Success: [xgb_ns#P51] Normalizing numeric features (0.11s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:10] In progress: [xgb_ns#P51] 1-th Feature selection.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:10] Success: [xgb_ns#P51] 1-th Feature selection (0.38s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 164 (# Cat. = 0; # Num. = 164)\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:10] In progress: [xgb_ns#P51] Training.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:15] In progress: [xgb_ns#P61] Normalizing numeric features.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:15] Success: [xgb_ns#P57] Training (1.16s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:15] Success: [xgb_ns#P61] Normalizing numeric features (0.10s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:15] In progress: [xgb_ns#P61] 1-th Feature selection.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:16] Success: [xgb_ns#P60] 1-th Feature selection (0.48s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 172 (# Cat. = 0; # Num. = 172)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:16] In progress: [xgb_ns#P60] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:20] In progress: [xgb_ns#P70] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:20] Success: [xgb_ns#P69] Training (1.11s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:20] Success: [xgb_ns#P70] Normalizing numeric features (0.08s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:20] In progress: [xgb_ns#P70] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:21] Success: [xgb_ns#P70] 1-th Feature selection (0.37s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 162 (# Cat. = 0; # Num. = 162)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:21] In progress: [xgb_ns#P70] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:26] In progress: [xgb_ns#P78] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:25] Success: [xgb_ns#P76] Training (1.29s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:25] Success: [xgb_ns#P77] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:25] In progress: [xgb_ns#P77] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:25] Success: [xgb_ns#P77] 1-th Feature selection (0.41s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 159 (# Cat. = 0; # Num. = 159)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:25] In progress: [xgb_ns#P77] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157747)\u001b[0m [23-06-01 13:41:30] In progress: [xgb_os#P30] Normalizing numeric features.\u001b[32m [repeated 22x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:29] Success: [xgb_ns#P79] Training (1.08s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157747)\u001b[0m [23-06-01 13:41:30] Success: [xgb_os#P30] Normalizing numeric features (0.34s).\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157747)\u001b[0m [23-06-01 13:41:30] In progress: [xgb_os#P30] 1-th Feature selection.\u001b[32m [repeated 15x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:28] Success: [xgb_ns#P79] 1-th Feature selection (0.36s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 155 (# Cat. = 0; # Num. = 155)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:41:28] In progress: [xgb_ns#P79] Training.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(_train pid=158381)\u001b[0m [23-06-01 13:41:31] In progress: [xgb_os#P08] Oversampling.\n",
      "\u001b[2m\u001b[36m(_train pid=158357)\u001b[0m [23-06-01 13:41:31] Success: [xgb_os#P05] Oversampling (0.07s).\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:03] In progress: [xgb_os#P45] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:41:35] Success: [xgb_os#P42] Training (3.60s).\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:41:31] Success: [xgb_os#P42] Normalizing numeric features (0.45s).\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:41:31] In progress: [xgb_os#P42] 1-th Feature selection.\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157663)\u001b[0m [23-06-01 13:41:32] Success: [xgb_os#P21] 1-th Feature selection (1.46s).\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157663)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157663)\u001b[0m - # Sel. Feat.: 164 (# Cat. = 0; # Num. = 164)\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:41:32] In progress: [xgb_os#P42] Training.\u001b[32m [repeated 24x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157663)\u001b[0m [23-06-01 13:41:32] In progress: [xgb_os#P21] Oversampling.\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=157705)\u001b[0m [23-06-01 13:41:32] Success: [xgb_os#P42] Oversampling (0.05s).\u001b[32m [repeated 23x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:06] In progress: [xgb_os#P53] Normalizing numeric features.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:08] Success: [xgb_os#P49] Training (1.50s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:07] Success: [xgb_os#P53] Normalizing numeric features (0.14s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17815, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:07] In progress: [xgb_os#P53] 1-th Feature selection.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:07] Success: [xgb_os#P50] 1-th Feature selection (0.64s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 165 (# Cat. = 0; # Num. = 165)\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:07] In progress: [xgb_os#P50] Training.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:07] In progress: [xgb_os#P50] Oversampling.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:07] Success: [xgb_os#P50] Oversampling (0.03s).\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:13] In progress: [xgb_os#P61] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:11] Success: [xgb_os#P55] Training (1.24s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:12] Success: [xgb_os#P60] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:12] In progress: [xgb_os#P60] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:12] Success: [xgb_os#P60] 1-th Feature selection (0.42s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 172 (# Cat. = 0; # Num. = 172)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:12] In progress: [xgb_os#P60] Training.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:12] In progress: [xgb_os#P60] Oversampling.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:12] Success: [xgb_os#P60] Oversampling (0.03s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:18] In progress: [xgb_os#P72] Normalizing numeric features.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:16] Success: [xgb_os#P67] Training (1.17s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:18] Success: [xgb_os#P72] Normalizing numeric features (0.09s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17676, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:18] In progress: [xgb_os#P72] 1-th Feature selection.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:17] Success: [xgb_os#P70] 1-th Feature selection (0.37s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 162 (# Cat. = 0; # Num. = 162)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:17] In progress: [xgb_os#P70] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:17] In progress: [xgb_os#P70] Oversampling.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:17] Success: [xgb_os#P70] Oversampling (0.03s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:22] In progress: [xgb_os#P78] Normalizing numeric features.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17566, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:23] Success: [xgb_os#P77] Training (1.22s).\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:22] Success: [xgb_os#P78] Normalizing numeric features (0.11s).\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:22] In progress: [xgb_os#P78] 1-th Feature selection.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:23] Success: [xgb_os#P78] 1-th Feature selection (0.44s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 169 (# Cat. = 0; # Num. = 169)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:23] In progress: [xgb_os#P78] Training.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:23] In progress: [xgb_os#P78] Oversampling.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:23] Success: [xgb_os#P78] Oversampling (0.03s).\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:24] In progress: [xgb_os#P80] Normalizing numeric features.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:26] Success: [xgb_os#P80] Training (1.22s).\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:24] Success: [xgb_os#P80] Normalizing numeric features (0.11s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:24] In progress: [xgb_os#P80] 1-th Feature selection.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:25] Success: [xgb_os#P80] 1-th Feature selection (0.44s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Orig. Feat.: 2791 (# Cat. = 0; # Num. = 2791)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m - # Sel. Feat.: 162 (# Cat. = 0; # Num. = 162)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:25] In progress: [xgb_os#P80] Training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:25] In progress: [xgb_os#P80] Oversampling.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(_train pid=17769, ip=192.168.1.28)\u001b[0m [23-06-01 13:42:25] Success: [xgb_os#P80] Oversampling (0.03s).\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import product\n",
    "from sklearn.base import clone\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from eli5.sklearn.permutation_importance import PermutationImportance\n",
    "\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "ESTIMATOR_DUMMY = DummyClassifier(strategy='prior')\n",
    "ESTIMATOR_RF = RandomForestClassifier(random_state=RANDOM_STATE)\n",
    "ESTIMATOR_XGB = EvXGBClassifier(\n",
    "    random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', \n",
    "    eval_size=0.2,\n",
    "    early_stopping_rounds=10, \n",
    "    objective='binary:logistic', \n",
    "    verbosity=0,\n",
    "    learning_rate=0.01\n",
    ")\n",
    "\n",
    "SELECT_SVC = SelectFromModel(\n",
    "    estimator=LinearSVC(\n",
    "        penalty='l1',\n",
    "        loss='squared_hinge',\n",
    "        dual=False,\n",
    "        tol=1e-3,\n",
    "        C=1e-2,\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    threshold=1e-5\n",
    ")\n",
    "\n",
    "# CLS = ['valence', 'arousal', 'stress', 'disturbance']\n",
    "CLS = ['stress']\n",
    "SETTINGS = [\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_DUMMY),\n",
    "        oversample=False,\n",
    "        select=None,\n",
    "        name='dummy'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_RF),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='rf_os'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=False,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_ns'\n",
    "    ),\n",
    "    dict(\n",
    "        estimator=clone(ESTIMATOR_XGB),\n",
    "        oversample=True,\n",
    "        select=[clone(SELECT_SVC)],\n",
    "        name='xgb_os'\n",
    "    )\n",
    "]\n",
    "\n",
    "p = os.path.join(PATH_INTERMEDIATE, 'feat',f'stress.pkl')\n",
    "par_dir = os.path.join(PATH_INTERMEDIATE, 'eval', 'stress')\n",
    "\n",
    "if os.path.isdir(par_dir):\n",
    "    # Get a list of all the files in the folder\n",
    "    files = os.listdir(par_dir)\n",
    "\n",
    "    # Delete all the files in the folder\n",
    "    for file in files:\n",
    "        if file !='.ipynb_checkpoints':\n",
    "            os.remove(os.path.join(par_dir, file))\n",
    "os.makedirs(par_dir, exist_ok=True)\n",
    "\n",
    "#with on_ray(num_cpus=6):\n",
    "with on_ray():\n",
    "    for l, s in product(\n",
    "        CLS, SETTINGS\n",
    "    ):       \n",
    "        X, y, groups, t, datetimes = load(p)\n",
    "        #The following code is for excluding 1st day\n",
    "        ###########################################\n",
    "#         filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_day.csv'),index_col=0)\n",
    "#         X_filtered = X[X.index.isin(filtered_df.index)]\n",
    "#         y_series = pd.Series(y, index=X.index)\n",
    "#         y_filtered = y_series[y_series.index.isin(filtered_df.index)]\n",
    "#         y_filtered = y_filtered.values\n",
    "#         groups_series = pd.Series(groups, index=X.index)\n",
    "#         groups_filtered = groups_series[groups_series.index.isin(filtered_df.index)]\n",
    "#         groups_filtered = groups_filtered.values\n",
    "#         X,y, groups=X_filtered,y_filtered, groups_filtered\n",
    "        \n",
    "        \n",
    "        ###########################################\n",
    "        #The following code is for similar-user model\n",
    "        ###########################################\n",
    "#         similar_user = pd.read_csv(os.path.join(PATH_INTERMEDIATE,  'similar_user.csv'))\n",
    "#         cluster_label = similar_user['cluster'].value_counts().index[0] #N number clusters\n",
    "#         similar_users_in_cluster = similar_user[similar_user['cluster'] == cluster_label]['pcode']\n",
    "\n",
    "#         # Check if each value in 'groups' is in 'similar_users_in_cluster'\n",
    "#         mask = np.isin(groups, similar_users_in_cluster)\n",
    "\n",
    "#         # Filter 'groups' based on the mask\n",
    "#         filtered_groups = groups[mask]\n",
    "#         # Filter 'X' and 'y' based on the mask\n",
    "#         X_filtered = X[mask]\n",
    "#         y_filtered = y[mask]\n",
    "#         X,y, groups=X_filtered,y_filtered, filtered_groups\n",
    "        ###########################################\n",
    "        \n",
    "        #Divide the features into different categories\n",
    "        feat_current = X.loc[:,[('#VAL' in str(x)) or ('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "        feat_dsc = X.loc[:,[('#DSC' in str(x))  for x in X.keys()]]  \n",
    "        feat_yesterday = X.loc[:,[('Yesterday' in str(x))  for x in X.keys()]]  \n",
    "        feat_today = X.loc[:,[('Today' in str(x))  for x in X.keys()]]  \n",
    "        feat_sleep = X.loc[:,[('Sleep' in str(x))  for x in X.keys()]]  \n",
    "        feat_time = X.loc[:,[('Time' in str(x))  for x in X.keys()]]  \n",
    "        feat_pif = X.loc[:,[('PIF' in str(x))  for x in X.keys()]]  \n",
    "        feat_ImmediatePast = X.loc[:,[('ImmediatePast' in str(x))  for x in X.keys()]]\n",
    "        #Divide the time window features into sensor/past stress label\n",
    "        feat_current_sensor = X.loc[:,[('#VAL' in str(x))  for x in X.keys()]]  \n",
    "        feat_current_ESM = X.loc[:,[('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "        feat_ImmediatePast_sensor = feat_ImmediatePast.loc[:,[('ESM' not in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "        feat_ImmediatePast_ESM = feat_ImmediatePast.loc[:,[('ESM'  in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "        feat_today_sensor = feat_today.loc[:,[('ESM' not in str(x)) for x in feat_today.keys()]]  \n",
    "        feat_today_ESM = feat_today.loc[:,[('ESM'  in str(x)) for x in feat_today.keys()]]  \n",
    "        feat_yesterday_sensor = feat_yesterday.loc[:,[('ESM' not in str(x)) for x in feat_yesterday.keys()]]  \n",
    "        feat_yesterday_ESM = feat_yesterday.loc[:,[('ESM'  in str(x)) for x in feat_yesterday.keys()]] \n",
    "        #Prepare the final feature set\n",
    "        feat_baseline = pd.concat([ feat_time,feat_dsc,feat_current_sensor, feat_ImmediatePast_sensor],axis=1)\n",
    "        feat_final = pd.concat([feat_current_ESM, feat_today_ESM, feat_today_sensor],axis=1)\n",
    "        X = feat_final\n",
    "        \n",
    "        cats = X.columns[X.dtypes == bool]\n",
    "        cross_val(\n",
    "            X=X, y=y, groups=groups,\n",
    "            path=par_dir,\n",
    "            categories=cats,\n",
    "            normalize=True,\n",
    "            split='logo',\n",
    "            split_params= {'n_splits' : 5},\n",
    "            random_state=RANDOM_STATE,\n",
    "            **s\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "from itertools import product\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, \\\n",
    "    confusion_matrix, precision_recall_fscore_support, \\\n",
    "    roc_auc_score, matthews_corrcoef, average_precision_score, \\\n",
    "    log_loss, brier_score_loss\n",
    "import scipy.stats.mstats as ms\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    classes: np.ndarray\n",
    ") -> Dict[str, any]:\n",
    "    R = {}\n",
    "    n_classes = len(classes)\n",
    "    is_multiclass = n_classes > 2\n",
    "    is_same_y = len(np.unique(y_true)) == 1\n",
    "    R['inst'] = len(y_true)\n",
    "    \n",
    "    for c in classes:\n",
    "        R[f'inst_{c}'] = np.sum(y_true == c)\n",
    "        \n",
    "    if not is_multiclass:\n",
    "        _, cnt = np.unique(y_true, return_counts=True)\n",
    "        \n",
    "        if len(cnt) > 1:\n",
    "            R['class_ratio'] = cnt[0] / cnt[1]\n",
    "        else:\n",
    "            R['class_ratio'] = np.nan\n",
    "\n",
    "    C = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=classes)\n",
    "    for (i1, c1), (i2, c2) in product(enumerate(classes), enumerate(classes)):\n",
    "        R[f'true_{c1}_pred_{c2}'] = C[i1, i2]\n",
    "\n",
    "    # Threshold Measure\n",
    "    R['acc'] = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['bac'] = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
    "    R['mcc'] = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    if is_multiclass:\n",
    "        for avg in ('macro', 'micro'):\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true,\n",
    "                y_pred=y_pred,\n",
    "                labels=classes,\n",
    "                average=avg, \n",
    "                zero_division=0\n",
    "            )\n",
    "            R[f'pre_{avg}'] = pre\n",
    "            R[f'rec_{avg}'] = rec\n",
    "            R[f'f1_{avg}'] = f1\n",
    "    else:\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true=y_true, y_pred=y_pred, pos_label=c, average='macro', zero_division=0\n",
    "        )\n",
    "        R[f'pre_macro'] = pre\n",
    "        R[f'rec_macro'] = rec\n",
    "        R[f'f1_macro'] = f1\n",
    "        \n",
    "        for c in classes:\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true, y_pred=y_pred, pos_label=c, average='binary', zero_division=0\n",
    "            )\n",
    "            R[f'pre_{c}'] = pre\n",
    "            R[f'rec_{c}'] = rec\n",
    "            R[f'f1_{c}'] = f1\n",
    "\n",
    "    # Ranking Measure\n",
    "    if is_multiclass:\n",
    "        for avg, mc in product(('macro', 'micro'), ('ovr', 'ovo')):\n",
    "            R[f'roauc_{avg}_{mc}'] = roc_auc_score(\n",
    "                y_true=y_true, y_score=y_prob,\n",
    "                average=avg, multi_class=mc, labels=classes\n",
    "            ) if not is_same_y else np.nan\n",
    "    else:\n",
    "        R[f'roauc'] = roc_auc_score(\n",
    "            y_true=y_true, y_score=y_prob[:, 1], average=None\n",
    "        ) if not is_same_y else np.nan\n",
    "        for i, c in enumerate(classes):\n",
    "            R[f'prauc_{c}'] = average_precision_score(\n",
    "                y_true=y_true, y_score=y_prob[:, i], pos_label=c, average=None\n",
    "            ) \n",
    "            R[f'prauc_ref_{c}'] = np.sum(y_true == c) / len(y_true)\n",
    "\n",
    "    # Probability Measure\n",
    "    R['log_loss'] = log_loss(y_true=y_true, y_pred=y_prob, labels=classes, normalize=True)\n",
    "\n",
    "    if not is_multiclass:\n",
    "        R[f'brier_loss'] = brier_score_loss(\n",
    "            y_true=y_true, y_prob=y_prob[:, 1], pos_label=classes[1]\n",
    "        )\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>split</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_inst</th>\n",
       "      <th>test_inst_0</th>\n",
       "      <th>test_inst_1</th>\n",
       "      <th>test_class_ratio</th>\n",
       "      <th>test_true_0_pred_0</th>\n",
       "      <th>test_true_0_pred_1</th>\n",
       "      <th>...</th>\n",
       "      <th>train_pre_1</th>\n",
       "      <th>train_rec_1</th>\n",
       "      <th>train_f1_1</th>\n",
       "      <th>train_roauc</th>\n",
       "      <th>train_prauc_0</th>\n",
       "      <th>train_prauc_ref_0</th>\n",
       "      <th>train_prauc_1</th>\n",
       "      <th>train_prauc_ref_1</th>\n",
       "      <th>train_log_loss</th>\n",
       "      <th>train_brier_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stress</td>\n",
       "      <td>rf_ns</td>\n",
       "      <td>P42</td>\n",
       "      <td>161</td>\n",
       "      <td>70</td>\n",
       "      <td>26</td>\n",
       "      <td>44</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938319</td>\n",
       "      <td>0.928299</td>\n",
       "      <td>0.933282</td>\n",
       "      <td>0.985573</td>\n",
       "      <td>0.985343</td>\n",
       "      <td>0.485681</td>\n",
       "      <td>0.986671</td>\n",
       "      <td>0.514319</td>\n",
       "      <td>0.202637</td>\n",
       "      <td>0.054969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stress</td>\n",
       "      <td>rf_os</td>\n",
       "      <td>P49</td>\n",
       "      <td>161</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>2.434783</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.948353</td>\n",
       "      <td>0.951201</td>\n",
       "      <td>0.949775</td>\n",
       "      <td>0.992938</td>\n",
       "      <td>0.993139</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.993078</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.172625</td>\n",
       "      <td>0.043121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_ns</td>\n",
       "      <td>P55</td>\n",
       "      <td>163</td>\n",
       "      <td>56</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "      <td>1.240000</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.910494</td>\n",
       "      <td>0.887218</td>\n",
       "      <td>0.898705</td>\n",
       "      <td>0.967643</td>\n",
       "      <td>0.965015</td>\n",
       "      <td>0.481077</td>\n",
       "      <td>0.971773</td>\n",
       "      <td>0.518923</td>\n",
       "      <td>0.259718</td>\n",
       "      <td>0.075721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P52</td>\n",
       "      <td>167</td>\n",
       "      <td>43</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>1.529412</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912943</td>\n",
       "      <td>0.885650</td>\n",
       "      <td>0.899090</td>\n",
       "      <td>0.966267</td>\n",
       "      <td>0.965106</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.969325</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.265852</td>\n",
       "      <td>0.076844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>P69</td>\n",
       "      <td>165</td>\n",
       "      <td>76</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.915615</td>\n",
       "      <td>0.886937</td>\n",
       "      <td>0.901048</td>\n",
       "      <td>0.969860</td>\n",
       "      <td>0.969367</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.972186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.247157</td>\n",
       "      <td>0.071452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label     alg split  n_feature  test_inst  test_inst_0  test_inst_1  \\\n",
       "0  stress   rf_ns   P42        161         70           26           44   \n",
       "1  stress   rf_os   P49        161         79           56           23   \n",
       "2  stress  xgb_ns   P55        163         56           31           25   \n",
       "3  stress  xgb_os   P52        167         43           26           17   \n",
       "4  stress  xgb_os   P69        165         76           30           46   \n",
       "\n",
       "   test_class_ratio  test_true_0_pred_0  test_true_0_pred_1  ...  train_pre_1  \\\n",
       "0          0.590909                  11                  15  ...     0.938319   \n",
       "1          2.434783                  49                   7  ...     0.948353   \n",
       "2          1.240000                  21                  10  ...     0.910494   \n",
       "3          1.529412                  24                   2  ...     0.912943   \n",
       "4          0.652174                  22                   8  ...     0.915615   \n",
       "\n",
       "   train_rec_1  train_f1_1  train_roauc  train_prauc_0  train_prauc_ref_0  \\\n",
       "0     0.928299    0.933282     0.985573       0.985343           0.485681   \n",
       "1     0.951201    0.949775     0.992938       0.993139           0.500000   \n",
       "2     0.887218    0.898705     0.967643       0.965015           0.481077   \n",
       "3     0.885650    0.899090     0.966267       0.965106           0.500000   \n",
       "4     0.886937    0.901048     0.969860       0.969367           0.500000   \n",
       "\n",
       "   train_prauc_1  train_prauc_ref_1  train_log_loss  train_brier_loss  \n",
       "0       0.986671           0.514319        0.202637          0.054969  \n",
       "1       0.993078           0.500000        0.172625          0.043121  \n",
       "2       0.971773           0.518923        0.259718          0.075721  \n",
       "3       0.969325           0.500000        0.265852          0.076844  \n",
       "4       0.972186           0.500000        0.247157          0.071452  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "RESULTS_EVAL = []\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "#for l in ['valence', 'arousal', 'disturbance', 'stress']:\n",
    "for l in [ 'stress']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        if f == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        model, pid = f[:f.index('.pkl')].split('#')\n",
    "        res = load(os.path.join(dir_l, f))\n",
    "        X, y = res.X_test, res.y_test\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_prob = res.estimator.predict_proba(X)\n",
    "        ev_test = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_prob=y_prob,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        X, y = res.X_train, res.y_train\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        y_prob = res.estimator.predict_proba(X)\n",
    "        ev_train = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_prob=y_prob,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "\n",
    "        RESULTS_EVAL.append({\n",
    "            'label': l,\n",
    "            'alg': model,\n",
    "            'split': pid,\n",
    "            'n_feature': len(X.columns),\n",
    "            **{\n",
    "                f'test_{k}': v for k, v in ev_test.items()\n",
    "            },\n",
    "            **{\n",
    "                f'train_{k}': v for k, v in ev_train.items()\n",
    "            }\n",
    "        })\n",
    "    \n",
    "RESULTS_EVAL = pd.DataFrame(RESULTS_EVAL)\n",
    "RESULTS_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_xgbos = RESULTS_EVAL[RESULTS_EVAL['alg']=='xgb_os']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_performance = RESULTS_xgbos['test_f1_macro'] >= 0.761\n",
    "RESULTS_xgbos_high_performance = RESULTS_xgbos[mask_performance]\n",
    "RESULTS_xgbos_low_performance = RESULTS_xgbos[~mask_performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>test_inst</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P69</td>\n",
       "      <td>76</td>\n",
       "      <td>0.902574</td>\n",
       "      <td>0.754839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P30</td>\n",
       "      <td>70</td>\n",
       "      <td>0.900250</td>\n",
       "      <td>0.702634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>P61</td>\n",
       "      <td>73</td>\n",
       "      <td>0.900284</td>\n",
       "      <td>0.759868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>P15</td>\n",
       "      <td>39</td>\n",
       "      <td>0.880132</td>\n",
       "      <td>0.756467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>P26</td>\n",
       "      <td>76</td>\n",
       "      <td>0.920059</td>\n",
       "      <td>0.703896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>P78</td>\n",
       "      <td>50</td>\n",
       "      <td>0.915614</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>P60</td>\n",
       "      <td>61</td>\n",
       "      <td>0.881966</td>\n",
       "      <td>0.651030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>P01</td>\n",
       "      <td>40</td>\n",
       "      <td>0.909527</td>\n",
       "      <td>0.720635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>P45</td>\n",
       "      <td>38</td>\n",
       "      <td>0.901308</td>\n",
       "      <td>0.744108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>P53</td>\n",
       "      <td>76</td>\n",
       "      <td>0.922332</td>\n",
       "      <td>0.709722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>P31</td>\n",
       "      <td>53</td>\n",
       "      <td>0.915188</td>\n",
       "      <td>0.745663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>P42</td>\n",
       "      <td>70</td>\n",
       "      <td>0.896968</td>\n",
       "      <td>0.668561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>P39</td>\n",
       "      <td>60</td>\n",
       "      <td>0.901205</td>\n",
       "      <td>0.718603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>P75</td>\n",
       "      <td>73</td>\n",
       "      <td>0.917443</td>\n",
       "      <td>0.746087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>P51</td>\n",
       "      <td>63</td>\n",
       "      <td>0.912087</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>P35</td>\n",
       "      <td>51</td>\n",
       "      <td>0.921722</td>\n",
       "      <td>0.655405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>P49</td>\n",
       "      <td>79</td>\n",
       "      <td>0.928673</td>\n",
       "      <td>0.740558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>P55</td>\n",
       "      <td>56</td>\n",
       "      <td>0.896917</td>\n",
       "      <td>0.672965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>P76</td>\n",
       "      <td>65</td>\n",
       "      <td>0.922886</td>\n",
       "      <td>0.745865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>P28</td>\n",
       "      <td>83</td>\n",
       "      <td>0.890427</td>\n",
       "      <td>0.477987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>P09</td>\n",
       "      <td>55</td>\n",
       "      <td>0.902056</td>\n",
       "      <td>0.663529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>P21</td>\n",
       "      <td>50</td>\n",
       "      <td>0.918173</td>\n",
       "      <td>0.753695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>P79</td>\n",
       "      <td>36</td>\n",
       "      <td>0.891837</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>P50</td>\n",
       "      <td>43</td>\n",
       "      <td>0.921422</td>\n",
       "      <td>0.743393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>P13</td>\n",
       "      <td>54</td>\n",
       "      <td>0.892639</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split  test_inst  train_f1_macro  test_f1_macro\n",
       "4     P69         76        0.902574       0.754839\n",
       "14    P30         70        0.900250       0.702634\n",
       "23    P61         73        0.900284       0.759868\n",
       "24    P15         39        0.880132       0.756467\n",
       "31    P26         76        0.920059       0.703896\n",
       "33    P78         50        0.915614       0.555556\n",
       "34    P60         61        0.881966       0.651030\n",
       "35    P01         40        0.909527       0.720635\n",
       "37    P45         38        0.901308       0.744108\n",
       "44    P53         76        0.922332       0.709722\n",
       "50    P31         53        0.915188       0.745663\n",
       "52    P42         70        0.896968       0.668561\n",
       "83    P39         60        0.901205       0.718603\n",
       "91    P75         73        0.917443       0.746087\n",
       "92    P51         63        0.912087       0.742857\n",
       "114   P35         51        0.921722       0.655405\n",
       "122   P49         79        0.928673       0.740558\n",
       "135   P55         56        0.896917       0.672965\n",
       "153   P76         65        0.922886       0.745865\n",
       "170   P28         83        0.890427       0.477987\n",
       "172   P09         55        0.902056       0.663529\n",
       "175   P21         50        0.918173       0.753695\n",
       "193   P79         36        0.891837       0.657143\n",
       "200   P50         43        0.921422       0.743393\n",
       "226   P13         54        0.892639       0.727273"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_xgbos_low_performance[['split','test_inst','train_f1_macro','test_f1_macro']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>train_f1_macro</th>\n",
       "      <th>test_f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P52</td>\n",
       "      <td>0.900576</td>\n",
       "      <td>0.795238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P33</td>\n",
       "      <td>0.913528</td>\n",
       "      <td>0.820040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>P19</td>\n",
       "      <td>0.922106</td>\n",
       "      <td>0.780220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>P48</td>\n",
       "      <td>0.909642</td>\n",
       "      <td>0.831818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>P08</td>\n",
       "      <td>0.912387</td>\n",
       "      <td>0.874903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>P40</td>\n",
       "      <td>0.915500</td>\n",
       "      <td>0.813725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>P57</td>\n",
       "      <td>0.925048</td>\n",
       "      <td>0.849073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>P72</td>\n",
       "      <td>0.916899</td>\n",
       "      <td>0.867771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>P67</td>\n",
       "      <td>0.914622</td>\n",
       "      <td>0.768430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>P70</td>\n",
       "      <td>0.912291</td>\n",
       "      <td>0.905371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>P02</td>\n",
       "      <td>0.904669</td>\n",
       "      <td>0.851744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>P80</td>\n",
       "      <td>0.905831</td>\n",
       "      <td>0.779135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>P05</td>\n",
       "      <td>0.882844</td>\n",
       "      <td>0.847761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>P03</td>\n",
       "      <td>0.893652</td>\n",
       "      <td>0.908333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>P06</td>\n",
       "      <td>0.908798</td>\n",
       "      <td>0.831034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>P47</td>\n",
       "      <td>0.926755</td>\n",
       "      <td>0.834052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>P12</td>\n",
       "      <td>0.898301</td>\n",
       "      <td>0.799604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>P32</td>\n",
       "      <td>0.903268</td>\n",
       "      <td>0.792663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>P23</td>\n",
       "      <td>0.916587</td>\n",
       "      <td>0.775915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>P66</td>\n",
       "      <td>0.906973</td>\n",
       "      <td>0.763038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>P77</td>\n",
       "      <td>0.914362</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>P10</td>\n",
       "      <td>0.912303</td>\n",
       "      <td>0.870879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    split  train_f1_macro  test_f1_macro\n",
       "3     P52        0.900576       0.795238\n",
       "8     P33        0.913528       0.820040\n",
       "15    P19        0.922106       0.780220\n",
       "16    P48        0.909642       0.831818\n",
       "28    P08        0.912387       0.874903\n",
       "38    P40        0.915500       0.813725\n",
       "85    P57        0.925048       0.849073\n",
       "89    P72        0.916899       0.867771\n",
       "106   P67        0.914622       0.768430\n",
       "107   P70        0.912291       0.905371\n",
       "112   P02        0.904669       0.851744\n",
       "121   P80        0.905831       0.779135\n",
       "138   P05        0.882844       0.847761\n",
       "141   P03        0.893652       0.908333\n",
       "165   P06        0.908798       0.831034\n",
       "167   P47        0.926755       0.834052\n",
       "171   P12        0.898301       0.799604\n",
       "188   P32        0.903268       0.792663\n",
       "195   P23        0.916587       0.775915\n",
       "211   P66        0.906973       0.763038\n",
       "228   P77        0.914362       0.909091\n",
       "232   P10        0.912303       0.870879"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_xgbos_high_performance[['split','train_f1_macro','test_f1_macro']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following code is for cluster analysis\n",
    "# pcode_to_cluster = dict(zip(similar_user['pcode'], similar_user['cluster']))\n",
    "# RESULTS_EVAL['cluster'] = RESULTS_EVAL['split'].map(pcode_to_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>value_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>med</th>\n",
       "      <th>range</th>\n",
       "      <th>conf.</th>\n",
       "      <th>nan_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>split</td>\n",
       "      <td>47</td>\n",
       "      <td>47.0</td>\n",
       "      <td>P77:1, P13:1, P60:1, P80:1, P61:1, P23:1, P55:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>n_feature</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>131177.0</td>\n",
       "      <td>2791.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2791.0</td>\n",
       "      <td>(2791, 2791)</td>\n",
       "      <td>(nan, nan)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2619.0</td>\n",
       "      <td>55.723404</td>\n",
       "      <td>13.076202</td>\n",
       "      <td>52.0</td>\n",
       "      <td>(36, 83)</td>\n",
       "      <td>(51.88408763344431, 59.56272087719398)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst_0</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1264.0</td>\n",
       "      <td>26.893617</td>\n",
       "      <td>14.547126</td>\n",
       "      <td>26.0</td>\n",
       "      <td>(2, 56)</td>\n",
       "      <td>(22.622420860143833, 31.16481318240936)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stress</td>\n",
       "      <td>dummy</td>\n",
       "      <td>test_inst_1</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1355.0</td>\n",
       "      <td>28.829787</td>\n",
       "      <td>15.207720</td>\n",
       "      <td>25.0</td>\n",
       "      <td>(6, 81)</td>\n",
       "      <td>(24.364633393179524, 33.29494107490558)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label    alg       metric   n  cardinality  \\\n",
       "0  stress  dummy        split  47         47.0   \n",
       "1  stress  dummy    n_feature  47          NaN   \n",
       "2  stress  dummy    test_inst  47          NaN   \n",
       "3  stress  dummy  test_inst_0  47          NaN   \n",
       "4  stress  dummy  test_inst_1  47          NaN   \n",
       "\n",
       "                                         value_count       sum         mean  \\\n",
       "0  P77:1, P13:1, P60:1, P80:1, P61:1, P23:1, P55:...       NaN          NaN   \n",
       "1                                                NaN  131177.0  2791.000000   \n",
       "2                                                NaN    2619.0    55.723404   \n",
       "3                                                NaN    1264.0    26.893617   \n",
       "4                                                NaN    1355.0    28.829787   \n",
       "\n",
       "          SD     med         range                                    conf.  \\\n",
       "0        NaN     NaN           NaN                                      NaN   \n",
       "1   0.000000  2791.0  (2791, 2791)                               (nan, nan)   \n",
       "2  13.076202    52.0      (36, 83)   (51.88408763344431, 59.56272087719398)   \n",
       "3  14.547126    26.0       (2, 56)  (22.622420860143833, 31.16481318240936)   \n",
       "4  15.207720    25.0       (6, 81)  (24.364633393179524, 33.29494107490558)   \n",
       "\n",
       "   nan_count  \n",
       "0        NaN  \n",
       "1        0.0  \n",
       "2        0.0  \n",
       "3        0.0  \n",
       "4        0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SUMMARY_EVAL = []\n",
    "\n",
    "for row in RESULTS_EVAL.groupby(\n",
    "#    ['label', 'alg', 'cluster']\n",
    "     ['label', 'alg']\n",
    ").agg(summary).reset_index().itertuples():\n",
    "    for k, v in row._asdict().items():\n",
    "        if type(v) is dict:\n",
    "            r = dict(\n",
    "                label=row.label,\n",
    "                alg=row.alg,\n",
    "#                 cluster = row.cluster,\n",
    "                metric=k,\n",
    "                **v\n",
    "            )\n",
    "            SUMMARY_EVAL.append(r)\n",
    "\n",
    "SUMMARY_EVAL = pd.DataFrame(SUMMARY_EVAL)    \n",
    "SUMMARY_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">mean_sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_bac</th>\n",
       "      <th>test_f1_0</th>\n",
       "      <th>test_f1_1</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_roauc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">stress</th>\n",
       "      <th>dummy</th>\n",
       "      <td>2791.0 (0.0)</td>\n",
       "      <td>0.5 (0.0)</td>\n",
       "      <td>0.0 (0.0)</td>\n",
       "      <td>0.652 (0.2)</td>\n",
       "      <td>0.326 (0.1)</td>\n",
       "      <td>0.5 (0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_ns</th>\n",
       "      <td>163.489 (5.465)</td>\n",
       "      <td>0.715 (0.082)</td>\n",
       "      <td>0.711 (0.18)</td>\n",
       "      <td>0.725 (0.173)</td>\n",
       "      <td>0.718 (0.084)</td>\n",
       "      <td>0.837 (0.072)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf_os</th>\n",
       "      <td>163.489 (5.465)</td>\n",
       "      <td>0.715 (0.089)</td>\n",
       "      <td>0.718 (0.183)</td>\n",
       "      <td>0.717 (0.174)</td>\n",
       "      <td>0.717 (0.089)</td>\n",
       "      <td>0.841 (0.074)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_ns</th>\n",
       "      <td>163.489 (5.465)</td>\n",
       "      <td>0.76 (0.095)</td>\n",
       "      <td>0.743 (0.173)</td>\n",
       "      <td>0.764 (0.132)</td>\n",
       "      <td>0.754 (0.093)</td>\n",
       "      <td>0.881 (0.062)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgb_os</th>\n",
       "      <td>163.489 (5.465)</td>\n",
       "      <td>0.767 (0.094)</td>\n",
       "      <td>0.751 (0.181)</td>\n",
       "      <td>0.772 (0.133)</td>\n",
       "      <td>0.761 (0.087)</td>\n",
       "      <td>0.879 (0.064)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean_sd                                               \\\n",
       "metric               n_feature       test_bac      test_f1_0      test_f1_1   \n",
       "label  alg                                                                    \n",
       "stress dummy      2791.0 (0.0)      0.5 (0.0)      0.0 (0.0)    0.652 (0.2)   \n",
       "       rf_ns   163.489 (5.465)  0.715 (0.082)   0.711 (0.18)  0.725 (0.173)   \n",
       "       rf_os   163.489 (5.465)  0.715 (0.089)  0.718 (0.183)  0.717 (0.174)   \n",
       "       xgb_ns  163.489 (5.465)   0.76 (0.095)  0.743 (0.173)  0.764 (0.132)   \n",
       "       xgb_os  163.489 (5.465)  0.767 (0.094)  0.751 (0.181)  0.772 (0.133)   \n",
       "\n",
       "                                             \n",
       "metric         test_f1_macro     test_roauc  \n",
       "label  alg                                   \n",
       "stress dummy     0.326 (0.1)      0.5 (0.0)  \n",
       "       rf_ns   0.718 (0.084)  0.837 (0.072)  \n",
       "       rf_os   0.717 (0.089)  0.841 (0.074)  \n",
       "       xgb_ns  0.754 (0.093)  0.881 (0.062)  \n",
       "       xgb_os  0.761 (0.087)  0.879 (0.064)  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SUB_SUMMARY_EVAL = SUMMARY_EVAL[SUMMARY_EVAL['alg']=='xgb_os'].loc[\n",
    "SUB_SUMMARY_EVAL = SUMMARY_EVAL.loc[\n",
    "    lambda x: x['metric'].isin(\n",
    "#        ['n_feature', 'train_class_ratio', 'train_inst_0', 'train_inst_1', 'test_inst_0', 'test_inst_1', 'test_bac', 'test_f1_0' ,'test_f1_1', 'test_f1_macro', 'train_f1_0' ,'train_f1_1', 'train_f1_macro','test_roauc']\n",
    "        ['n_feature', 'test_bac', 'test_f1_0' ,'test_f1_1', 'test_f1_macro','test_roauc']\n",
    "    )\n",
    "].round(3).assign(\n",
    "    mean_sd=lambda x: x['mean'].astype(str).str.cat(' (' + x['SD'].astype(str) + ')', sep='')\n",
    ").pivot(\n",
    "#    index=['label', 'alg', 'cluster'], columns=['metric'], values=['mean_sd']\n",
    "    index=['label', 'alg'], columns=['metric'], values=['mean_sd']\n",
    ")\n",
    "SUB_SUMMARY_EVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Optional\n",
    "\n",
    "\n",
    "def feature_importance(\n",
    "    estimator\n",
    "):\n",
    "    if not hasattr(estimator, 'feature_names_in_') or not hasattr(estimator, 'feature_importances_'):\n",
    "        return None\n",
    "    \n",
    "    names = estimator.feature_names_in_\n",
    "    importances = estimator.feature_importances_\n",
    "    \n",
    "    return names, importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "IMPORTANCE_EVAL = defaultdict(list)\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "\n",
    "# for l in ['valence', 'arousal', 'disturbance', 'stress']:\n",
    "for l in ['stress']:\n",
    "    dir_l = os.path.join(DIR_EVAL, l)\n",
    "    if not os.path.exists(dir_l):\n",
    "        continue\n",
    "    \n",
    "    for f in os.listdir(dir_l):\n",
    "        if f!='.ipynb_checkpoints':\n",
    "            res = load(os.path.join(dir_l, f))\n",
    "\n",
    "            f_norm = f[:f.index('.pkl')]\n",
    "            alg = f_norm[:f.rindex('#')]\n",
    "\n",
    "            feat_imp = feature_importance(res.estimator)\n",
    "            if not feat_imp:\n",
    "                continue\n",
    "\n",
    "            names, importance = feat_imp\n",
    "            new_names = []\n",
    "            for n in names:\n",
    "                for c in res.categories:\n",
    "                    n = n.replace(f'{c}_', f'{c}=')\n",
    "                new_names.append(n)\n",
    "\n",
    "            d = pd.DataFrame(\n",
    "                importance.reshape(1, -1),\n",
    "                columns=new_names\n",
    "            )\n",
    "            IMPORTANCE_EVAL[(l, alg)].append(d)\n",
    "        \n",
    "\n",
    "IMPORTANCE_SUMMARY = []\n",
    "\n",
    "for (l, alg), v in IMPORTANCE_EVAL.items():\n",
    "    new_v = pd.concat(\n",
    "        v, axis=0\n",
    "    ).fillna(0.0).mean().reset_index().set_axis(\n",
    "        ['feature', 'importance'], axis=1\n",
    "    ).assign(\n",
    "        label=l,\n",
    "        alg=alg\n",
    "    )\n",
    "    IMPORTANCE_SUMMARY.append(new_v)\n",
    "    \n",
    "IMPORTANCE_SUMMARY = pd.concat(IMPORTANCE_SUMMARY, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Attaching packages  tidyverse 1.3.2 \n",
      " ggplot2 3.4.0       purrr   1.0.0 \n",
      " tibble  3.1.8       dplyr   1.0.10\n",
      " tidyr   1.2.1       stringr 1.5.0 \n",
      " readr   2.1.3       forcats 0.5.2 \n",
      " Conflicts  tidyverse_conflicts() \n",
      " dplyr::filter() masks stats::filter()\n",
      " dplyr::lag()    masks stats::lag()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: sysfonts\n",
      "\n",
      "R[write to console]: Loading required package: showtextdb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(tidyverse)\n",
    "library(ggforce)\n",
    "library(ggpubr)\n",
    "library(showtext)\n",
    "library(rmcorr)\n",
    "library(patchwork)\n",
    "\n",
    "font_add_google(\n",
    "    name='Source Serif Pro',\n",
    "    family='ssp',\n",
    "    db_cache=FALSE\n",
    ")\n",
    "\n",
    "showtext_auto()\n",
    "\n",
    "THEME_DEFAULT <- theme_bw(\n",
    "    base_size=10,\n",
    "    base_family='ssp',\n",
    ") + theme(\n",
    "        axis.title.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "        axis.title.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "        axis.text.x=element_text(colour='grey20', size=10),\n",
    "        axis.text.y=element_text(colour='grey20', size=10),\n",
    "        strip.text.x=element_text(colour='grey20', size=10, face='bold'),\n",
    "        strip.text.y=element_text(colour='grey20', size=10, face='bold'),\n",
    "        legend.background=element_blank(),\n",
    "        legend.title=element_text(colour='grey20', size=10, face='bold'),\n",
    "        legend.text=element_text(colour='grey20', size=10),\n",
    "        legend.position='top',\n",
    "        legend.box.spacing= unit(0, 'cm'),\n",
    "        plot.subtitle=element_text(colour='grey20', size=10, hjust=.5),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panyu/miniconda3/envs/sci-data/lib/python3.9/site-packages/rpy2/robjects/pandas2ri.py:65: UserWarning: Error while trying to convert the column \"feature\". Fall back to string conversion. The error is: Series can only be of one type, or None (and here we have <class 'str'> and <class 'numpy.str_'>). If happening with a pandas DataFrame the method infer_objects() will normalize data types before conversion.\n",
      "  warnings.warn('Error while trying to convert '\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuEAAAOLCAMAAADJhq0oAAACvlBMVEUAAAABAQECAgIEBAQFBQUHBwcJCQkKCgoLCwsNDQ0ODg4PDw8REREUFBQVFRUaGhocHBwdHR0eHh4fHx8gICAjIyMlJSUnJycoKCgqKiorKystLS0yMjIzMzM0NDQ1NTU2NjY3Nzc4ODg5OTk6Ojo7Ozs8PDw9PT0+Pj4/Pz9AQEBBQUFCQkJDQ0NERERFRUVGRkZHR0dISEhJSUlKSkpLS0tMTExNTU1OTk5PT09QUFBRUVFSUlJTU1NUVFRVVVVWVlZXV1dYWFhZWVlaWlpbW1tcXFxdXV1eXl5fX19gYGBhYWFiYmJjY2NkZGRlZWVmZmZnZ2doaGhpaWlqampra2tsbGxtbW1ubm5vb29wcHBxcXFycnJzc3N0dHR1dXV2dnZ3d3d4eHh5eXl6enp7e3t8fHx9fX1+fn5/f3+AgICBgYGCgoKDg4OEhISFhYWGhoaHh4eIiIiJiYmKioqLi4uMjIyNjY2Ojo6Pj4+QkJCRkZGSkpKTk5OUlJSVlZWWlpaXl5eYmJiZmZmampqbm5ucnJydnZ2enp6fn5+goKChoaGioqKjo6OkpKSlpaWmpqanp6eoqKipqamqqqqrq6usrKytra2urq6vr6+wsLCxsbGysrKzs7O0tLS1tbW2tra3t7e4uLi5ubm6urq7u7u8vLy9vb2+vr6/v7/AwMDBwcHCwsLDw8PExMTFxcXGxsbHx8fIyMjJycnKysrLy8vMzMzNzc3Ozs7Pz8/Q0NDR0dHS0tLT09PU1NTV1dXW1tbX19fY2NjZ2dna2trb29vc3Nzd3d3e3t7f39/g4ODh4eHi4uLj4+Pk5OTl5eXm5ubn5+fo6Ojp6enq6urr6+vs7Ozt7e3u7u7v7+/w8PDx8fHy8vLz8/P09PT19fX29vb39/f4+Pj5+fn6+vr7+/v8/Pz9/f3+/v7///93rQr2AAAACXBIWXMAAAsSAAALEgHS3X78AAAgAElEQVR4nO2di58V5Znne3dnZmd3Zi+zO7s7O7t4A5KgIeokRvEyxgujZCAJa7xwVyJKa9A4hkSMRi62iop4CTGoeMErATTIIAEFQQXtAApqNzRNX2johve/2HP6nD5NnVPv83urnqpT1a+/7yfhHM/TdXveb5+ueuup920whPhMQ9Y7QEiq0HDiNzSc+A0NJ35Dw4nf0HDiNzSc+A0NJ35Dw4nf0HDiNzSc+A0NJ35Dw4nf0PB60nvwWNa78JWDhtePjaP+8qS/Pvcz0/fYO1nvylcIGl432v76335o5jZsNCsbpmW9L18haHjdWNnwF4fNH87+bOeYhstWHTn+5rr992wypvXhX6wqBHuf/eXDeysvJDloeN3Y1NDwrS2F18v/vOG/nHr3f2340d81/Hfz9H84/86Gq03X//37X3/rz46XX7LeU6+g4fXjzIaGhov+ZMz/aLjB7P7fDf9x8T9M3/XnDZ+Yv2l475GGy46/dJYpv5AEoeH14/C1/66h4T990m+4+XrDiMJHv2z4N88+/hcNSxY3NPy3STtN+YUkCA2vJx9/v6FhcsnwUQ1jCx/c0NBwy5w5c7Z1jSh8v/9Vc+llX9a76RU0vG48O7rTmO82fN/87aDh8xsa3i7GPnx79dV/1vDr0svyjHfUL2h43fhFw8ai2E+Y/9Nw/hdffr3h8sJnX/x1w/965nff2H3j3xtzYcMLpZe3s95Tr6DhdWPl3/7dFaf9+1uM+dW/bfibuX/R8OcXFz78w/9saPjLu8zj//niS//q+oEXkiA0vH4c++j3f+wovtm3uafy4fEd73YVXo5+uLVz8IUkBw0nfkPDid/QcOI3NJz4DQ0nfkPDid/QcOI3NJz4DQ0nfkPDid/QcOI3NJz4DQ0nfjNUDf98TVfWu0CGBLk2/I8zJ916631hD3X1LjztU+syM2fOnHw41R37arDl8aUrzYrHlh83Xz6zdNkTO82fnnps+bLXh1h5b64NN5uHdZmVo1vDQqM+F5YxY1uEtS5Zqd+zrwRrR35uPrzXmE2jf2/MGzP6c3v88Qv6Qn84r1nNt+Fbh/UYM+J1c3zz6rbCf3Z8enTdB8XPP17bUTR876rm/k973vzQtK/ec8Iyv20bjHa+dcSYff3/cfjN9T3my2sf28EhSZyYev2xWYdN33ebCu9bnyzltnXYvoHcll8qWc3loIz5Nvz9Qka3D9/bO+Gp577TaV7+xozrZ43YaMyisUtnnfa5WTJp1exfFD69fvpPTnvg6hkjPqssU3wQbCA6d8opfzDLrn3t6qdN9w9eefwq88jZM+87mu1xDRX2jrxxQ+HEb1hz+b+Luf3t+OPl3JZfBrPaI60rK/Ju+O0zJm4x+67vM5e+Y8z8ScfM7PvNn0YeNObkz3cNP2h6z9rQ/+n0fzHmn18sL9P408uNqUT/oaPH7D3jsNlxttl4Qc/xFYVTmDUZH9bQYf5Zhe+CF4Z1GPPF7t0thdzeOuHK5oHcll9yntW8G96z75K3jel7o+nbhQQ2/dSYefPMc1eaouHPnV94uWpR/6e3Lyr8SV02sIyZZEwl2lh4XXHmvHk3XGi6Lj1zfnt+2yJ/HGsc82DhdHzY7sJp+LTT3+rP7ZbR75ZzW37JeVZzb7h58CrTNm6tGTdo+IpLTdHwF84rvEx8oP/T2xYaM2XQ8MIp+YlRs/LC0vr6Xht/UW9u2yJ/PLbhrZH7TMfwwle0WT6mlFsz8c5ybgdSnO+s5tvw94Z1m02ndjx/hTl8YeFyfuGtxtx1l/l0xB7TcdLnXxSu9A+fsb3/058uMGbSssoyBU6Mmn2nrTNmlXnr96b3tP3m8tezPKYhxO47jZk+zZjF5xYu3J8dU8pt25kryrktv+Q8q7k2fNO1w27a03v2pD2jxzXOGb/5ncvG/GHdxf+4wTxxzux/OWNO22s/eujq35jip6vHXPruirMn7Cgvs6u4cCm6aeyY4hfQilETJ6wy6ycsbrzbmLn/dOeRbA9saPDMhdM7tl49bNZO88QlcxddO7+Y25tv/OcnBnJbfhnMai5vQuTa8BI9Xxw7/IU5fvCEjzpazP7CN/XR3VJOA9HePcUL/Z5dh4r/8RkFj0jvp/sCXYHl3JZe8p3VIWA4IQpoOPEbGk78hoYTv6HhxG9oOPEbGk78xtHw3ldrePnl2s9OZOUruvhLcviVlbq4dvdfir77blNQHQvZV3AsTHU1H0U2vHPhp9Xs3FHzUYCPPpHj23bJ8a1yeNc2Of7JR3J8x045/sGf5PjW3WJ4T8juNzmluue+mgV3gmPJONXNH8pxmOpmOf6+KtWuhj9R81E3eFCyA1QLt4U/KlIh9MmeQfra5HhPhxzv6pbj7aCEfL9c7n98f+1nD8hrLNOzpOajbvDgGEx1rxxXpvrIITkOUw1uhh4AqQ7Z/RNSTcMt0PAKNDwcGl4NDQ+HhodCwweh4dXQcBp+IjSchtdCwyvQ8HBoeDg0vBoaHgoNH4SGY2h4NTS8Ag0Ph4aHQ8OroeGh0PBBaDim87GjBS4TOFpNe1fNRwEO9MjxVjncc0COd7XL8Y4OOd7WLcdb5d0/sr/2s/udUl0yXEp1zSI0vBoaTsNPhIYPnKUkm3aepYRCw6vJkeGRmoWGh0PDq6HhodDwQWg4hoZXQ8Mr0HAaXoKGh0PDQ6Hhg9Dwamg4DT8RGk7Da6HhFWg4DS9Bw8Oh4aHQ8EFoeDU0nIafCA2n4bXQ8Ao0nIaXoOHh0PBQaPggNLwaGk7DT4SG0/Ba0jP8oe4CUiq7q2k7VPNRgP2dcrxVDnful+MdbXK8vV2OH+iQ4/u7xHBXS+1niwbzScMt8Du8Ar/DaXgtNHwQGh4ODafhJYaO4VK4ttloOA0vQcNDoeGD0HAMDa+Ghleg4TS8BA0Ph4aHQsMHoeHV0HAafiI0nIbXQsMr0HAaXoKGh0PDQ6Hhg9Dwamg4DT8RGk7Da8nY8EippOFlep+Zv7P6bcfKd4ovNLwaGl5h6Bh+88P7Lt0RfPv0xA3Hi/9Nw6uh4RWGjOEHT+8zD93U/3ZP+e1vJpTP8Gh4NTS8wpAxfNsVxqw+p//titLbjpE7vjxc+M8vtm1e2ltASqtDXAr3Lx+gteaTAEcOyPGudjne0SnHDx6W4/uPiOGj+2s/a5IbsgwNryYxwzdONOadkf1vl5Tervx647QztxfOVa669qGDBaS0OsSlcP/yAVprPgnQBuIH9oP4ATne2ibHW0A8ZPcWyg1ZhoZXk5jhmycYs35U/9snS28f/aExT4wrfsCzlGp4llJhyBj+8UXGvHR5/9vVpbcrxhuz4cziBzS8GhpeYcgYfmR0q7mjcK64eJnpLL3d981u89SkYoyGV0PDKwwZw81r18y/rrAz536/8nb51feP/6wYouHV0PAKQ8dw09P/s12HK29NX0t/dzgNryHfhtc11UPIcDs0vBoaXoGGZ5J2Gl63VNPwTNJOw+uWahqeSdppeN1STcMzSTsNr1uqaXgmaafhdUs1Dc8k7TS8bqmm4ZmknYbXLdU0PJO00/C6pZqGZ5J2Gl63VNPwTNJOw+uWahqeSdppeN1STcMzSTsNr1uqaXgmaafhdUs1Dc8k7TS8bqmm4ZmknYbXLdU0PJO00/C6pZqGZ5L2XBve+9yij6vfHnms9AENr4aGh5Jrw0PGzzO//GbpAxpeDQ0PJc+Gt9eOn2fW3kvDLdDwUPJs+Paa8fNMy8+babgFGh5Kng3fVDN+3rGfdpQMv/+Msxa1FpBS5RAXU91aTUvNJ9FQLo8WjxFfMJh1Gm4hTcPfqxk/75G7Xn3i66+2FHa7veXR4wWkVDnExVQfr6a15pMAvW1yvOeQHO/skuPtPXL8QJ8YPhay+ycMgkrDLaRpeHPN+HmvNjXNHdm0u/gJz1Kq4VlKKHk2vHb8vAI8D7dBw0PJs+Eh4+fRcDs0PJRcG2669xb/PdRVeTsIDa+GhoeSb8MFaHg1NDwUGl63VHtheMej3QWktDnExbR3V9Na80mAzv1y/NBBOd7eLscPdMjx1i4Qr/1okVOqaXg1/A4Phd/hiTUFDU8q7UFoeIqpjtQUNDyptAeh4SmmOlJT0PCk0h6EhqeY6khNQcOTSnsQGp5iqiM1BQ1PKu1BaHiKqY7UFDQ8qbQHoeEppjpSU9DwpNIehIanmOpITUHDk0p7EBqeYqojNQUNTyrtQWh4iqmO1BQ0PKm0B6HhKaY6UlPQ8KTSHoSGp5jqSE1Bw5NKexAanmKqIzUFDU8q7UFoeIqpjtQUNDyptAeh4SmmOlJT0PCk0h6EhqeY6khNQcOTSnsQGp5iqiM1BQ1PKu1BaHiKqY7UFDQ8qbQHoeEppjpSU9DwpNIehIanmOpITUHDk0p7EBqeYqojNQUNTyrtQWh4iqmO1BQ0PKm0B6HhKaY6UlPQ8KTSHoSGp5jqSE1Bw5NKexAanmKqIzUFDU8q7UFoeIqpjtQUNDyptAeh4SmmOlJT0PCk0h6EhqeY6khNQcOTSnsQGp5iqiM1BQ1PKu1BaHiKqY7UFN4Y3veH5/ZWv+19tfQBDa+GhlcYMoZLU1HT8GpoeIWhYvhBaSpqGl4NDa8wVAzfJk1FTcOroeEVhorhG+1TUb9ww40PHyogpcUhLqb1UDWtNZ8EaAfxtgMg3ibH97fL8RYQD9m9hXJDlqHh1SRl+Gb7VNS71r/52NECUloc4mJaj1bTWvNJgJ4DcryrXY53dMjxtm453tojho/sr/3sfrkhy9DwapIy/GNpKmqepVTj91kKigcYKoaLU1HT8GrSM/yh4rxtUqoc4mKqE4gH6GiTp6XTTnu3X572rqul9rNFg/k8obdQmoqahlfD7/AKQ+U7XJyKmoZXQ8MrDB3DBWh4NTS8Ag2PlTYanmaqtfEANDxW2mh4mqnWxgPQ8Fhpo+FpplobD0DDY6WNhqeZam08AA2PlTYanmaqtfEANDxW2mh4mqnWxgPQ8Fhpo+FpplobD0DDY6WNhqeZam08AA2PlTYanmaqtfEANDxW2mh4mqnWxgPQ8Fhpo+FpplobD0DDY6WNhqeZam08AA2PlTYanmaqtfEANDxW2mh4mqnWxgPQ8Fhpo+FpplobD0DDY6WNhqeZam08AA2PlTYanmaqtfEANDxW2mh4mqnWxgPQ8Fhpo+FpplobD0DDY6WNhqeZam08AA2PlTYanmaqtfEANDxW2mh4mqnWxgPQ8Fhpo+FpplobD0DDU0krDU8z1SgegIanklYanmaqUTwADU8lrTQ8zVSjeAAankpaaXiaqUbxADQ8lbTS8DRTjeIB/DB8aV8B6bAd4mLaHOIBjhyo/iRI9yE53tkpxw/2yPH9R8Vw7/7az5qcUk3Dq6mP4Ut6CkiH7RAX0+YQD9B9oPqTIB0H5fihQ3K8rUuOtx4Ww4dbaz8bQrOcoHgAPwznWUoVPEupQMNTSSsNTzPVKB6AhqeSVhqeZqpRPAANTyWtNDzNVKN4ABqeSlppeJqpRvEANDyVtNLwNFON4gFoeCpppeFpphrFA9DwVNJKw9NMNYoHoOGppHVoG973xlN7gm8PvPibbf3/TcOroeGh5Nvwmx/ed+mOE9/u/eau7aPXFf+bhldDw0PJteHtp/eZh27qf7un9PbtWcb8dF7xAxpeDQ0PJdeGb7/CmNXn9L9dMfh20m+L/9Lwamh4KLk2fNNEY94Z2f92SeXtx+d3GfPMVdc2HSwgpcIhLqYygXiAtv3VnwQ5cECOt6K4HD7YUvvRwsGs03ALqRr+3gRj1o/qf/vkwNvuiTsL/36x7b1HegtIqXCIi6lMIB6gu736kyAdnXL8YLcc339EDB9trf3shEJlGm4hVcObLzLmpcv7364uvz06a3spxrOUaniWEkquDT8yutXcUfieWbzMdJbe9jZuPHSof5eHhOEgHISGu8YDDGnDzWvXzL+usAPnfn/g7cphBU4uhmh4NTQ8lHwbbrr3Fv891FV5W8ELw1E8mGoaHpaXIW64HRpeDQ0PhYZnFU9g94LQ8FBoeFbxBHYvCA0PhYZnFU9g94LQ8FBoeFbxBHYvCA0PhYZnFU9g94LQ8FBoeFbxBHYvCA0PhYZnFU9g94LQ8FBoeFbxBHYvCA0PhYZnFa/D7gVTTcNDoeFpxeuwe8FU0/BQaHha8TrsXjDV7ob3PjN/Z/Bty9IF7/T/Nw2vhoYL4bwaLjwATsOroeFCOKeGHxQeAKfh1dBwIZxTw7dZHwA/+OkOznJSxVd7lhMQznr3LIZvtD4AvvSfxj/UVkBar0Nc3C+HeJDWmk8CHNgvx/eDeOsBOd4C4iG7d8ID4DQ81bjF8M3WB8B5llILz1KEcNa7ZzH8Y+EBcBpeDQ0XwlnvnsVw6QFwGl4NDRfCWe+erbdQeACchldDw4Vw1rtnvafZ01L8t/Nw5W0FGl4NDRfCWe8e79obGp5ePAe7R8MNDU8vnoPdo+GGhqcXz8Hu0XBDw9OL52D3aLih4enFc7B7NNzQ8PTiOdg9Gm5oeHrxHOweDTc0PL14DnaPhhsanl48B7tHww0NTy+eg92j4YaGpxfPwe7RcEPD04vnYPdouKHh6cVzsHs03NDw9OI52D0abmh4evEc7B4NNzQ8vXgOdo+GGxqeXjwHu0fDDQ1PL56D3aPhJs+GP9RdQEqFQ1xMZcrxHOxe96LBfNJwC9kZ/ujxAlIqHOJiKlOO52D3jp8wvNhQMlwTrzmi/BrOs5Sv7FmKJl5zRDQ8rXgOdo+GGxqeXjwHu0fDDQ1PL56D3fuqGo7iAWh43HgOdo+Gx1p9EBouhLPePRqeyuYD0PCsNk/DU9t8ABqe1eZpeGqbD0DDs9p8TMM7HuWtZG38xFvJNDzVOL/D67756rTT8FTjNLzum6fhdds8Dc9k8zS8bpun4ZlsnobXbfM0PJPN0/C6bZ6GZ7J5Gl63zdPwTDZPw+u2eRqeyeZpeN02T8Mz2TwNr9vmaXgmm6fhdds8Dc9k8zS8bpun4ZlsnobXbfM0PJPN0/C6bZ6GZ7J5Gl63zdPwTDZPw+u2eRqeyeZpeN02T8Mz2TwNr9vmaXgmm6fhdds8Dc9k8zS8bpun4ZlsnobXbfM0PJPN0/C6bZ6GZ7J5Gl63zdPwTDZPw+u2eRqeyeZpeN02T8Mz2TwNr9vmaXgmm6fhdds8Dc9k8zS8bpun4ZlsnobXbfM0PJPN0/C6bZ6GZ7J5Gl63zUuGH9vwyufBt5VPaHiyaRdSTcPTM/zmh/dduiPwtvIJDU827UKqaXhqhh88vc88dFP/2z2lt3sqn9DwRNPeLqSahqdm+LYrjFl9Tv/bFaW3Kyqf0PBE075dSDUNT83wjRONeWdk/9slpbflF/Pa7T97uKOAtF6HuLhfKcdzsHsdiyqp3mRN9Ru3/+wBplobPyHVJxq+eYIx60f1v32y9Lb8Yt57etmjh6s51F7zUYCDHXJ8f5ccb5XDXfvleMdBOd5+SI63dcrx1m4x3B2y+/dXUv2eNdVbn356ce2+gmOBqUbHIoe7DsjxzjY5jlJ9AO0+SHVL7WeDqT7R8I8vMualy/vfri69XV35pHSWEqC7q+ajAB09crytT463yuG+Njne0yHHM531u1lIdeksJUB3p7wvMNW9clyZ6iOH5DhM9RE5fgCkOmT3w89SjoxuNXc0GbN4meksvS2/GBpei8pwKdU0vJrEDDevXTP/usLOnPv9ytvyCw2vRTfrt5BqGl5Ncoab7r3Ffw91Vd4OvNDwGpTz2ttTTcOrSdBwOzS8GqXhdmh4NTQ8FBo+CA3H0PBqaHgFGh4ODQ+HhldDw0Oh4YPQcAwNr4aGV/DD8Lu3VbPpjzUfBXhnsxxfv1WOr5PDW9fL8c3vyPE/bpLjG96T42/Lu//+27WfNTmluueXNQtu2ijvC0z1FjmuTPW72lS/K8dRqkN2P/yuvUTf+hoW3FX72YnMWSLHJ78ox6+Qwy9OluNL5sjxuxbI8RuXyfGJq8Twmh/UfrbHKdXHahdcNFfel589IsenPC/Hr3xbDK+8Vl586a1y/Fe/luM3PSXHr3pNDL85vvazXZEND2HJfXL8lpfl+NiP5fhwOfzxWDn+8i1y/L7ak4EAU96W498NOQ05gY4z5cUj8eSv5PhtL8jxcR/K8RHHxfCuS+TFX58lxxctluMz3pTj538hhg+fIYbjG/7as3L8kXfk+B175fh1cnjvHXL8nUfk+LOvyfH52+X4Te1iuPsGefFIrHpaji9dL8fv/FSOT5IN/+I2efFND8nx58F33aKtcny2fB1wZLoYjm84IUMBGk78Rmf4W9bIZ/2nsX1rbH+AjvV3cB0G699gjaDlQRztnnb33Q7PEbAybSrRsZaI3dTaVGqbKpbhuxY0lbjM+iNfTlm21pi7x1z12/D4jv7r1DvtPaEb7583765/tIbR8iCOdk+7+/DwogBWpk2leKxr1U2tTaW2qWIZ/uElPy1ya+N51h/p+M5NExaZcRvMjaFXMSsfm7lmzZrX/+kz2/IfjGgsNMvFtjBaHsXB7ml3Hx5eFMDKtKmUj/UFdVNrTVA2VTzDD79RfvOi9UfWFn6v7jCXfmDuC70QXnLt2WPHjr18rnX5P/T3QK2zhdHyKA52T7v78PCiAFamTaV8rG1Rmjr0LrfWBPemCu/dSutKc+MT5sgsc9EOc3v4zf0vQWfe0RuKt2r/YI2j5UEc7Z5291E8EmBl2lSiY0UMLh96pqFNpXtThRcHxDb8hbMvNKtWW8PHJo4ZvWDceXN+dqW0ki3WyKczJhX+No4BO2FfHsTR7ml33y0eCbCy+KmEx6pram0qtU0V1/DmSTtvMObH9subvh2fm76jXz5ku1X9wRMPNDVdbl284xvzm5oW2i9v0PIojnZPufswHgmwMm0qwbGWm9peiQaW16ZS2VRxDV/1hplnzERQamHvoto5fFJj42zhO/pl3fJw/fLqUTyRzbsCVqZNZQl7vNzU8q1ztH6FCS6rF+JxDd973eF5Zt3p9rJM0EW19ifFf1cJW9iw6AHhxjlaHsXB7ml3Hx9eBMDKtKlEx1puanuxM1hea4KyqWKfhz91+pkXDrdX/KAuqu5pxX+Fmwxzz7pq4hm/ib08iKPd0+4+PLwogJVpU4mOVdnU2lRqmyp+X8pnK1bus0fFLqpNDy9dOuvWJuns6+PZhT8Ph68Ov9W1DiyP4rgHTYz/q3rzEQAr+0iZSoNzoWpqEH4f776qqUx6vYViF9Ub+DbCqt8X/30w/Dx/BVgexXEPmhhfqd58BMDKNipTaXAuEGB5MbwO776qqYzC8O2Tv3P+XHsFqdhF1T5wG+F1+/KTDhqz7wfhF/BtYHkUxz1oYvygevMRACvrUqbSOHTMapoahDscdl/TVCa+4a2j713zxi3jrXHURQXLfR4Zfv55I+3HrazHQbun3X23aiZHlKVNKJXoWJVNrU2ltqniGr5mfvHfq+1PMYAuKlQvY8yu514QOqi09TioB025+/jwIqAsbUKpRMdabuqWuMtrTVA2VVzD991T/HcGeMh7ozWC6mVQF5e2HgfsHoonsnlXdKVNBvYW9mM/1nJTg7EHQC41JjisXojHMnxP4Qp44sKmpnmTwi/Qd/+oo/mX99xzz6++Z10FqqdBXVyDy4cPZTAYr61W2At2r1m/+6gcKBKDKwtNtyqVW8Gxrqs0dfjta7D8PmUqt4Pl0e6bmIZ/MHAFPCa8/XZNONT1jbnz7vqFvZcS1dOgLq7B5cP/jEjlQJ+B3ftYv/uoHCgSgysL/R5VpXILONZKV86Y8PFnwPJ7lancDpZHu2+01bNv2Mdq6X9O2f4QNaqXQV1c2nocsHva3XcrN3JEWdqEUikea5u+qZWp1DaVrj/8XRAXrg9AvQzq4lKXToHdQ/EkNu+MrrQJprIflAtFU4OwU6rqX5diOt9Zs+b3E+xnmaiaoPRD9hDo4oLLg7iy2EG7+RjEvpSDqUTHWmpq+yh5urqU8g/F372U6lLavnPpt8ddYB9IQ6wW+AhfH4hdXOj6Al9/qIodtukvf9wBK9ujTKXBuVA1NQg7XNRnVZey+jmz0ByebY2L1QIf4uuDEpa/Pej6Al9/qIod3tdf/rgDVrZbmUqDc6FqahD+BO9+VnUpm5/qe2OtGWcdTAkWO6DrB/S3SXf9oS120F7+REN3KYdSiY613NTWvwKaupQiYPezqks5PuGGvnFXfMvamydXC4DRfg3624OWh+vXFTuoNx8FsDJtKnEuyk1tfZxLU5fisPtZ1aWY3n2m7Xn75a9cLdAIVy//7UHLw/Xrih3Um48CWBneFvozDp9yUzW12oSs6lKKtO89aA+K1QKTZxS5ctT3rE93y3970PJ4/apiB/3mIwBWpk2lcXrKLX5Tq03Iqi6lyJuXnBxzyVuL/7z49Sn2QUXlvz1oebx+FXXdPFiZNpVuxG9qQMotZbR3fGbaQ+IQBJ3GdM0+rXbmlEHkvz1oebx+MEKCbvfx5iMAVqZNpcG56CduU6tN0DVVXMMHTsrsh41Gm9h2/oUfiJsAf3vQ8iCOdk+7+/DwogBWpk2lfKzqptamUttU8Qy/ubOnSLd9bHJ5tInjS05tLJYkPWddvkd8qgotD9ePBsPQ7T4+vAiAlWlTiY5V29RqE3RNFdfwScPKWH9CHm3iX4bd/FaRCdbl154ijduKlofrR4Nh6HYfH14EwMq0qUTHqm1qtQm6popr+E82b32/wHvX2n9EHIJg5vIS46yLd0wq1kGsiLk8Xj8YIUG3+3jzEQAr06bSgGPVNrXaBF1TxTX8j+VxzTcJPyMNQfDH8qt92PVP53670d4BgJbH6wcjJOh232Hz7oCVaVNZRD5WXVPD1ZeQUqVpqvh9KWhc87Yd8vKfSxkzAx0A9vnW0PIgjnZPu/soHgmwMm0q0bGWm9pafQuW16ZS27E+4vAAACAASURBVFQxDYfjmu+47CVx3o0d35u3U9xCfweA/eDR8iAOd0+5+/DwooCORZtK+VgHmvrLmMurU6lsqpiGw3HNdyxZddsv37Ov4E+rPm26aRmYLloALQ/iaPe0u689vCgr024LHKu2qbWp1DZV3LMUOCx7pzHbL7rI+pTikcLVT/PVp/3MOpcp6MdHy4M42j3t7sPDiwJYmTaV6FiVTa1NpbapNPc0e4VpgXcsfmb8yDkf2eOPPHXl1+Zs6Xn8gfA46sdHy4M43D3l7qN4JNCxaFMJjrWIoqnVqVQ2VVzDD1+1ov2i0+61b3fYmCXSH84dw8Y+XfjlM93f3hUaR/34g8uHX0YPxkPbBu+ebvcH42A6YhcGVxZa/qRPpXysyqbWp1LXVHENX/f48fsm9DZaH97bcZ88FM4ny0qv+88LLypD/fiDy4ePJjEYD/3uQrun3f3BeAKjSQyuLLQ/Q5tKdKzlprYW/4HltanUNlVcwze8evjM18zi3eHRwy3FWrF9L4C546UHuFE/P1peiqPdS2D3neKRACuLm0p8rOWm/jzW8tpU6psq9lnKhPMv7/v9BMuobpPHFgeh29ck3GYAz+of6yn24wvdQOhZfymOdk+/+zAeCbAyVSrxsZab2tIfDpbXplLfVLGvNLs3dpu31luCMwv/u3pGh1CQhh7ghneUwPJiHO2efvdRPBJgZbpU4mNVNbU2lfqmSmdEoOL2Go1Ucgke4IZ3lNAD4GIc7Z5692E8EmBlulTiYy0Rs6m1qdQ3VTojAs3s6ulpFEsuwbP68DYDetZfjKPdU+8+jEcCrEyXSnys8ohAYHltKvVNlc6IQLjkUnxWf8tOeJsBPesvxtHuKXffIR4JsDIx/BFKJT5WVVNrU6lvqnRGBHIouZQe4J7+sGnfBnYAPAAuxtHuKXffJR4JsDIp/HOUSnysqqbWplLfVOmMCDRQE2kp9zn46ecl5oT/5t69r3x59Fj48gfA8igOdg/F25SbjwRYWSfY1qMglTAXaEQgsDwId6BUKZvKpDcikFgT+dvTRo067eSTTz7pjAOh8QM/mDbjksbGxtnnhi+/GCyP4srq16XqzUcArGwV2NZBkEqDc4FGBNIU976MU6UtVE5rRCCxJvJPi0z7zYXXjjstP9C3ccEPm+yzLO4Ay6O4svr1Y/XmIwBWtk+ZSuNQfatpahD+DKdKW6ic1ohAck1kr1n7ePH1Zuv0Rx1ri//aBmpCy8P166pf1ZuPAliZNpVu1bfxm1ptgrZQOa0RgVBN5M4rCinbfY59UOp+7M2ClgdxbfWrcvPRACvTptKl0lfR1NpUapsqrRGBYPnogpFXXjpcHjTn+Lv2R6/g8nJcXf2q23xEwMqUqXSr9I3d1NpUapsqrRGBUE1k4ffuuRXiDZH3551z6ighjpYX4+7Vr3F3H8UjAVamS+XgsYbV0UVp6lY5HC+V7k0VfqmQ1ohAqCYSTPL40a/HnHrOI4ekwg40SaQYd69+jbX7DvFIgJXpUikfa5SmDu1u0aZSW6ic1ohAJYSSTnG+zBmnXvPsoaU7jDC7EphvE8bB7qF4Ept3BqxMm8p+bMeaQFODsFOq4jdVaiMCgZJOeb7MTxbe/nSb2Cxovk0UV1a/ajcfCbAybSrlY9U3tTKV2qaKOyJQCXtnOyrphJM8brt3/OJDc2IvD+La6lfl5qMBVqZNpXys6qbWplLbVHH7Ug40mcPCoOmwfNRhksfjm+adE3t5ENdWvyo3Hw2wMm0q0bEqm1qbSm1TxTN83dx7R32+XCophuWjTvNl2qtn4fJyXF39qtt8RMDKlKmUj1Xd1NpUapsq5nf44dUjF044b84i6w/g8lF5kkcMWl6M66tfVZuPCliZblvgWLVNrU2ltqniGd5nmr9pls88LgyIKBYzvHT3S2gT4jA2aHm8flX1q37zEQAr06bSgGPVNrXeBGWhcsyzlFtmjFhyx9Q+SxiVdJrpL1ofTysjD2ODlpfjXWD3Dml3Hx9eBMDKlKmElb6gqcHyKNVo91GdtUOhctwrzeYzdvz8H2//aXjwdVQTOXBad591/fIwNmh5Ob4O7N6L2t3HhxcBsDJlKh0qfcWmBsuvV6byCX2hcuzRJDaa9Uttwb2oJnLavHuKzLvQun55GBu0vBz/Euzep9rdx4cXAbAyZSodKn3FpgbLtyhT+Ym+UDme4W1Vr9Wgmsip106ZWmDSWfZNiMPYoOVBXFv9qtx8NMDKtKlEx6psam0q9YXK8QxvLL9a/nQZVBM58LfpZ9bl5WFs0PJw/brqV/XmowBWpk0lOtbG8mvcplaboC1UjlmXcvo3i5xxqv1HxJrI67eVEm6f1VwexgYtj9evqn7Vbz4CYGXaVBpwrNqmVpugLVSOZ/jy86576a233lr7/4SfkWoiH55iPbErAYaxQcvD9euqXxPYvDtgZdpUFpGOVdvUIOySKl2hcswrzePrGm9Zf9xsEX5ErokEt4LBMDYf3PNK4d8tM5ZYV/BJ0+33ilO1a6pf8YibcPNRALkC24KDK4FcqJtaDOOW1BYqx3/Gp/3J6U2W8UiLiDWR+FawPIzN7MeK0xN1b5hg++P2yEmjLj5z2Kxj8XYPxWc2SzvnsvkIoFzBbaHBlXD5qqapQRi2pLpQWfEUW/vS0d+yBkFNJLwVXML2ZTmr/LrA8tdpy7nFxxKbJz4Zc/dAfPr862972da54LL5SMi5ct2W/e+OQ6WvpqnlMGpJfaFybMO3NI74/vP2qxe5JtLhVrBY9XtN+fVuy8nl3FKtZ8fV8XYPxV8z5uDLc6bdu8HyxQk3HwWQK4dtgQJqWH2ramoQRi2pL1SOZ3j37y7/2u0fDhYP1yLXRIJbwQZV/c7uPyrTPtayhoG/2TfG2z0UL571ffLA2K/9xDLBA9x8FECu8LZQAbV8rNqmBmHUkvpC5XiGTznpmuUvvvDCC9+3/wioiRRvBRtU9ds8+v7mzi9fvsjWR3RrV+nhQnvVsKr69abt9130tZmvW/8w4s1HQswV3hYc6Vk8Vn1Ti2HUknj1KB7P8BteLTFe+Bm5JlK8FWxg1e+Wi4cNGzb8QdvSDg8XaqpfJ51y7ivSaavrs42OiLnC28IjPUvHqm9qOQxa0mH1IB7P8DfLr7bZyFFN5MAjUSutP4Gqfns3Pr/GPs4ReLhQW/16S9vyWbettszwgjcfDZArvC05lehYlU3tUMcstqS+UFkzIlCr9eoDlXTOLJ11NV9i/xGH4Ynt2wcPF2qrX4sTYB985roZL1q6uPCzjREAuXLYlphKt0rf2E2d8uod1h/P8FXXvGo6/nnYqLWWOCrpnDyr8Ft74I4R9i6oIvbB8tD2wW+2tvr1CXNs64M/OvWCuTG/FyMBcuU22Zk9lehYlU2d8uodiofjGX716gPmzjEte8dZroBRSefKvTM/XDxq5m65E9c+WB7aPvjN1la/Trv+jBHXPWn/A5PoExAgVw6TnRkplehYK6m29Iwqi3u1JuHi4XiGzzDm0IgXCr85loG6UE3kp+bwDd/bbgwSwXYnD20f/GZrq1+nzn3LfhKONx8NkCuHudQC+1QNOtZKqi398criXq1JuHg4puEtZt63jxrza8s1LKqJLHZdPVz47rnVEkeD5aHtg99sbfUrmqw+0ScgQK7QZGQolehYK6m2zGyvLO7VmoSrb+MZ/u7ZF4xYZ/b8aqxlwmVUEzlp2Mknn1z4v62LCw2Wh7YPfrO11a+oKyjRJyBArtBkZCiV6FiVTZ3y6h2qb2P2pbSsayn8/XzsTUsY1USiLi7YyQu2D36ztdWvqCso0ScgQK60k5XB8lVdU6e8eofq23iG4wt4ueITdXGh3wDUWQF+s93mm7f3P6CuoESfgAC50k9WJjcVbmpQvSuHXbqdWmx98UW6174tFH+YuIajC3hU8bmn6rUa9BuAOivAbzasfu3H3v+AuoISfQIC5Eo7WRlqKthXA6p3QRi15LoZT5rdp48ZM98Sbz//1JN+LFYpxzMcXsCD6tiBk8ObrFuQZ9hy66yw3kdA1a/Vm6nGrSvIfhsjEiBX6ElhOFkZaCrU1KB6FxX3opac+kar2T1t+bPXWix+cGFf96w1loX7iW24eAGPqmNxMYU8wxbqrAD3EVD1K+p/QF1B6DZGJECuGsuv9iI2OZWoqVBTg+pdVNyLWrK42S9WGbPIsn/F4vA9C42xzS8R23BwAY+qY/HJoTzDFuqsAPcRUPUr6n9AXUHoNkYk0JUmfFJYTiVqKtTUoHoXFfeilpxcfp1r+XtZLK1s+7l0NpDWHBBydSwuppBn2IK9rPJ9BFT9ig4P/YKi2xiRALnCTwqjycrkpkK5ANW7qLgXteStpfEW2y6z/AqmNa89/g5G1bFFpEka5Rm2UGcFuI+Aql/R4aFfUHQbIwb2XMEnhdFkZXJTKTt2kYGoJZtHNzV37F5xru05zLTmtf+o6rUaXB1bRJqkUZ4gDHVWgPsIqPrVrTbQfiWJbmPEQMoVeFJYnswMNRVqaqAYMhB2O236buHXY8RiWzi9ee1lHKpjSz9njaAZuMAIC/J9BFT9OoBtllV4JQluY8RCKjwRnxSWU+naVDaAYthANMVE3x9fWGufDRd316djOLolgidpLGG7NYNHoxDzhqpfS9hnWcVXkqjZIoBzBZ4ULmFLpVshsx2gGDIQteRzYPO4tDIdw9EtETxJI3hAHHTigryh6tci0iyr6EoS/wJGAOQKPyksp9KtkNkOUAwaCFpymnjB5FJamY7h6JYIvgKWHxCHo1HIeUPVr2iWVXgl6TgcjBMgV/hJYTmVroXMNoBiyEDUktOemT7rdaGxUHd9WoajWyL4Clh+QBx14oK8oepXNMsqupJ0GA7GHZAr/KSwnErUVAigGDIQteR7hd/Q301vXG1rCtRdn5bh6JYIvv5AD4jLnbggb6j/AM6yCq4k8XAwEQC5Qk8Ko1SipkIAxbCBaFyRAq0LTjnbcrGZVn84QlvQhp+1R/3tYt4c+g/ALKto9x2azR2wMV0qteMCKPvDUUsuNh3P/fiUCcttvSlp9YcjtAVtBjwgvuyT4r8bxtgVFfPm1H8gzLKKd7+0+eYk+sPBxrSp1I4LoOwPRy05dcbw7y4Q+gSy6g9H1bHgUgzOsDV5ZFOxK/uQrZ4HFNy59h9YRyRGV5Itr+8t/NsxyTr1RhTAxuQwmswMNxVA2R+OWnJK4wb5a6Jv33Gz+c4V9h9Ix3BUHQsuxeAMWzO3XXrJVmO/fmksv1pOE1D/AWp1dCX52egRw7esu+rUbydRPws2BsK/Q6nEhcwy4MsEFfeilkSdAi3nD5vQPHrimfYvq7SuNOWzL3ApBmfYmml6Hxx512FrXkDBHeo/QK2OriTvfcW8P/GSBzcl8owP2BgI70Kp1I5A11h+tXyZgDBsyQFst5d//Xjrb69837RNsC6Z1ZWmfCmGZtgq5qN5wnnrbXkBBXeo/0BbOnlL4f/TP4//lz/SxpSpVF9pyl8mqLgXtWQJ++3lmwrnMEW77UPvZnOliftC5Bm2pv2muXDYT359lG1xueBO/2yjvPvFktHbFX/5I21MmUrtlSb4MkHFvbAljXx7uZjqWwupvtm6dDqGl7BXfOJHr+QZtp7/Rf/0kPtmWeL9W7cX3GmfbSxvwHp4iY4965Ar8MQcmszMyIXMAFC9C8KwJcHt5az6w0vYKz4by69Sh7E0w9bAcuIQ9GLBnZGscJk+STq8RMeebSy/WnLl8sQcmswMFOdCwDw/Uhi1JLq9nFV/+AAxrwT7kWbYmnxvse9r3zThS1IquENWOEyf1I/t8BIdexbkyuWJOTSZWRFVnRj4MhHCqCXR7eWs+8NjXgkWEWfYuvPDWRuOPDhyuq0XFRTcISvQ9Eno8NzGg3UE5MrhiTkxla6FzAKgelcMo5Y06tvL6faHW6sR4KNXaIatYzeeNeYts9USBQV3yAo0fRI6PLfxYF2Rc4WfmJNT6VDILAK+THBxr9yS/ahuL2fTH15EPnmTZ9i6e9/1I+c3bjC2agVQcIesQNMnocNzHQ/WGSFX+Ik5OZXaq2LwZYKKe1FLDhD79nJm/eEGnLzJM2xNGTl1rzn22J3TLEuDgjtkBZo+CR0eLlqOipAr+MScnErtVTH4MkHFvagl0VkILlTOqj8cPnolzrA1rXSNuPsCSxydCCMrwPRJ6PBwyWg05FztXvLLRRulxcVUaq+KwZcJKu5FLYnOQnChclp9KfJvnsOjV+IMWwM3OGyj2cETYXR5Ik+fhLqoE+0PR7laePLwc0YNu9YyuFE/8mRl2mdKVcW9qCXxWQgqVE7HcPSbh87OXCfCsVUrgBNhfHkify82ll9taU20Pxzk6sXL1h8rNPPNjeFhmErtM6X64t7Sz1k+x2ch6JZuSt/h4DcPnZ25TYRjr1ZAJ8LoiwF8L6Lu/ET7w0GuJpev0aZbrtVgKrXPlKqKe8vYWxKdhaQ726Ad9JuHzs5cxpaVqhXAiTDaPfS9iLrzE52LDeTqhvJrU3N4HKVS+0yprri3H6kl0VlIWrMNItweVLTfNocT4eiqFdDuoe9F1J2f6FxsJay5ur7Up9/zQ0t/N0ql9plSXXEvbEl0FpLWbIMY+TcP3TaHM3hpqxXk3UPfi0Wk7vxE52IDudp89tI/dex79Yp7LYvjOYW0z5SqintRS5ZQfBemZrj8m4dum6MRSdXVCvLuoe/FfoQu6kTnYkO5Wlcc2O+UX9i+JfGcQi6DqEqointRS2q/C9MyHHWnodvmDhPhiNUKysnW0feiAV3Uic7FBgtPjvzrilWt1sVRKp2KcwUcrjnEeXhAS2q/C9MyvLH8av3bBG6bO02EI1QraCdbB9+LqIs60bnYQK5QpS9KZWP5Ne5ZCsglmoenH6El9d+FKdWlgO40XEzhdhvCVq2gnGwdfS+i7vxE52IDucKVvnIqXQqZJdD002AengFsLen6XWgfuCMdw2F1LBo0yvU2REv4+ZtysvUS9ssb1J2f6FxsIFeo0hel0qGQWcRh+mlpHp4KlpaE34Vw4I6UrjRBdxosoHa9DTF1R/jHusnW0eUN6s5P5Lt7AJArVOkLUwkLmWVALtE8PIPrCW9J9F2IB+5I7xkfqTsN1Y0434aw5EU52brrTFO2W82N8mLRALlClb4uqQRPoYmAXKJ5eCrYDAcFFHjgjhSfYhO601ABtfNtCEtelJOtu800Zb/VPHlGkStHfS98/opogFyhSl+nVKJHWgVALtE8PBVshoMCCjxwR2qGi91puIDa8TaEJS+Ok63bLk9cZpoShzgo/vPi16fE7YELgHIFKn0dUuk0h4QNdM0B5uGpYGlJVECBB+5Ix3DYnQYLqB1vQ1j/thWxXyqCyxN4eQNuNXca0zX7NHn8BmdgruRKX5RKl0JmCTgpmTwPTwVLS6ICiqxGk0DdaWi/3OZyK/Bq+Gh84FIRXp6Ayxt8q3nb+Rd+YN/rSLgWm1s6I1Aq8RwSMo4zXdkuWSpYWhIVUGQ1mgTqToOPgYG0odsc4FLRYVzBl7pesp9Eo1vNx5ec2lg8cUTTLDnhWmxuu+gGqcRzSMi4jVRtvWRBLYkKKLIaTQJ1p6FJGlHa0G0OcKnoMK7gzJaZ4tDI4q3mfxl281tF7MNFRgDlagDbn3mQSjyHhIzDSNXSJQtqSVRAsbz8+ox162mOCCQONSaC0oZuc4BLRYdxBZHh4q3mmctLjJPXkCwWw93GSo/fVGikanDJgloSFVBMf/jRIo9cZt3BdAx3GWpMAqUN3eYAl4oOp7bYcFOclzOcgT+dcb8XY2ExHKVS21RgpGp0yQJvWIECislXjh//rfHjx51u/Yl0DHe9ZWIDDfCNbnN0ypeKDqe2TobbSHTMK1cshqNUapsKjFSNLllQS6Lz9OKJYqOpf22h2y0TO2iAb3Sbo1FevcNzlCrDkx3zyhFLZwRKpbap8LeFeMmCWtJlCMlGcQdTMtzhlokETBu4zTGlcXP/q6U7BF+emGUdyxw6cS0kPuaVQOnvhR2USm1TuTx1LVyyoJZE5+nFjxuNNOFtOobj6lgZnDb5NsevDz/V+Hbh9fbwMLw86V77tmYyzOTHvLJT+nthB6VS21Ql4JWqdVQ20JLoPL2xs6fnpp6ebtuEuKn1pcChxmTQVFEOA3z3zrn4hz8cHR5Dlyft55960o9BQbNE0mNeidsy5vrLJ9n7PeFca8qmAleq6BEi1JLaISTTMlx7qYWmikJnZ/OPvT5u5B1NTZbbHOjy5MGFfd2z1kTZ4SCJjnkFKP6dKNac2E6jUSq1TQWuVBvLr7ayGNSS2iEk0zJce6mFFEFnZ1PP/9qvihdeQj1So7D54nDEexbarUEkOuYVYODvhc1glEptU4ErVfQIEewPB+fp+H5YOoZrL7WQIujsbOp94hNw6PKkeEeo7efxZ5pKdMwrADLYYZxcVVOBK1X0CBHuD0eFZYjUDFddaiFF0NmZ8N1dBF2eJHaWYamGShJkMBwn1+iaCl2pgkeIUEtWiJ3KlAxP5FLLPkEYOjsrYb3A137vOSMW9yaDdt44dVMdfL+w6pZX3hM2LjxC5NaSRpHK7OaAwAgThIGzM3CBr/3ec6YOhrvNS29PZT2uiqVHiOADHGVyZnhSX4L2P53y2Rm4wEeXJ/FHOKuiDoa7zktvS2X6V8XgESLH8+ycGe5a8WnDdYIwW1298lb05JkFbpj6gDSomxN1MBx9B6NUapsK4PoIEXxCImeGa3GbIMxeV6+8FX1LafXP2ieXcaQOhqPvYO1ca0rcHiGyt2QFzwx3OTmU6uqVt6IHKlK+Z6/adKLZUg2VJOiaoZ53n0JweYRIHj+8TOxU5tNweHKIRp3W3Yr+svx6eXO85fFATMnxLojX8+5TCPARItCSqLAMk0/D0ReT26jTJm4vauks5diK02P2weKBmJJjZrMcr+fdJwlLS6CWRIVlmHwajoaTRHX1FeKdvU264OKLL75o1PBX4ixsnJ50Tozp86+/7WXxe04711oyWFoCtSQqLMPk03CHkTnBbOdl4hl+w2+LT1m+Efsk2uFJ58R4zZiDL8+Zdu8GSy2kdq61pLC3hNiSqLAMk0/DnUbmlOrqB4hneNxK0gEcnnROjO2F/3/ywNiv/cQ27pl2rrWEkFpCeqgbFJZh8mm468ic6d3rNZrnz+vZf3HT9vsu+trM161d99q51pICtIStJfWpzKfh2gnCKsQzXPv8eT37Lyadcu4r0p2pxFKpJOZ3jT6V+TRcP0FYeS3xelG1z5/Xs//ilrbls25b3SP8RDKp1BKzP1ufyrwarpwgTNchrX3+vJ42FfvuDz5z3YwXrR032rnWVDg8byjiVlgmkU/DtROEKTuktc+fJ1bX4sAT5tjWB3906gVzLRvTplKJy2gQEq6FZXbyaXhj+TXul6GyQ1r7/HlidS0OTLv+jBHXPWn/imssv2Z0lgKfUgP4eqWpnSBM2yGtfP48qboWF6bOfUs6CVenUgl+Sk3G1ytN7QRhSXVIx3x0Sl3XEoEVIK5NpRLnp9QseHulqZwgLKkO6ZhdXNq6lkRRplKJ81NqFlBhGSanhhvdBGFJdUjHNFxb15I0mlRqcX1KzQIqLMPk13DNBGFJdUjHNFxb15I4ilSq0Y0GgQvLELk1XDVBWFIdBzEN19a1JIwqlUq0/eGosAyTT8O1E4Ql1SEdu6zlk6bb792g3HgyaFOpRNsfDgvLIPk0XDtBWFId0nEfnXrkpFEXnzlslmJwz8TQplKJtj8cFZZh8mm4doIwZYe0dg61LecWHx1vnijPnVMftKlUou0PR4VlmHwarp0gTNkhPU2Z1LmlK9yOq1VrSQZtKpVo+8NxYRkin4aXiF+greyQnvbM9FmvK7I6cHpyY/xVJEz8VCrR9ofjwjJEPg3XFmgrO6TfM6btd9MbV8e9YVO8pdojTkxQP7Sp1KLsD0eFZZh8Gq4t0E6iQ7p1wSlnx5zKJ+MxSgJoU6lG1x+OCssw+TRcW6Ct7JBebDqe+/EpE5bHnasq4zFKAmhTmRBw1DYLqLAMk1PDlQXayg7pqTOGf3eB4nsjL2OUFNGnMgEcRm2zgArLMPk0XD1BmK5DekrjBtXMZBXqMEI+Ipm51lQ4jdqWGvk0XFugreyQfiDmZmuow8icEGUqtaDx91Inn4ZrJwhLpEPaPm+CMzkwPJMZyAdxHn8vNfJpuHaCsEQ6pIUpKFzJgeGZzEA+iPP4e6mRT8O1E4Ql1CGtHgstB4bXcwbycNzG30uN3BqumiBM2SHtOgUFJB+G120Gchsu4++lRk4NV04QpuyQTmzehDqMkI+o5wzkAnHv2uvJp+Ham4LKDmn1PcnutW9nPoxamTzdX82EfBqe2E3BeB3S2s23n3/qST/OQ3G4ydf91UzIp+GJTRAW70S48icg5l2SBxf2dc9aE2/ZpEl5rrX8k0/DEyPmpZ5yHp7ZvYWr1YWaYd1JYtDwELTz8BQ7K9t+Xp8R8gmAhoegnYfnK391lydoeAjaYQ+/8ld3ecJzw+N1SGuHPcxT9exXHk8N13VI+9Qf/pXHT8OVHdI+9Yd/5fHTcGWHtPYsI0/94V95/DRc3SGtm0eY/eE5wk/DlR3S2nmE2R+eI/w0XHupqJxHmP3hOcJPw5WXitp5hNkfniP8NFx5qaidR5j94TnCT8PVHdLJzCMcdxgckiB+Gq7ukE5iHuH4w+CQBPHTcGWH9Et3v6TehWyHwSEV/DRc2SE9/cWY47kPkPkwOKSCn4YrO6QHesLvi7n57IfBIRX8NFzZIT1t3j1F5l0Yc/PZD4NDKvhpuLJDeuq1U6YWmHRW/D3IeBgcUsFPw5Ud0gNnKT/T7EOmw+CQCn4aPkDMDunrt5Xm1Ig9d0yZ7IbBIRV8Njx2h/TDU7R94SQ3+Gt4Ah3SvCfpAZ4aPR46ZgAABjtJREFUnkSHNO9JeoGfhifQIc17kp7gp+HaDmnek/QHPw03ug5p3pP0CG8N13RI856kR3hsuNF0SPOepC/4bbgG3pP0AxouMDfrHSB6aHgIH9zzSuHfLTOWZL0jRA8ND2H2Y8Uha7s3TNAWppDsoeEhzCq/Lvg0090gSUDDQ7im/Hq38mE2kgNoeAizf9//0j6WQyQPfWh4CM2j72/u/PLli1jf7QE0PIwtFw8bNmz4g1nvBkkAGh5K78bn1xzKeidIEtBwiXhTKpM8QcMlYk44S3IEDZeg4UMfGi5Bw4c+NFyChg99aLgEDR/60HCJeFMqkzxBw8PgnMb+QMND4JzGHkHDQ+Ccxh5Bw0PgnMYeQcND4JzGHkHDQ+Ccxh5Bw0PgnMYeQcND4JzGHkHDw2B/uD/Q8BDYH+4RNDwE9od7BA0Pgf3hHkHDQ2B/uEfQ8BDYH+4RNDwE9od7BA0Pgf3hHkHDBTifpgfQcCucT9MLaLgFzqfpCTQ8DM6n6Q80PATOp+kRNDwEzqfpETQ8HM6n6Qs03Abn0/QDGi7AOSA8gIYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG9oOPEbGk78hoYTv6HhxG/+P3ruNJIOm8BZAAAAAElFTkSuQmCC\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i IMPORTANCE_SUMMARY -w 26 -h 32 -u cm\n",
    "\n",
    "plots <- list()\n",
    "\n",
    "#for (l in c('valence', 'arousal', 'stress', 'disturbance')) {\n",
    "for (l in c( 'stress')) {\n",
    "    data <- IMPORTANCE_SUMMARY %>% filter(\n",
    "        (label == l)\n",
    "    )\n",
    "\n",
    "    p_label <- ggplot() + geom_text(\n",
    "        aes(x=.5, y=.5),\n",
    "        label=str_to_title(l), \n",
    "        family='ssp', \n",
    "        fontface='bold',\n",
    "        size=4\n",
    "    ) + theme_void()\n",
    "\n",
    "    p_rf <- ggplot(\n",
    "        data %>% filter(alg == 'rf_os') %>% top_n(n=10, wt=importance),\n",
    "        aes(x=reorder(feature, -importance), y=importance),\n",
    "    ) + geom_col(\n",
    "    ) + THEME_DEFAULT + theme(\n",
    "        axis.text.x=element_text(angle=90, size=10, hjust=1, vjust=.5),\n",
    "        axis.title.x=element_blank(),\n",
    "        axis.title.y=element_blank()\n",
    "    ) + labs(\n",
    "        subtitle='Random Forest'\n",
    "    )\n",
    "    \n",
    "    p_xgb <- ggplot(\n",
    "        data %>% filter(alg == 'xgb_os') %>% top_n(n=10, wt=importance),\n",
    "        aes(x=reorder(feature, -importance), y=importance),\n",
    "    ) + geom_col(\n",
    "    ) + THEME_DEFAULT + theme(\n",
    "        axis.text.x=element_text(angle=90, size=10, hjust=1, vjust=.5),\n",
    "        axis.title.x=element_blank(),\n",
    "        axis.title.y=element_blank()\n",
    "    ) + labs(\n",
    "        subtitle='XGBoost'\n",
    "    )\n",
    "    \n",
    "    plots[[paste(l, 'label', sep='_')]] <- p_label\n",
    "    plots[[paste(l, 'rf', sep='_')]] <- p_rf\n",
    "    plots[[paste(l, 'xgb', sep='_')]] <- p_xgb\n",
    "}\n",
    "\n",
    "#p <- plots$arousal_label + plots$valence_label\n",
    "#p <- p / (plots$arousal_rf | plots$arousal_xgb | plots$valence_rf | plots$valence_xgb)\n",
    "#p <- p / (plots$stress_label + plots$disturbance_label)\n",
    "#p <- p / (plots$stress_rf | plots$stress_xgb | plots$disturbance_rf | plots$disturbance_xgb)\n",
    "p <- plots$stress_label \n",
    "p <- p / (plots$stress_rf | plots$stress_xgb)\n",
    "\n",
    "p <- p + plot_layout(\n",
    "    heights=c(1.1, 10, 1.1, 10)\n",
    ")\n",
    "\n",
    "ggsave(paste('./fig/imp.pdf'), plot=p, width=26, height=32, unit='cm', device=cairo_pdf)\n",
    "print(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
